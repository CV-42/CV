{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3946306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import time\n",
    "import json\n",
    "import tensorflow as tf\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.Session()\n",
    "import keras\n",
    "import keras_metrics\n",
    "import random\n",
    "\n",
    "import import_ipynb\n",
    "from reading_splitting_dataset_functions import *\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "692f88a1-8927-46c0-9041-2e28ac5783f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hier AUSWAHL TREFFEN!\n",
    "\n",
    "# Parameter für Kreuzvalidierung\n",
    "n_splits = 2\n",
    "n_epochs = 100\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e49039-78eb-4dc7-a242-5cdcd08aa8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length ROI: 33676\n"
     ]
    }
   ],
   "source": [
    "data_roi = open_js_file('data_preprocessed_roi.JSON')\n",
    "print('length ROI:', len(data_roi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1d304e-b625-4dbd-b89b-35db1d691c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roi, fid_roi, v_roi, lva_roi, lha_roi = get_acceleration_fid_v_labels(data_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3983f1d6-9f7f-4813-a16b-8768e98b5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33676, 512, 3)\n",
      "(33676,)\n",
      "(33676,)\n",
      "(33676,)\n",
      "(33676,)\n"
     ]
    }
   ],
   "source": [
    "print(df_roi.shape)\n",
    "print(fid_roi.shape)\n",
    "print(v_roi.shape)\n",
    "print(lva_roi.shape)\n",
    "print(lha_roi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee92a9d-a2e7-4e43-8ed1-18bdcf167747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "l_roi = labels_roi(lva_roi, lha_roi)\n",
    "print(l_roi[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a069b42-075c-4fe5-be98-d757cfbff59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#amount splits into test and trainingsdata such every fid was exactly once in testdata\n",
    "#with n_splits->\n",
    "cv = StratifiedGroupKFold(n_splits)\n",
    "splits =  cv.split(df_roi, l_roi, fid_roi)\n",
    "splits = list(splits) # Generatoren sind schlecht wiederverwendbar. Deshalb Liste draus machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9e2d90-28fc-47c9-b290-44bec90d9611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512, 3, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*df_roi.shape[1:],1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c9c47b4-2628-4a49-a126-8762c3c2838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(\n",
    "            kernel_size = (12,3),\n",
    "            filters = 10,\n",
    "            strides = (3,1),\n",
    "            input_shape = [*df_roi.shape[1:],1], # Das Sternchen sorgt für's \"Entpacken\". So können zwei Listen zusammengehängt werden.\n",
    "            activation = \"relu\"\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.MaxPool2D(\n",
    "            pool_size = (5,1)\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            kernel_size = (8,1),\n",
    "            filters = 10,\n",
    "            activation = \"relu\"\n",
    "        ),\n",
    "        tf.keras.layers.MaxPool2D(\n",
    "            pool_size = (7,1)\n",
    "        ),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(\n",
    "            units = 10,\n",
    "            activation = \"relu\"\n",
    "        ),\n",
    "        tf.keras.layers.Dense(\n",
    "            units = 4,\n",
    "            activation = \"softmax\"\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f625e030-8537-414b-9352-95f30475f2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bring_in_right_shape_3D(x_train, y_train, x_test, y_test, num_classes=4, num_features=512*3):\n",
    "    #from tensorflow import to_categorical\n",
    "    #reshape y\n",
    "    y_train = y_train.reshape((-1,1))\n",
    "    y_test = y_test.reshape((-1,1))\n",
    "    \n",
    "    #cast to np.float32\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_test = y_test.astype(np.float32)\n",
    "    \n",
    "    # Compute the categorical classes (doenst requested when binary classification)\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
    "    \n",
    "    x_train = x_train.reshape(*x_train.shape, 1)\n",
    "    x_test  = x_test.reshape([*x_test.shape, 1])\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e982d5a-acf9-4ca1-b457-3a0282b773d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "260/260 [==============================] - 13s 24ms/step - loss: 0.8788 - accuracy: 0.6116 - val_loss: 0.6437 - val_accuracy: 0.7729\n",
      "Epoch 2/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.4791 - accuracy: 0.8149 - val_loss: 0.5065 - val_accuracy: 0.8270\n",
      "Epoch 3/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.3857 - accuracy: 0.8516 - val_loss: 0.4200 - val_accuracy: 0.8556\n",
      "Epoch 4/100\n",
      "260/260 [==============================] - 5s 20ms/step - loss: 0.3311 - accuracy: 0.8749 - val_loss: 0.3912 - val_accuracy: 0.8537\n",
      "Epoch 5/100\n",
      "260/260 [==============================] - 5s 21ms/step - loss: 0.2950 - accuracy: 0.8854 - val_loss: 0.3418 - val_accuracy: 0.8835\n",
      "Epoch 6/100\n",
      "260/260 [==============================] - 5s 21ms/step - loss: 0.2654 - accuracy: 0.8966 - val_loss: 0.3392 - val_accuracy: 0.8719\n",
      "Epoch 7/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.2481 - accuracy: 0.9030 - val_loss: 0.3122 - val_accuracy: 0.8963\n",
      "Epoch 8/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.2363 - accuracy: 0.9093 - val_loss: 0.2961 - val_accuracy: 0.8946\n",
      "Epoch 9/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.2228 - accuracy: 0.9153 - val_loss: 0.2924 - val_accuracy: 0.8967\n",
      "Epoch 10/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.2174 - accuracy: 0.9174 - val_loss: 0.2765 - val_accuracy: 0.9024\n",
      "Epoch 11/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.2085 - accuracy: 0.9221 - val_loss: 0.2832 - val_accuracy: 0.8961\n",
      "Epoch 12/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.2034 - accuracy: 0.9235 - val_loss: 0.2812 - val_accuracy: 0.8960\n",
      "Epoch 13/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.2040 - accuracy: 0.9230 - val_loss: 0.2719 - val_accuracy: 0.9040\n",
      "Epoch 14/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.1910 - accuracy: 0.9280 - val_loss: 0.2483 - val_accuracy: 0.9174\n",
      "Epoch 15/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.1886 - accuracy: 0.9297 - val_loss: 0.2510 - val_accuracy: 0.9133\n",
      "Epoch 16/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1765 - accuracy: 0.9352 - val_loss: 0.2493 - val_accuracy: 0.9140\n",
      "Epoch 17/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1798 - accuracy: 0.9333 - val_loss: 0.2678 - val_accuracy: 0.8991\n",
      "Epoch 18/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.1809 - accuracy: 0.9310 - val_loss: 0.2526 - val_accuracy: 0.9114\n",
      "Epoch 19/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.1750 - accuracy: 0.9366 - val_loss: 0.2488 - val_accuracy: 0.9117\n",
      "Epoch 20/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1704 - accuracy: 0.9370 - val_loss: 0.2349 - val_accuracy: 0.9215\n",
      "Epoch 21/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1687 - accuracy: 0.9370 - val_loss: 0.2338 - val_accuracy: 0.9155\n",
      "Epoch 22/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.1644 - accuracy: 0.9386 - val_loss: 0.2334 - val_accuracy: 0.9174\n",
      "Epoch 23/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1656 - accuracy: 0.9377 - val_loss: 0.2375 - val_accuracy: 0.9174\n",
      "Epoch 24/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1578 - accuracy: 0.9392 - val_loss: 0.2403 - val_accuracy: 0.9182\n",
      "Epoch 25/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1569 - accuracy: 0.9405 - val_loss: 0.2360 - val_accuracy: 0.9182\n",
      "Epoch 26/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1492 - accuracy: 0.9445 - val_loss: 0.2227 - val_accuracy: 0.9260\n",
      "Epoch 27/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1517 - accuracy: 0.9431 - val_loss: 0.2563 - val_accuracy: 0.9058\n",
      "Epoch 28/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1611 - accuracy: 0.9407 - val_loss: 0.2451 - val_accuracy: 0.9147\n",
      "Epoch 29/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1533 - accuracy: 0.9420 - val_loss: 0.2262 - val_accuracy: 0.9225\n",
      "Epoch 30/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1484 - accuracy: 0.9444 - val_loss: 0.2283 - val_accuracy: 0.9223\n",
      "Epoch 31/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.1511 - accuracy: 0.9431 - val_loss: 0.2293 - val_accuracy: 0.9225\n",
      "Epoch 32/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1481 - accuracy: 0.9455 - val_loss: 0.2385 - val_accuracy: 0.9181\n",
      "Epoch 33/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1427 - accuracy: 0.9449 - val_loss: 0.2247 - val_accuracy: 0.9240\n",
      "Epoch 34/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1435 - accuracy: 0.9466 - val_loss: 0.2158 - val_accuracy: 0.9277\n",
      "Epoch 35/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1377 - accuracy: 0.9467 - val_loss: 0.2246 - val_accuracy: 0.9255\n",
      "Epoch 36/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1434 - accuracy: 0.9467 - val_loss: 0.2195 - val_accuracy: 0.9263\n",
      "Epoch 37/100\n",
      "260/260 [==============================] - 5s 18ms/step - loss: 0.1421 - accuracy: 0.9455 - val_loss: 0.2186 - val_accuracy: 0.9265\n",
      "Epoch 38/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1357 - accuracy: 0.9493 - val_loss: 0.2354 - val_accuracy: 0.9183\n",
      "Epoch 39/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1387 - accuracy: 0.9484 - val_loss: 0.2221 - val_accuracy: 0.9261\n",
      "Epoch 40/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1297 - accuracy: 0.9517 - val_loss: 0.2235 - val_accuracy: 0.9242\n",
      "Epoch 41/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1393 - accuracy: 0.9473 - val_loss: 0.2215 - val_accuracy: 0.9249\n",
      "Epoch 42/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1372 - accuracy: 0.9501 - val_loss: 0.2231 - val_accuracy: 0.9229\n",
      "Epoch 43/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1257 - accuracy: 0.9528 - val_loss: 0.2254 - val_accuracy: 0.9218\n",
      "Epoch 44/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1355 - accuracy: 0.9495 - val_loss: 0.2303 - val_accuracy: 0.9200\n",
      "Epoch 45/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1330 - accuracy: 0.9495 - val_loss: 0.2170 - val_accuracy: 0.9252\n",
      "Epoch 46/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1341 - accuracy: 0.9495 - val_loss: 0.2421 - val_accuracy: 0.9151\n",
      "Epoch 47/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1358 - accuracy: 0.9481 - val_loss: 0.2239 - val_accuracy: 0.9225\n",
      "Epoch 48/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1282 - accuracy: 0.9530 - val_loss: 0.2213 - val_accuracy: 0.9230\n",
      "Epoch 49/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1279 - accuracy: 0.9528 - val_loss: 0.2224 - val_accuracy: 0.9236\n",
      "Epoch 50/100\n",
      "260/260 [==============================] - 5s 20ms/step - loss: 0.1296 - accuracy: 0.9517 - val_loss: 0.2225 - val_accuracy: 0.9232\n",
      "Epoch 51/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1229 - accuracy: 0.9541 - val_loss: 0.2147 - val_accuracy: 0.9256\n",
      "Epoch 52/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1269 - accuracy: 0.9520 - val_loss: 0.2206 - val_accuracy: 0.9236\n",
      "Epoch 53/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1225 - accuracy: 0.9546 - val_loss: 0.2164 - val_accuracy: 0.9243\n",
      "Epoch 54/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1266 - accuracy: 0.9541 - val_loss: 0.2364 - val_accuracy: 0.9181\n",
      "Epoch 55/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1236 - accuracy: 0.9548 - val_loss: 0.2259 - val_accuracy: 0.9245\n",
      "Epoch 56/100\n",
      "260/260 [==============================] - 5s 19ms/step - loss: 0.1267 - accuracy: 0.9531 - val_loss: 0.2243 - val_accuracy: 0.9246\n",
      "Epoch 57/100\n",
      "260/260 [==============================] - 6s 23ms/step - loss: 0.1255 - accuracy: 0.9537 - val_loss: 0.2193 - val_accuracy: 0.9246\n",
      "Epoch 58/100\n",
      "260/260 [==============================] - 6s 23ms/step - loss: 0.1292 - accuracy: 0.9511 - val_loss: 0.2208 - val_accuracy: 0.9233\n",
      "Epoch 59/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1227 - accuracy: 0.9553 - val_loss: 0.2177 - val_accuracy: 0.9264\n",
      "Epoch 60/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1191 - accuracy: 0.9558 - val_loss: 0.2168 - val_accuracy: 0.9247\n",
      "Epoch 61/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1241 - accuracy: 0.9547 - val_loss: 0.2208 - val_accuracy: 0.9239\n",
      "Epoch 62/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1175 - accuracy: 0.9575 - val_loss: 0.2217 - val_accuracy: 0.9227\n",
      "Epoch 63/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1210 - accuracy: 0.9548 - val_loss: 0.2249 - val_accuracy: 0.9214\n",
      "Epoch 64/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1176 - accuracy: 0.9561 - val_loss: 0.2311 - val_accuracy: 0.9190\n",
      "Epoch 65/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1198 - accuracy: 0.9549 - val_loss: 0.2206 - val_accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1216 - accuracy: 0.9540 - val_loss: 0.2201 - val_accuracy: 0.9227\n",
      "Epoch 67/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1264 - accuracy: 0.9525 - val_loss: 0.2355 - val_accuracy: 0.9182\n",
      "Epoch 68/100\n",
      "260/260 [==============================] - 6s 24ms/step - loss: 0.1198 - accuracy: 0.9559 - val_loss: 0.2361 - val_accuracy: 0.9176\n",
      "Epoch 69/100\n",
      "260/260 [==============================] - 6s 23ms/step - loss: 0.1212 - accuracy: 0.9555 - val_loss: 0.2201 - val_accuracy: 0.9242\n",
      "Epoch 70/100\n",
      "260/260 [==============================] - 6s 23ms/step - loss: 0.1231 - accuracy: 0.9537 - val_loss: 0.2152 - val_accuracy: 0.9253\n",
      "Epoch 71/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1246 - accuracy: 0.9548 - val_loss: 0.2237 - val_accuracy: 0.9236\n",
      "Epoch 72/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1189 - accuracy: 0.9573 - val_loss: 0.2242 - val_accuracy: 0.9227\n",
      "Epoch 73/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1165 - accuracy: 0.9574 - val_loss: 0.2367 - val_accuracy: 0.9181\n",
      "Epoch 74/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1102 - accuracy: 0.9584 - val_loss: 0.2337 - val_accuracy: 0.9165\n",
      "Epoch 75/100\n",
      "260/260 [==============================] - 6s 25ms/step - loss: 0.1220 - accuracy: 0.9534 - val_loss: 0.2204 - val_accuracy: 0.9252\n",
      "Epoch 76/100\n",
      "260/260 [==============================] - 6s 23ms/step - loss: 0.1153 - accuracy: 0.9561 - val_loss: 0.2246 - val_accuracy: 0.9219\n",
      "Epoch 77/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1097 - accuracy: 0.9599 - val_loss: 0.2204 - val_accuracy: 0.9232\n",
      "Epoch 78/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1151 - accuracy: 0.9563 - val_loss: 0.2204 - val_accuracy: 0.9245\n",
      "Epoch 79/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1081 - accuracy: 0.9598 - val_loss: 0.2143 - val_accuracy: 0.9268\n",
      "Epoch 80/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1171 - accuracy: 0.9564 - val_loss: 0.2461 - val_accuracy: 0.9121\n",
      "Epoch 81/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1147 - accuracy: 0.9577 - val_loss: 0.2306 - val_accuracy: 0.9202\n",
      "Epoch 82/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1102 - accuracy: 0.9598 - val_loss: 0.2205 - val_accuracy: 0.9252\n",
      "Epoch 83/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1095 - accuracy: 0.9598 - val_loss: 0.2200 - val_accuracy: 0.9246\n",
      "Epoch 84/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1171 - accuracy: 0.9571 - val_loss: 0.2293 - val_accuracy: 0.9211\n",
      "Epoch 85/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1133 - accuracy: 0.9586 - val_loss: 0.2206 - val_accuracy: 0.9253\n",
      "Epoch 86/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1054 - accuracy: 0.9609 - val_loss: 0.2224 - val_accuracy: 0.9227\n",
      "Epoch 87/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1088 - accuracy: 0.9608 - val_loss: 0.2181 - val_accuracy: 0.9255\n",
      "Epoch 88/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1151 - accuracy: 0.9556 - val_loss: 0.2214 - val_accuracy: 0.9231\n",
      "Epoch 89/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1077 - accuracy: 0.9607 - val_loss: 0.2207 - val_accuracy: 0.9237\n",
      "Epoch 90/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1114 - accuracy: 0.9583 - val_loss: 0.2333 - val_accuracy: 0.9204\n",
      "Epoch 91/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1135 - accuracy: 0.9599 - val_loss: 0.2289 - val_accuracy: 0.9208\n",
      "Epoch 92/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1105 - accuracy: 0.9569 - val_loss: 0.2330 - val_accuracy: 0.9187\n",
      "Epoch 93/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1074 - accuracy: 0.9600 - val_loss: 0.2301 - val_accuracy: 0.9204\n",
      "Epoch 94/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1073 - accuracy: 0.9613 - val_loss: 0.2315 - val_accuracy: 0.9195\n",
      "Epoch 95/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1097 - accuracy: 0.9583 - val_loss: 0.2268 - val_accuracy: 0.9225\n",
      "Epoch 96/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1059 - accuracy: 0.9601 - val_loss: 0.2208 - val_accuracy: 0.9227\n",
      "Epoch 97/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1079 - accuracy: 0.9602 - val_loss: 0.2235 - val_accuracy: 0.9219\n",
      "Epoch 98/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1087 - accuracy: 0.9588 - val_loss: 0.2187 - val_accuracy: 0.9260\n",
      "Epoch 99/100\n",
      "260/260 [==============================] - 6s 22ms/step - loss: 0.1127 - accuracy: 0.9593 - val_loss: 0.2364 - val_accuracy: 0.9179\n",
      "Epoch 100/100\n",
      "260/260 [==============================] - 6s 24ms/step - loss: 0.1124 - accuracy: 0.9581 - val_loss: 0.2179 - val_accuracy: 0.9252\n",
      "Epoch 1/100\n",
      "267/267 [==============================] - 7s 24ms/step - loss: 0.9151 - accuracy: 0.6229 - val_loss: 0.6987 - val_accuracy: 0.7356\n",
      "Epoch 2/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.5436 - accuracy: 0.7823 - val_loss: 0.5406 - val_accuracy: 0.8019\n",
      "Epoch 3/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.4025 - accuracy: 0.8452 - val_loss: 0.4591 - val_accuracy: 0.8355\n",
      "Epoch 4/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.3362 - accuracy: 0.8734 - val_loss: 0.4202 - val_accuracy: 0.8599\n",
      "Epoch 5/100\n",
      "267/267 [==============================] - 6s 24ms/step - loss: 0.2946 - accuracy: 0.8884 - val_loss: 0.3946 - val_accuracy: 0.8772\n",
      "Epoch 6/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.2654 - accuracy: 0.9029 - val_loss: 0.3683 - val_accuracy: 0.8799\n",
      "Epoch 7/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.2386 - accuracy: 0.9125 - val_loss: 0.3748 - val_accuracy: 0.8746\n",
      "Epoch 8/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.2287 - accuracy: 0.9173 - val_loss: 0.3574 - val_accuracy: 0.8802\n",
      "Epoch 9/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.2108 - accuracy: 0.9242 - val_loss: 0.3685 - val_accuracy: 0.8684\n",
      "Epoch 10/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.2058 - accuracy: 0.9255 - val_loss: 0.3541 - val_accuracy: 0.8658\n",
      "Epoch 11/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1920 - accuracy: 0.9280 - val_loss: 0.3290 - val_accuracy: 0.8930\n",
      "Epoch 12/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1862 - accuracy: 0.9331 - val_loss: 0.3563 - val_accuracy: 0.8927\n",
      "Epoch 13/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1870 - accuracy: 0.9312 - val_loss: 0.3221 - val_accuracy: 0.8905\n",
      "Epoch 14/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1790 - accuracy: 0.9355 - val_loss: 0.3244 - val_accuracy: 0.8959\n",
      "Epoch 15/100\n",
      "267/267 [==============================] - 7s 25ms/step - loss: 0.1688 - accuracy: 0.9380 - val_loss: 0.3416 - val_accuracy: 0.8931\n",
      "Epoch 16/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1702 - accuracy: 0.9385 - val_loss: 0.3232 - val_accuracy: 0.8938\n",
      "Epoch 17/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.1616 - accuracy: 0.9420 - val_loss: 0.3214 - val_accuracy: 0.8975\n",
      "Epoch 18/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1619 - accuracy: 0.9403 - val_loss: 0.3134 - val_accuracy: 0.8952\n",
      "Epoch 19/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1548 - accuracy: 0.9435 - val_loss: 0.3205 - val_accuracy: 0.8943\n",
      "Epoch 20/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1514 - accuracy: 0.9452 - val_loss: 0.3271 - val_accuracy: 0.9039\n",
      "Epoch 21/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1457 - accuracy: 0.9455 - val_loss: 0.3265 - val_accuracy: 0.8892\n",
      "Epoch 22/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1457 - accuracy: 0.9467 - val_loss: 0.3061 - val_accuracy: 0.8969\n",
      "Epoch 23/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1491 - accuracy: 0.9469 - val_loss: 0.3140 - val_accuracy: 0.9069\n",
      "Epoch 24/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1463 - accuracy: 0.9472 - val_loss: 0.3115 - val_accuracy: 0.9042\n",
      "Epoch 25/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.1403 - accuracy: 0.9496 - val_loss: 0.3030 - val_accuracy: 0.8936\n",
      "Epoch 26/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1418 - accuracy: 0.9498 - val_loss: 0.2865 - val_accuracy: 0.9088\n",
      "Epoch 27/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1433 - accuracy: 0.9479 - val_loss: 0.2924 - val_accuracy: 0.9018\n",
      "Epoch 28/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1431 - accuracy: 0.9472 - val_loss: 0.2869 - val_accuracy: 0.9009\n",
      "Epoch 29/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1399 - accuracy: 0.9503 - val_loss: 0.2924 - val_accuracy: 0.9007\n",
      "Epoch 30/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1351 - accuracy: 0.9519 - val_loss: 0.3027 - val_accuracy: 0.8947\n",
      "Epoch 31/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.1352 - accuracy: 0.9509 - val_loss: 0.3075 - val_accuracy: 0.8967\n",
      "Epoch 32/100\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.1335 - accuracy: 0.9532 - val_loss: 0.3080 - val_accuracy: 0.9027\n",
      "Epoch 33/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1350 - accuracy: 0.9503 - val_loss: 0.3063 - val_accuracy: 0.9014\n",
      "Epoch 34/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1301 - accuracy: 0.9532 - val_loss: 0.2897 - val_accuracy: 0.8969\n",
      "Epoch 35/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1257 - accuracy: 0.9534 - val_loss: 0.2910 - val_accuracy: 0.9081\n",
      "Epoch 36/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1273 - accuracy: 0.9547 - val_loss: 0.3209 - val_accuracy: 0.8974\n",
      "Epoch 37/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1338 - accuracy: 0.9527 - val_loss: 0.3008 - val_accuracy: 0.8951\n",
      "Epoch 38/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1312 - accuracy: 0.9531 - val_loss: 0.3515 - val_accuracy: 0.8822\n",
      "Epoch 39/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1270 - accuracy: 0.9542 - val_loss: 0.3058 - val_accuracy: 0.8980\n",
      "Epoch 40/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1260 - accuracy: 0.9548 - val_loss: 0.3159 - val_accuracy: 0.8908\n",
      "Epoch 41/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1215 - accuracy: 0.9563 - val_loss: 0.3136 - val_accuracy: 0.8947\n",
      "Epoch 42/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1200 - accuracy: 0.9567 - val_loss: 0.2917 - val_accuracy: 0.9051\n",
      "Epoch 43/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1212 - accuracy: 0.9567 - val_loss: 0.3129 - val_accuracy: 0.8941\n",
      "Epoch 44/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1190 - accuracy: 0.9588 - val_loss: 0.3296 - val_accuracy: 0.8878\n",
      "Epoch 45/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1215 - accuracy: 0.9554 - val_loss: 0.3332 - val_accuracy: 0.8851\n",
      "Epoch 46/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1162 - accuracy: 0.9578 - val_loss: 0.3098 - val_accuracy: 0.9013\n",
      "Epoch 47/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1172 - accuracy: 0.9577 - val_loss: 0.3005 - val_accuracy: 0.8862\n",
      "Epoch 48/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1168 - accuracy: 0.9576 - val_loss: 0.3202 - val_accuracy: 0.8938\n",
      "Epoch 49/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1148 - accuracy: 0.9587 - val_loss: 0.3109 - val_accuracy: 0.9045\n",
      "Epoch 50/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1145 - accuracy: 0.9588 - val_loss: 0.3410 - val_accuracy: 0.8931\n",
      "Epoch 51/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1148 - accuracy: 0.9589 - val_loss: 0.3158 - val_accuracy: 0.8942\n",
      "Epoch 52/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1187 - accuracy: 0.9582 - val_loss: 0.3328 - val_accuracy: 0.8894\n",
      "Epoch 53/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1127 - accuracy: 0.9604 - val_loss: 0.3527 - val_accuracy: 0.8939\n",
      "Epoch 54/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1126 - accuracy: 0.9601 - val_loss: 0.3227 - val_accuracy: 0.8901\n",
      "Epoch 55/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1150 - accuracy: 0.9587 - val_loss: 0.3265 - val_accuracy: 0.8857\n",
      "Epoch 56/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1156 - accuracy: 0.9604 - val_loss: 0.3290 - val_accuracy: 0.8881\n",
      "Epoch 57/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1068 - accuracy: 0.9622 - val_loss: 0.3325 - val_accuracy: 0.8954\n",
      "Epoch 58/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1116 - accuracy: 0.9609 - val_loss: 0.3250 - val_accuracy: 0.8964\n",
      "Epoch 59/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1116 - accuracy: 0.9601 - val_loss: 0.3236 - val_accuracy: 0.8945\n",
      "Epoch 60/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1120 - accuracy: 0.9606 - val_loss: 0.2956 - val_accuracy: 0.8979\n",
      "Epoch 61/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1116 - accuracy: 0.9611 - val_loss: 0.3372 - val_accuracy: 0.8902\n",
      "Epoch 62/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1130 - accuracy: 0.9603 - val_loss: 0.3212 - val_accuracy: 0.8833\n",
      "Epoch 63/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1081 - accuracy: 0.9635 - val_loss: 0.3414 - val_accuracy: 0.8957\n",
      "Epoch 64/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1068 - accuracy: 0.9633 - val_loss: 0.3207 - val_accuracy: 0.8902\n",
      "Epoch 65/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1077 - accuracy: 0.9628 - val_loss: 0.3088 - val_accuracy: 0.8958\n",
      "Epoch 66/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1022 - accuracy: 0.9650 - val_loss: 0.3113 - val_accuracy: 0.8895\n",
      "Epoch 67/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1057 - accuracy: 0.9632 - val_loss: 0.3446 - val_accuracy: 0.8901\n",
      "Epoch 68/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1052 - accuracy: 0.9635 - val_loss: 0.3302 - val_accuracy: 0.8911\n",
      "Epoch 69/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1065 - accuracy: 0.9638 - val_loss: 0.3182 - val_accuracy: 0.8924\n",
      "Epoch 70/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1051 - accuracy: 0.9640 - val_loss: 0.3276 - val_accuracy: 0.8957\n",
      "Epoch 71/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1073 - accuracy: 0.9633 - val_loss: 0.3128 - val_accuracy: 0.8967\n",
      "Epoch 72/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.1051 - accuracy: 0.9622 - val_loss: 0.3428 - val_accuracy: 0.8793\n",
      "Epoch 73/100\n",
      "267/267 [==============================] - 6s 23ms/step - loss: 0.1031 - accuracy: 0.9643 - val_loss: 0.3421 - val_accuracy: 0.8783\n",
      "Epoch 74/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1053 - accuracy: 0.9621 - val_loss: 0.3184 - val_accuracy: 0.8925\n",
      "Epoch 75/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1025 - accuracy: 0.9636 - val_loss: 0.3111 - val_accuracy: 0.8999\n",
      "Epoch 76/100\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.1017 - accuracy: 0.9616 - val_loss: 0.3073 - val_accuracy: 0.9012\n",
      "Epoch 77/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1005 - accuracy: 0.9654 - val_loss: 0.3247 - val_accuracy: 0.8933\n",
      "Epoch 78/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1000 - accuracy: 0.9656 - val_loss: 0.3334 - val_accuracy: 0.8852\n",
      "Epoch 79/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1088 - accuracy: 0.9625 - val_loss: 0.3387 - val_accuracy: 0.8864\n",
      "Epoch 80/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1039 - accuracy: 0.9641 - val_loss: 0.3078 - val_accuracy: 0.8967\n",
      "Epoch 81/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1036 - accuracy: 0.9643 - val_loss: 0.3255 - val_accuracy: 0.8968\n",
      "Epoch 82/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1029 - accuracy: 0.9631 - val_loss: 0.3222 - val_accuracy: 0.8951\n",
      "Epoch 83/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0970 - accuracy: 0.9662 - val_loss: 0.3177 - val_accuracy: 0.8895\n",
      "Epoch 84/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.0998 - accuracy: 0.9659 - val_loss: 0.3425 - val_accuracy: 0.8864\n",
      "Epoch 85/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1010 - accuracy: 0.9649 - val_loss: 0.3266 - val_accuracy: 0.8901\n",
      "Epoch 86/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0995 - accuracy: 0.9647 - val_loss: 0.3323 - val_accuracy: 0.8828\n",
      "Epoch 87/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.1029 - accuracy: 0.9627 - val_loss: 0.3435 - val_accuracy: 0.8786\n",
      "Epoch 88/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1005 - accuracy: 0.9642 - val_loss: 0.3213 - val_accuracy: 0.8939\n",
      "Epoch 89/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.0963 - accuracy: 0.9656 - val_loss: 0.3297 - val_accuracy: 0.8900\n",
      "Epoch 90/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.0998 - accuracy: 0.9659 - val_loss: 0.3320 - val_accuracy: 0.8895\n",
      "Epoch 91/100\n",
      "267/267 [==============================] - 5s 18ms/step - loss: 0.0951 - accuracy: 0.9676 - val_loss: 0.3375 - val_accuracy: 0.8937\n",
      "Epoch 92/100\n",
      "267/267 [==============================] - 5s 19ms/step - loss: 0.1012 - accuracy: 0.9651 - val_loss: 0.3367 - val_accuracy: 0.8892\n",
      "Epoch 93/100\n",
      "267/267 [==============================] - 6s 22ms/step - loss: 0.1045 - accuracy: 0.9632 - val_loss: 0.3215 - val_accuracy: 0.8892\n",
      "Epoch 94/100\n",
      "267/267 [==============================] - 5s 21ms/step - loss: 0.0963 - accuracy: 0.9665 - val_loss: 0.3534 - val_accuracy: 0.8822\n",
      "Epoch 95/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.1002 - accuracy: 0.9657 - val_loss: 0.3176 - val_accuracy: 0.8924\n",
      "Epoch 96/100\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0980 - accuracy: 0.9659 - val_loss: 0.3150 - val_accuracy: 0.8937\n",
      "Epoch 97/100\n",
      "267/267 [==============================] - 5s 20ms/step - loss: 0.0975 - accuracy: 0.9664 - val_loss: 0.3561 - val_accuracy: 0.8752\n",
      "Epoch 98/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.0957 - accuracy: 0.9660 - val_loss: 0.3292 - val_accuracy: 0.8973\n",
      "Epoch 99/100\n",
      "267/267 [==============================] - 6s 21ms/step - loss: 0.0948 - accuracy: 0.9675 - val_loss: 0.3296 - val_accuracy: 0.8904\n",
      "Epoch 100/100\n",
      "267/267 [==============================] - 5s 21ms/step - loss: 0.1048 - accuracy: 0.9623 - val_loss: 0.3195 - val_accuracy: 0.8950\n",
      "Train Accuray =  [0.9581325054168701, 0.9623448252677917] mit Mittelwert 0.9602386653423309\n",
      "Test Accuray =  [0.9251581430435181, 0.8949999809265137] mit Mittelwert 0.9100790619850159\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "train_acc = []\n",
    "for train_idxs, test_idxs in splits:        \n",
    "        x_train, y_train, x_test, y_test = bring_in_right_shape_3D(df_roi[train_idxs],\n",
    "                                                                     l_roi[train_idxs],\n",
    "                                                                     df_roi[test_idxs],\n",
    "                                                                     l_roi[test_idxs])\n",
    "        model = create_conv_model()\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "        H = model.fit(x_train, y_train,\n",
    "                      batch_size = batch_size,\n",
    "                      validation_data = (x_test, y_test),\n",
    "                      epochs = n_epochs)\n",
    "        \n",
    "        test_acc.append(H.history[\"val_accuracy\"][-1])\n",
    "        train_acc.append(H.history[\"accuracy\"][-1])\n",
    "        \n",
    "print(\"Train Accuray = \", train_acc, \"mit Mittelwert\", np.mean(train_acc))\n",
    "print(\"Test Accuray = \", test_acc, \"mit Mittelwert\", np.mean(test_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e51b9bd5-43ec-4349-ade5-625464749ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 167, 1, 10)        370       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 167, 1, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 33, 1, 10)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 26, 1, 10)         810       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 3, 1, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 1,534\n",
      "Trainable params: 1,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e577c-d94e-4cd6-82e3-28a9a0146c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
