---
title: Zeitreihenvorhersage - Sonnenflecke
subtitle: Hauptquelle https://blogs.rstudio.com/ai/posts/2018-06-25-sunspots-lstm/
---

Pakete laden:

```{r results='hide', message=FALSE, warning=FALSE}
rm(list = ls())
set.seed(42)
# Core Tidyverse
library(tidyverse)
library(glue)
library(forcats)

# Time Series
library(timetk)
library(tidyquant)
library(tibbletime)

# Visualization
library(cowplot)

# Preprocessing
library(recipes)

# Sampling / Accuracy
library(rsample)
library(yardstick) 

# Modeling
library(keras)
library(tfruns)

```

Daten laden:

```{r}


sun_spots <- datasets::sunspot.month %>%
    tk_tbl() %>%
    mutate(index = as_date(index)) %>%
    as_tbl_time(index = index)

sun_spots


```
Daten anschauen:

```{r}


p1 <- sun_spots %>%
    ggplot(aes(index, value)) +
    geom_point(color = palette_light()[[1]], alpha = 0.5) +
    theme_tq() +
    labs(
        title = "From 1749 to 2013 (Full Data Set)"
    )

p2 <- sun_spots %>%
    filter_time("start" ~ "1800") %>%
    ggplot(aes(index, value)) +
    geom_line(color = palette_light()[[1]], alpha = 0.5) +
    geom_point(color = palette_light()[[1]]) +
    geom_smooth(method = "loess", span = 0.2, se = FALSE) +
    theme_tq() +
    labs(
        title = "1749 to 1759 (Zoomed In To Show Changes over the Year)",
        caption = "datasets::sunspot.month"
    )

p_title <- ggdraw() + 
  draw_label("Sunspots", size = 18, fontface = "bold", 
             colour = palette_light()[[1]])

plot_grid(p_title, p1, p2, ncol = 1, rel_heights = c(0.1, 1, 1))
```

Strategie für den Rückvergleich
===============================
Strategie (mit Paket rsample) erstellen:
```{r}
periods_train <- 12 * 100
periods_test  <- 12 * 50
skip_span     <- 12 * 22 - 1

rolling_origin_resamples <- rolling_origin(
  sun_spots,
  initial    = periods_train,
  assess     = periods_test,
  cumulative = FALSE,
  skip       = skip_span
)

rolling_origin_resamples
```

Plotten:
```{r}
# Plotting function for a single split
plot_split <- function(split, expand_y_axis = TRUE, 
                       alpha = 1, size = 1, base_size = 14) {
    
    # Manipulate data
    train_tbl <- training(split) %>%
        add_column(key = "training") 
    
    test_tbl  <- testing(split) %>%
        add_column(key = "testing") 
    
    data_manipulated <- bind_rows(train_tbl, test_tbl) %>%
        as_tbl_time(index = index) %>%
        mutate(key = fct_relevel(key, "training", "testing"))
        
    # Collect attributes
    train_time_summary <- train_tbl %>%
        tk_index() %>%
        tk_get_timeseries_summary()
    
    test_time_summary <- test_tbl %>%
        tk_index() %>%
        tk_get_timeseries_summary()
    
    # Visualize
    g <- data_manipulated %>%
        ggplot(aes(x = index, y = value, color = key)) +
        geom_line(size = size, alpha = alpha) +
        theme_tq(base_size = base_size) +
        scale_color_tq() +
        labs(
          title    = glue("Split: {split$id}"),
          subtitle = glue("{train_time_summary$start} to ", 
                          "{test_time_summary$end}"),
            y = "", x = ""
        ) +
        theme(legend.position = "none") 
    
    if (expand_y_axis) {
        
        sun_spots_time_summary <- sun_spots %>% 
            tk_index() %>% 
            tk_get_timeseries_summary()
        
        g <- g +
            scale_x_date(limits = c(sun_spots_time_summary$start, 
                                    sun_spots_time_summary$end))
    }
    
    g
}



# Plotting function that scales to all splits 
plot_sampling_plan <- function(sampling_tbl, expand_y_axis = TRUE, 
                               ncol = 3, alpha = 1, size = 1, base_size = 14, 
                               title = "Sampling Plan") {
    
    # Map plot_split() to sampling_tbl
    sampling_tbl_with_plots <- sampling_tbl %>%
        mutate(gg_plots = map(splits, plot_split, 
                              expand_y_axis = expand_y_axis,
                              alpha = alpha, base_size = base_size))
    
    # Make plots with cowplot
    plot_list <- sampling_tbl_with_plots$gg_plots 
    
    p_temp <- plot_list[[1]] + theme(legend.position = "bottom")
    legend <- get_legend(p_temp)
    
    p_body  <- plot_grid(plotlist = plot_list, ncol = ncol)
    
    p_title <- ggdraw() + 
        draw_label(title, size = 14, fontface = "bold", 
                   colour = palette_light()[[1]])
    
    g <- plot_grid(p_title, p_body, legend, ncol = 1, 
                   rel_heights = c(0.05, 1, 0.05))
    
    g
    
}



rolling_origin_resamples %>%
    plot_sampling_plan(expand_y_axis = T, ncol = 3, alpha = 1, size = 1, base_size = 10, 
                       title = "Backtesting Strategy: Rolling Origin Sampling Plan")


```

Modell für ein einzelnes Trainings-Test-Paar
======================================

Wähle das neueste Paar:
```{r}
example_split    <- rolling_origin_resamples$splits[[6]]
example_split_id <- rolling_origin_resamples$id[[6]]
```

Plotte:

```{r}
plot_split(example_split, expand_y_axis = FALSE, size = 0.5) +
    theme(legend.position = "bottom") +
    ggtitle(glue("Split: {example_split_id}"))
```

Daten aufbereiten
=================
Daten für Training, Validierung (während des Trainings) und Testen:
```{r}
df_trn <- analysis(example_split)[1:800, , drop = FALSE]
df_val <- analysis(example_split)[801:1200, , drop = FALSE]
df_tst <- assessment(example_split)
```
In eine Tibble zusammenfassen:
```{r}


df <- bind_rows(
  df_trn %>% add_column(key = "training"),
  df_val %>% add_column(key = "validation"),
  df_tst %>% add_column(key = "testing")
)

df
```
Skalierung und Zentrierung mit Paket recipes

```{r}
rec_obj <- recipe(value ~ ., df) %>%
    step_sqrt(value) %>%
    step_center(value) %>%
    step_scale(value) %>%
    prep()

df_processed_tbl <- bake(rec_obj, df)

df_processed_tbl


```

Umrechnung merken:
```{r}
center_history <- rec_obj$steps[[2]]$means["value"]
scale_history  <- rec_obj$steps[[3]]$sds["value"]

zurueck_transf <- function(x) x^2 * scale_history + center_history

c("center" = center_history, "scale" = scale_history)
```

In Matrizen umschreiben:
```{r}
# these variables are being defined just because of the order in which
# we present things in this post (first the data, then the model)
# they will be superseded by FLAGS$n_timesteps, FLAGS$batch_size and n_predictions
# in the following snippet
n_timesteps_x <- 12 * 1
n_timesteps_y <- n_timesteps_x
batch_size <- 10
n_timesteps_sprung <- n_timesteps_x

# functions used
build_matrix <- function(tseries, overall_timesteps) {
  t(sapply(1:(length(tseries) - overall_timesteps + 1), function(x) 
    tseries[x:(x + overall_timesteps - 1)]))
}

reshape_X_3d <- function(X) {
  dim(X) <- c(dim(X)[1], dim(X)[2], 1)
  X
}

# extract values from data frame
train_vals <- df_processed_tbl %>%
  filter(key == "training") %>%
  select(value) %>%
  pull()
valid_vals <- df_processed_tbl %>%
  filter(key == "validation") %>%
  select(value) %>%
  pull()
test_vals <- df_processed_tbl %>%
  filter(key == "testing") %>%
  select(value) %>%
  pull()


# build the windowed matrices
train_matrix <-
  build_matrix(train_vals, n_timesteps_x + n_timesteps_y)
valid_matrix <-
  build_matrix(valid_vals, n_timesteps_x + n_timesteps_y)
test_matrix <- build_matrix(test_vals, n_timesteps_x + n_timesteps_y)

# separate matrices into training and testing parts
# also, discard last batch if there are fewer than batch_size samples
# (a purely technical requirement)
X_train <- train_matrix[, 1:n_timesteps_x]
y_train <- train_matrix[, (n_timesteps_x + 1):(n_timesteps_x + n_timesteps_y)]
X_train <- X_train[1:(nrow(X_train) %/% batch_size * batch_size), ]
y_train <- y_train[1:(nrow(y_train) %/% batch_size * batch_size), ]

X_valid <- valid_matrix[, 1:n_timesteps_x]
y_valid <- valid_matrix[, (n_timesteps_x + 1):(n_timesteps_x + n_timesteps_y)]
X_valid <- X_valid[1:(nrow(X_valid) %/% batch_size * batch_size), ]
y_valid <- y_valid[1:(nrow(y_valid) %/% batch_size * batch_size), ]

X_test <- test_matrix[, 1:n_timesteps_x]
y_test <- test_matrix[, (n_timesteps_x + 1):(n_timesteps_x + n_timesteps_y)]
X_test <- X_test[1:(nrow(X_test) %/% batch_size * batch_size), ]
y_test <- y_test[1:(nrow(y_test) %/% batch_size * batch_size), ]

# add on the required third axis
X_train <- reshape_X_3d(X_train)
X_valid <- reshape_X_3d(X_valid)
X_test <- reshape_X_3d(X_test)

y_train <- reshape_X_3d(y_train)
y_valid <- reshape_X_3d(y_valid)
y_test <- reshape_X_3d(y_test)
```

Entscheidungen für Modellparameter:
```{r}
FLAGS <- flags(
  # There is a so-called "stateful LSTM" in Keras. While LSTM is stateful
  # per se, this adds a further tweak where the hidden states get 
  # initialized with values from the item at same position in the previous
  # batch. This is helpful just under specific circumstances, or if you want
  # to create an "infinite stream" of states, in which case you'd use 1 as 
  # the batch size. Below, we show how the code would have to be changed to
  # use this, but it won't be further discussed here.
  flag_boolean("stateful", FALSE),
  # Should we use several layers of LSTM?
  # Again, just included for completeness, it did not yield any superior 
  # performance on this task.
  # This will actually stack exactly one additional layer of LSTM units.
  flag_boolean("stack_layers", FALSE),
  # number of samples fed to the model in one go
  flag_integer("batch_size", batch_size),
  # size of the hidden state, equals size of predictions
  flag_integer("n_timesteps_versteckt", n_timesteps_x),
  # wie weit y und x von einander verschoben sind
  flag_integer("n_timesteps_sprung", n_timesteps_sprung),
  # size of Eingabe ins Netz
  flag_integer("n_timesteps_x", n_timesteps_x),
  # size of Ausgabe vom Netz
  flag_integer("n_timesteps_y", n_timesteps_y),
  # how many epochs to train for
  flag_integer("n_epochs", 100),
  # fraction of the units to drop for the linear transformation of the inputs
  flag_numeric("dropout", 0.2),
  # fraction of the units to drop for the linear transformation of the 
  # recurrent state
  flag_numeric("recurrent_dropout", 0.2),
  # loss function. Found to work better for this specific case than mean
  # squared error
  flag_string("loss", "logcosh"),
  # optimizer = stochastic gradient descent. Seemed to work better than adam 
  # or rmsprop here (as indicated by limited testing)
  flag_string("optimizer_type", "sgd"),
  # size of the LSTM layer
  flag_integer("n_units", 128),
  # learning rate
  flag_numeric("lr", 0.003),
  # momentum, an additional parameter to the SGD optimizer
  flag_numeric("momentum", 0.9),
  # parameter to the early stopping callback
  flag_integer("patience", 10)
)

# how many features = predictors we have
n_features <- 1
# just in case we wanted to try different optimizers, we could add here
optimizer <- switch(FLAGS$optimizer_type,
                    sgd = optimizer_sgd(lr = FLAGS$lr, 
                                        momentum = FLAGS$momentum)
                    )

# callbacks to be passed to the fit() function
# We just use one here: we may stop before n_epochs if the loss on the
# validation set does not decrease (by a configurable amount, over a 
# configurable time)
callbacks <- list(
  callback_early_stopping(patience = FLAGS$patience)
)

```

Modell erstellen und trainieren:
```{r}


# create the model
model <- keras_model_sequential()

# add layers
# we have just two, the LSTM and the time_distributed 
model %>%
  layer_lstm(
    units = FLAGS$n_units,
    # the first layer in a model needs to know the shape of the input data
    batch_input_shape  = c(FLAGS$batch_size, FLAGS$n_timesteps_x, n_features),
    dropout = FLAGS$dropout,
    recurrent_dropout = FLAGS$recurrent_dropout,
    # by default, an LSTM just returns the final state
    return_sequences = TRUE
  ) %>% time_distributed(layer_dense(units = 1))

model %>%
  compile(
    loss = FLAGS$loss,
    optimizer = optimizer,
    # in addition to the loss, Keras will inform us about current 
    # MSE while training
    metrics = list("mean_squared_error")
  )

history <- model %>% fit(
  x          = X_train,
  y          = y_train,
  validation_data = list(X_valid, y_valid),
  batch_size = FLAGS$batch_size,
  epochs     = FLAGS$n_epochs,
  callbacks = callbacks
)
```

Fit des Trainingssatzes anschauen:
```{r}


pred_train <- model %>%
  predict(X_train, batch_size = FLAGS$batch_size) %>%
  .[, , 1]

# Retransform values to original scale
pred_train <- (pred_train * scale_history + center_history) ^2
compare_train <- df %>% filter(key == "training")

# build a dataframe that has both actual and predicted values
for (i in 1:nrow(pred_train)) {
  varname <- paste0("pred_train", i)
  compare_train <-
    mutate(compare_train,!!varname := c(
      rep(NA, FLAGS$n_timesteps_sprung + i - 1),
      pred_train[i,],
      rep(NA, nrow(compare_train) - FLAGS$n_timesteps_sprung - FLAGS$n_timesteps_y - i + 1)
    ))
}


```

Mittleren Fehler im Trainingssatz berechnen:
```{r}
coln <- colnames(compare_train)[4:ncol(compare_train)]
rmse_train <-
  sapply(coln, 
         function(col){
            rmse(
              compare_train,
              truth = value,
              estimate = !!col,
              na.rm = TRUE
            ) %>% pull(.estimate)
          }
    ) %>% mean()

rmse_train

```

Vorhersagen im Trainingssatz anschauen:
```{r}


ggplot(compare_train, aes(x = index, y = value)) + geom_line() +
  geom_line(aes(y = pred_train1), color = "cyan") +
  geom_line(aes(y = pred_train50), color = "red") +
  geom_line(aes(y = pred_train100), color = "green") +
  geom_line(aes(y = pred_train150), color = "violet") +
  geom_line(aes(y = pred_train200), color = "cyan") +
  geom_line(aes(y = pred_train250), color = "red") +
  geom_line(aes(y = pred_train300), color = "red") +
  geom_line(aes(y = pred_train350), color = "green") +
  geom_line(aes(y = pred_train400), color = "cyan") +
  geom_line(aes(y = pred_train450), color = "red") +
  geom_line(aes(y = pred_train500), color = "green") +
  geom_line(aes(y = pred_train550), color = "violet") +
  geom_line(aes(y = pred_train600), color = "cyan") +
  geom_line(aes(y = pred_train650), color = "red") +
  geom_line(aes(y = pred_train700), color = "red") +
  geom_line(aes(y = pred_train750), color = "green") +
  ggtitle("Predictions on the training set")


```

Nochmal das Gleiche (Vorhersagen, Fehler berechnen) für den Testdatensatz:
```{r}


pred_test <- model %>%
  predict(X_test, batch_size = FLAGS$batch_size) %>%
  .[, , 1]

# Retransform values to original scale
pred_test <- (pred_test * scale_history + center_history) ^2
pred_test[1:10, 1:5] %>% print()
compare_test <- df %>% filter(key == "testing")

# build a dataframe that has both actual and predicted values
for (i in 1:nrow(pred_test)) {
  varname <- paste0("pred_test", i)
  compare_test <-
    mutate(compare_test,!!varname := c(
      rep(NA, FLAGS$n_timesteps_sprung + i - 1),
      pred_test[i,],
      rep(NA, nrow(compare_test) - FLAGS$n_timesteps_sprung - FLAGS$n_timesteps_y - i + 1)
    ))
}

coln <- colnames(compare_test)[4:ncol(compare_test)]
rmse_test<-
  sapply(coln, 
         function(col){
            rmse(
              compare_test,
              truth = value,
              estimate = !!col,
              na.rm = TRUE
            ) %>% pull(.estimate)
          }
    ) %>% mean()

rmse_test

```
Und Plotten für den Testsatz:

```{r}


ggplot(compare_test, aes(x = index, y = value)) + geom_line() +
  geom_line(aes(y = pred_test1), color = "cyan") +
  geom_line(aes(y = pred_test50), color = "red") +
  geom_line(aes(y = pred_test100), color = "green") +
  geom_line(aes(y = pred_test150), color = "violet") +
  geom_line(aes(y = pred_test200), color = "cyan") +
  geom_line(aes(y = pred_test250), color = "red") +
  geom_line(aes(y = pred_test300), color = "green") +
  geom_line(aes(y = pred_test350), color = "cyan") +
  geom_line(aes(y = pred_test400), color = "red") +
  geom_line(aes(y = pred_test450), color = "green") +  
  geom_line(aes(y = pred_test500), color = "cyan") +
  geom_line(aes(y = pred_test550), color = "violet") +
  ggtitle("Predictions on test set")


```

Zum Vergleich ein lineares Modell
--------------------------------
Wir erzeugen 12 separate Modelle (-> direkte Methode)
```{r}
lm_modelle <- list()
x_train_tbl <- as_tibble(X_train[ , , 1])
colnames(x_train_tbl) <- make.names(paste("X", 1:FLAGS$n_timesteps_x, sep = " "))
for (i in 1:n_timesteps_y){
  temp_tbl <- x_train_tbl %>% mutate(y = y_train[ , i, 1])
  lm_modelle[[i]] <- caret::train(
    y ~ .,
    data = temp_tbl,
    method = "glm",
    preProcess = c("center", "scale")
  )
}
```

Vorhersagen für Testsatz treffen:
```{r}
# X-Daten aus Testsatz als tibble:
x_test_tbl <- as_tibble(X_test[ , , 1])
colnames(x_test_tbl) <- make.names(paste("X", 1:FLAGS$n_timesteps_x, sep = " "))

# 12 Vorhersagen treffen
vorhersagen_test_lm <- sapply(lm_modelle, function(lm_modell){
  predict(lm_modell, x_test_tbl)
})

# Retransform values to original scale
vorhersagen_test_lm <- (vorhersagen_test_lm * scale_history + center_history) ^2
vorhersagen_test_lm[1:10, 1:5] %>% print()
```

Auswertung:
```{r}
# build a dataframe that has both actual and predicted values
vergleich_test_lm <- df %>% filter(key == "testing")
for (i in 1:nrow(vorhersagen_test_lm)) {
  varname <- paste0("VorhersageAus", i)
  vergleich_test_lm <-
    mutate(vergleich_test_lm,!!varname := c(
      rep(NA, FLAGS$n_timesteps_sprung + i - 1),
      vorhersagen_test_lm[i,],
      rep(NA, nrow(vergleich_test_lm) - FLAGS$n_timesteps_sprung - FLAGS$n_timesteps_y - i + 1)
    ))
}

coln <- colnames(vergleich_test_lm)[4:ncol(vergleich_test_lm)]
rmse_test_lm<-
  sapply(coln, 
         function(col){
            rmse(
              vergleich_test_lm,
              truth = value,
              estimate = !!col,
              na.rm = TRUE
            ) %>% pull(.estimate)
          }
    ) %>% mean()

rmse_test_lm
```
Und Plotten für den Testsatz (noch mit linearem Modell):

```{r}


ggplot(vergleich_test_lm, aes(x = index, y = value)) + geom_line() +
  geom_line(aes(y = VorhersageAus1), color = "cyan") +
  geom_line(aes(y = VorhersageAus50), color = "red") +
  geom_line(aes(y = VorhersageAus100), color = "green") +
  geom_line(aes(y = VorhersageAus150), color = "violet") +
  geom_line(aes(y = VorhersageAus200), color = "cyan") +
  geom_line(aes(y = VorhersageAus250), color = "red") +
  geom_line(aes(y = VorhersageAus300), color = "green") +
  geom_line(aes(y = VorhersageAus350), color = "cyan") +
  geom_line(aes(y = VorhersageAus400), color = "red") +
  geom_line(aes(y = VorhersageAus450), color = "green") +  
  geom_line(aes(y = VorhersageAus500), color = "cyan") +
  geom_line(aes(y = VorhersageAus550), color = "violet") +
  ggtitle("Vorhersage mit lm auf Testsatz")


```

Zum Vergleich ein Regressionswald
---------------------------------
Wir erzeugen 12 separate Modelle (-> direkte Methode)
```{r}
rw_modelle <- list()

# Wurden oben schon so erzeugt:
  # x_train_tbl <- as_tibble(X_train[ , , 1])
  # colnames(x_train_tbl) <- make.names(paste("X", 1:FLAGS$n_timesteps, sep = " "))

for (i in 1:n_timesteps_y){
  rw_modelle[[i]] <- caret::train(
    y = y_train[ , i, 1],
    x = as.matrix(x_train_tbl),
    method = "rf",
    .ntree = 40,
    tuneGrid = expand.grid(.mtry = 5),
    trControl = trainControl(method = "none")
  )
}
```

Auswertung Training:
```{r}
# Oben schon erstellt:
  # X-Daten aus Testsatz als tibble:
  # x_test_tbl <- as_tibble(X_test[ , , 1])
  # colnames(x_test_tbl) <- make.names(paste("X", 1:FLAGS$n_timesteps, sep = " "))

# 12 Vorhersagen treffen
vorhersagen_train_rw <- sapply(rw_modelle, function(rw_modell){
  predict(rw_modell, x_train_tbl)
})

# Retransform values to original scale
vorhersagen_train_rw <- (vorhersagen_train_rw * scale_history + center_history) ^2
vorhersagen_train_rw[1:10, 1:5] %>% print()

# build a dataframe that has both actual and predicted values
vergleich_train_rw <- df %>% filter(key == "training")
for (i in 1:nrow(vorhersagen_train_rw)) {
  varname <- paste0("VorhersageAus", i)
  vergleich_train_rw <-
    mutate(vergleich_train_rw, !!varname := c(
      rep(NA, FLAGS$n_timesteps_sprung + i - 1),
      vorhersagen_train_rw[i,],
      rep(NA, nrow(vergleich_train_rw) - FLAGS$n_timesteps_sprung - FLAGS$n_timesteps_y - i + 1)
    ))
}

coln <- colnames(vergleich_train_rw)[4:ncol(vergleich_train_rw)]
rmse_train_rw<-
  sapply(coln, 
         function(col){
            rmse(
              vergleich_train_rw,
              truth = value,
              estimate = !!col,
              na.rm = TRUE
            ) %>% pull(.estimate)
          }
    ) %>% mean()

rmse_train_rw
```

Vorhersagen für Testsatz treffen:
```{r}
# Oben schon erstellt:
  # X-Daten aus Testsatz als tibble:
  # x_test_tbl <- as_tibble(X_test[ , , 1])
  # colnames(x_test_tbl) <- make.names(paste("X", 1:FLAGS$n_timesteps, sep = " "))

# 12 Vorhersagen treffen
vorhersagen_test_rw <- sapply(rw_modelle, function(rw_modell){
  predict(rw_modell, x_test_tbl)
})

# Retransform values to original scale
vorhersagen_test_rw <- (vorhersagen_test_rw * scale_history + center_history) ^2
vorhersagen_test_rw[1:10, 1:5] %>% print()
```

Auswertung Testsatz:
```{r}
# build a dataframe that has both actual and predicted values
vergleich_test_rw <- df %>% filter(key == "testing")
for (i in 1:nrow(vorhersagen_test_rw)) {
  varname <- paste0("VorhersageAus", i)
  vergleich_test_rw <-
    mutate(vergleich_test_rw, !!varname := c(
      rep(NA, FLAGS$n_timesteps_sprung + i - 1),
      vorhersagen_test_rw[i,],
      rep(NA, nrow(vergleich_test_rw) - FLAGS$n_timesteps_sprung - FLAGS$n_timesteps_y - i + 1)
    ))
}

coln <- colnames(vergleich_test_rw)[4:ncol(vergleich_test_rw)]
rmse_test_rw<-
  sapply(coln, 
         function(col){
            rmse(
              vergleich_test_rw,
              truth = value,
              estimate = !!col,
              na.rm = TRUE
            ) %>% pull(.estimate)
          }
    ) %>% mean()

rmse_test_rw
```
Und Plotten für den Testsatz (noch mit Regressionswald):

```{r}


ggplot(vergleich_test_rw, aes(x = index, y = value)) + geom_line() +
  geom_line(aes(y = VorhersageAus1), color = "cyan") +
  geom_line(aes(y = VorhersageAus50), color = "red") +
  geom_line(aes(y = VorhersageAus100), color = "green") +
  geom_line(aes(y = VorhersageAus150), color = "violet") +
  geom_line(aes(y = VorhersageAus200), color = "cyan") +
  geom_line(aes(y = VorhersageAus250), color = "red") +
  geom_line(aes(y = VorhersageAus300), color = "green") +
  geom_line(aes(y = VorhersageAus350), color = "cyan") +
  geom_line(aes(y = VorhersageAus400), color = "red") +
  geom_line(aes(y = VorhersageAus450), color = "green") +  
  geom_line(aes(y = VorhersageAus500), color = "cyan") +
  geom_line(aes(y = VorhersageAus550), color = "violet") +
  ggtitle("Vorhersagen für Testsatz")


```

Noch eine Idee: Einstufiges Netz iterieren
==========================================

```{r}

```

```{r}
# create the model
modell_einstufig <- keras_model_sequential()

# add layers
# we have just two, the LSTM and the time_distributed 
modell_einstufig %>%
  layer_lstm(
    units = FLAGS$n_units,
    # the first layer in a model needs to know the shape of the input data
    batch_input_shape  = c(FLAGS$batch_size, FLAGS$n_timesteps_x, n_features),
    dropout = FLAGS$dropout,
    recurrent_dropout = FLAGS$recurrent_dropout,
    # by default, an LSTM just returns the final state
    return_sequences = FALSE
  ) %>% layer_dense(units = 1)

modell_einstufig %>%
  compile(
    loss = FLAGS$loss,
    optimizer = optimizer,
    # in addition to the loss, Keras will inform us about current 
    # MSE while training
    metrics = list("mean_squared_error")
  )

history_einstufig <- modell_einstufig %>% fit(
  x          = X_train,
  y          = y_train[ , 1, 1],
  validation_data = list(X_valid, y_valid[ ,1 ,1]),
  batch_size = FLAGS$batch_size,
  epochs     = FLAGS$n_epochs,
  callbacks = callbacks
)
```

Fehler des Fit berechnen:

```{r}
pred_train_einstufig <- modell_einstufig %>%
  predict(X_train, batch_size = FLAGS$batch_size) 

# Die neueste Vorhersage an X anheften und dafür den ältesten Wert rausschmeißen
hilf_X <- cbind(
  X_train[ , 2:dim(X_train)[2], 1],
  pred_train_einstufig)
dim(hilf_X) <- c(dim(hilf_X), 1)
for (i in 2:FLAGS$n_timesteps_y){
  # Neue Vorhersage an pred_test_einstufig anheften
  pred_train_einstufig <- cbind(
    pred_train_einstufig,
    predict(modell_einstufig,
            hilf_X,
            batch_size = FLAGS$batch_size)
  )
  # hilf_X wieder eins weiterrücken lassen
  hilf_X <- cbind(
    hilf_X[ , 2:dim(hilf_X)[2], 1],
    pred_train_einstufig[ , dim(pred_train_einstufig)[2]])
  dim(hilf_X) <- c(dim(hilf_X), 1)
}

# Retransform values to original scale
pred_train_einstufig <- (pred_train_einstufig * scale_history + center_history) ^2
pred_train_einstufig[1:10, 1:5] %>% print()
compare_train_einstufig <- df %>% filter(key == "training")

# build a dataframe that has both actual and predicted values
for (i in 1:nrow(pred_train_einstufig)) {
  varname <- paste0("pred_train", i)
  compare_train_einstufig <-
    mutate(compare_train_einstufig,!!varname := c(
      rep(NA, FLAGS$n_timesteps_sprung + i - 1),
      pred_train_einstufig[i,],
      rep(NA, nrow(compare_train_einstufig) - FLAGS$n_timesteps_sprung - FLAGS$n_timesteps_y - i + 1)
    ))
}

coln <- colnames(compare_train_einstufig)[4:ncol(compare_train_einstufig)]
rmse_train_einstufig<-
  sapply(coln, 
         function(col){
            rmse(
              compare_train_einstufig,
              truth = value,
              estimate = !!col,
              na.rm = TRUE
            ) %>% pull(.estimate)
          }
    ) %>% mean()

rmse_train_einstufig
```


Vorhersagen und Fehler berechnen:

```{r}
pred_test_einstufig <- modell_einstufig %>%
  predict(X_test, batch_size = FLAGS$batch_size) 

# Die neueste Vorhersage an X anheften und dafür den ältesten Wert rausschmeißen
hilf_X <- cbind(
  X_test[ , 2:dim(X_test)[2], 1],
  pred_test_einstufig)
dim(hilf_X) <- c(dim(hilf_X), 1)
for (i in 2:FLAGS$n_timesteps_y){
  # Neue Vorhersage an pred_test_einstufig anheften
  pred_test_einstufig <- cbind(
    pred_test_einstufig,
    predict(modell_einstufig,
            hilf_X,
            batch_size = FLAGS$batch_size)
  )
  # hilf_X wieder eins weiterrücken lassen
  hilf_X <- cbind(
    hilf_X[ , 2:dim(hilf_X)[2], 1],
    pred_test_einstufig[ , dim(pred_test_einstufig)[2]])
  dim(hilf_X) <- c(dim(hilf_X), 1)
}

# Retransform values to original scale
pred_test_einstufig <- (pred_test_einstufig * scale_history + center_history) ^2
pred_test_einstufig[1:10, 1:5] %>% print()
compare_test_einstufig <- df %>% filter(key == "testing")

# build a dataframe that has both actual and predicted values
for (i in 1:nrow(pred_test_einstufig)) {
  varname <- paste0("pred_test", i)
  compare_test_einstufig <-
    mutate(compare_test_einstufig,!!varname := c(
      rep(NA, FLAGS$n_timesteps_sprung + i - 1),
      pred_test_einstufig[i,],
      rep(NA, nrow(compare_test_einstufig) - FLAGS$n_timesteps_sprung - FLAGS$n_timesteps_y - i + 1)
    ))
}

coln <- colnames(compare_test_einstufig)[4:ncol(compare_test_einstufig)]
rmse_test_einstufig<-
  sapply(coln, 
         function(col){
            rmse(
              compare_test_einstufig,
              truth = value,
              estimate = !!col,
              na.rm = TRUE
            ) %>% pull(.estimate)
          }
    ) %>% mean()

rmse_test_einstufig
```


Eigentlich sollten wir beim LSTM-Modell nur auf die letzte Vorhersage schauen
=============================================================================
```{r}
rmse_letzter_wert <- function(echt, vorhersage){
  # vorhersage sowas wie vorhersage_test_lm oder pred_test
  # sucht alle Werte raus, die als letztes von den einzelnen Vorhersagereihen rauskamen.
  # da hat also der Versteckte Zustand am meisten arbeiten müssen.

  # anzahl der Werte, die zu weit vorn liegen, um mal als n_timestep_y ter Wert vorhergesagt zu werden
  k <- FLAGS$n_timesteps_sprung + FLAGS$n_timesteps_y
  
  abgespeckt <- echt[(k + 1) : (k + dim(vorhersage)[1])]
  ModelMetrics::rmse(
    abgespeckt,
    vorhersage[, FLAGS$n_timesteps_y]
  )
}

rmse_letzter_wert_lm <- rmse_letzter_wert(vergleich_test_lm$value, vorhersagen_test_lm)
rmse_letzter_wert_rw <- rmse_letzter_wert(vergleich_test_rw$value, vorhersagen_test_rw)
rmse_letzter_wert_rnn <- rmse_letzter_wert(compare_test$value, pred_test)
rmse_letzter_wert_rnn_einstufig <- rmse_letzter_wert(compare_test_einstufig$value, pred_test_einstufig)
  
rmse_letzter_wert_lm 
rmse_letzter_wert_rw
rmse_letzter_wert_rnn
rmse_letzter_wert_rnn_einstufig

```
Und zum Vergleich die ersten Werte vergleichen:
```{r}
rmse_bestimmter_wert <- function(echt, vorhersage, i){
  # vorhersage sowas wie vorhersage_test_lm oder pred_test
  # sucht alle Werte raus, die als i-tes von den einzelnen Vorhersagereihen rauskamen.

  # anzahl der Werte, die zu weit vorn liegen, um mal als i ter Wert vorhergesagt zu werden
  k <- FLAGS$n_timesteps_sprung + i
  
  abgespeckt <- echt[(k + 1) : (k + dim(vorhersage)[1])]
  ModelMetrics::rmse(
    abgespeckt,
    vorhersage[, i]
  )
}

rmse_erster_wert_lm <- rmse_bestimmter_wert(vergleich_test_lm$value, vorhersagen_test_lm, 1)
rmse_erster_wert_rw <- rmse_bestimmter_wert(vergleich_test_rw$value, vorhersagen_test_rw, 1)
rmse_erster_wert_rnn <- rmse_bestimmter_wert(compare_test$value, pred_test, 1)
rmse_erster_wert_rnn_einstufig <- rmse_bestimmter_wert(compare_test_einstufig$value, pred_test_einstufig, 1)
  
rmse_erster_wert_lm 
rmse_erster_wert_rw
rmse_erster_wert_rnn
rmse_erster_wert_rnn_einstufig
```

Abspeichern

```{r}
save(rmse_letzter_wert_lm ,
rmse_letzter_wert_rw,
rmse_letzter_wert_rnn,
rmse_erster_wert_lm ,
rmse_erster_wert_rw,
rmse_erster_wert_rnn,
rmse_erster_wert_rnn_einstufig,
FLAGS,
file = paste("Ergebnisse_rmse_und_FLAGS", stringr::str_replace_all(as.character(now()), ":", "_"))
)
```


Zur Zusammenfassung die RMSEs der gesamten Trainings und Tests

```{r}
print("--Fits:")
rmse_train # vom ursprünglichen LSTM-Netz
rmse_train_einstufig
rmse_train_rw
#rmse_train_lm


print("--Tests")
rmse_test # vom ursprünglichen LSTM-Netz
rmse_test_einstufig
rmse_test_lm
rmse_test_rw
```

