{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction","metadata":{"_uuid":"16e349d9-34ae-410f-bf31-d0ec20919385","_cell_guid":"7f209f66-6ac3-4777-a1a6-a9c01f46d5eb","trusted":true}},{"cell_type":"markdown","source":"**Using the \"Hash-Trick\": Calculate Fingerprints for Molecules and build a neural network for prediction of the binding affinity.**\n\nLink to the competition and data: https://www.kaggle.com/competitions/leash-BELKA/overview\n\n**Finding a good topology for the net still poses a big challenge.**\n\n**Since the dataset is too big, we need to provide a data stream.\nI thought it might be better to prepare TFRecord-Files to speed up the data supply.\nBut the data is even too much for my 20GB disc memory on Kaggle. So using a datastream from the provided files may be the only option to train on all of the data.**\n\n**One can try to use TPUs instead of CPU/GPU. But one may end up waiting in line. (The TPU-code may be commented.)**\n\n**IDEAS TO IMPROVE:**\n- Search for pretrained nets online. (There are many publications on this subject.)\n- Use Graph Neural Networks\n- Use other finger prints (e.g. 3D-finger prints)\n- Build three independent models: one for each target protein. (May be much easier to learn separate interaction patterns.) (---> Already done! See \"split_model()\".)\n\n**Questions:**\n- How to set float64-policy?\n- How to properly use tf.py_function\n- How to properly use GPU?","metadata":{"_uuid":"b7536b3d-5a91-43f6-802c-8b1f08d25aff","_cell_guid":"248d3ff4-e444-4cd2-98f2-e0da59025f83","trusted":true}},{"cell_type":"markdown","source":"## Switches:","metadata":{"_uuid":"34e0588b-d3e4-4aba-8053-2f66850a54b3","_cell_guid":"d4983027-0d65-4d73-a2af-0902993fc304","trusted":true}},{"cell_type":"code","source":"# If submitting this file, different parameters will be used\nsubmit = True","metadata":{"_uuid":"e59a1d70-dc28-4397-9c8d-fdbe83653f43","_cell_guid":"94da54f8-66e9-4950-bf87-ff2cedd94039","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:15.748452Z","iopub.execute_input":"2024-06-19T11:10:15.748849Z","iopub.status.idle":"2024-06-19T11:10:15.753458Z","shell.execute_reply.started":"2024-06-19T11:10:15.748810Z","shell.execute_reply":"2024-06-19T11:10:15.752317Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{"_uuid":"b1d62873-4932-4b49-828c-8b5241f2de4f","_cell_guid":"a34151a7-6e5f-4239-b47f-93928864743b","trusted":true}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nimport sys\n\n# rdkit helps generating characteristics of molecules:\nif submit:\n    !pip install rdkit  --no-dependencies\nelse:\n    # only install if not installed anymore\n    if not os.path.isdir('/kaggle/working/mysitepackages'):\n        # it was important to use \"--no-dependencies\" Otherwise submissions would not work anymore!!\n        !pip install rdkit  --no-dependencies --target=/kaggle/working/mysitepackages\n    sys.path.append('/kaggle/working/mysitepackages')\nimport rdkit\nimport rdkit.Chem as Chem\nfrom rdkit.Chem import AllChem\n\ngpu_name = tf.test.gpu_device_name()\nif \"GPU\" not in gpu_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(gpu_name))","metadata":{"_uuid":"ffc73950-f2c2-4760-af83-8dbbcdb6119f","_cell_guid":"a981202a-46fb-438d-8b0f-69ac77fa3fd2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:15.803024Z","iopub.execute_input":"2024-06-19T11:10:15.803434Z","iopub.status.idle":"2024-06-19T11:10:15.814277Z","shell.execute_reply.started":"2024-06-19T11:10:15.803399Z","shell.execute_reply":"2024-06-19T11:10:15.813116Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"GPU device not found\nFound GPU at: \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Select Hyperparameters","metadata":{"_uuid":"8a6fc190-83af-463a-9744-c0ed1f8122ea","_cell_guid":"b74515b0-a32f-4727-8d9d-ab8b1a608960","trusted":true}},{"cell_type":"code","source":"# Parameters for testing (small numbers):\n\nN_BITS_FINGERPRINT = 1024 # for ECFP-Fingerprint\nN_RADIUS = 4 # for ECFP-Fingerprint\nBATCH_SIZE = 25\nN_TRAIN = 5000#-1 # set to -1 for \"all\"\nN_TEST = 1000#-1 # set to -1 for \"all\"\nN_EPOCHS = 15\nWITH_DROPOUT = False\nDROPOUT_RATE = 0.05\n#ACTIVATION = 'relu'\nACTIVATION = tf.keras.layers.LeakyReLU(negative_slope=0.01)\nHIDDEN_NEURONS = [500, 5] #Numbers of neurons per internal layer:\n\n# Parameters for submissions (larger numbers):\nif submit:\n    BATCH_SIZE = 8000 # should be big, if (not RESAMPLE_INSTEAD_OF_REWEIGHT) in order to have at least some positive samples in the batch?\n    N_BITS_FINGERPRINT = 2048 # for ECFP-Fingerprint\n    N_RADIUS = 4 # for ECFP-Fingerprint\n    N_TEST = -1 # -1 means \"all\"\n    N_TRAIN = 5600000\n    N_EPOCHS = 25\n    HIDDEN_NEURONS = [251, 15]\n    #ACTIVATION = 'relu'\n    ACTIVATION = tf.keras.layers.LeakyReLU(negative_slope=0.01)\n    WITH_DROPOUT = False\n    DROPOUT_RATE = 0.005 # only needed if WITH_DROPOUT\n","metadata":{"_uuid":"b7d1f2ef-43b3-4433-9d96-a79cbbd08bc9","_cell_guid":"43a7af1e-aff5-435d-af8b-aa9a9fe9f7fe","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:15.847111Z","iopub.execute_input":"2024-06-19T11:10:15.847532Z","iopub.status.idle":"2024-06-19T11:10:15.856254Z","shell.execute_reply.started":"2024-06-19T11:10:15.847497Z","shell.execute_reply":"2024-06-19T11:10:15.854828Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/leash-BELKA/train.csv'\ntest_path = '/kaggle/input/leash-BELKA/test.csv'","metadata":{"_uuid":"bc8f6a48-f758-4e4e-af0f-cefc21c59e0b","_cell_guid":"68830606-f3bc-4aad-987b-41b5e813670d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:15.882029Z","iopub.execute_input":"2024-06-19T11:10:15.882445Z","iopub.status.idle":"2024-06-19T11:10:15.887472Z","shell.execute_reply.started":"2024-06-19T11:10:15.882412Z","shell.execute_reply":"2024-06-19T11:10:15.886285Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"## Old version (slow):\n#def generate_ecfp(molecule, radius=N_RADIUS, bits=N_BITS_FINGERPRINT):\n#    return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))\n\n## New verion (3 times faster) (used in \"Simple Net 2.ipynb\"):\ndef ecfp(smile, radius=N_RADIUS, nBits=N_BITS_FINGERPRINT):\n    \"\"\" creates a list containing the fingerprint\n    accepts a bytes-string as smile\n    \"\"\"\n    mol = Chem.MolFromSmiles(smile.numpy())\n    fp_list = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits).ToList()\n    return fp_list\n\n## Would it be more efficient to use bools? (But the following code throws an error.)\n#def ecfp_bool(smile, radius=N_RADIUS, nBits=N_BITS_FINGERPRINT):\n#    \"\"\" creates a tf.constant containing the fingerprint\n#    \"\"\"\n#    ...\n#    return tf.equals(..., 1)\n#    )","metadata":{"_uuid":"d0f596a9-1568-4e60-bb3e-b222af1f7524","_cell_guid":"65aa0b07-9438-450d-8d0a-f7835b7a1bee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:15.946280Z","iopub.execute_input":"2024-06-19T11:10:15.947121Z","iopub.status.idle":"2024-06-19T11:10:15.953202Z","shell.execute_reply.started":"2024-06-19T11:10:15.947081Z","shell.execute_reply":"2024-06-19T11:10:15.951966Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"## Functions for reading csv","metadata":{"_uuid":"4c4169e7-2d70-4b9d-98aa-9ae7d33b9165","_cell_guid":"f29c83fa-432a-4ed1-a2e3-33f95bc2376f","trusted":true}},{"cell_type":"code","source":"@tf.py_function(Tout=tf.int32)\ndef get_fp(smile, radius=N_RADIUS, nBits=N_BITS_FINGERPRINT):\n    fp_list = ecfp(smile, radius=N_RADIUS, nBits=N_BITS_FINGERPRINT)\n    fp = tf.constant(fp_list, shape=(nBits,), dtype=tf.int32)\n    return fp\n\ndef parse_fp_oneHot(x):\n    oneHot = tf.math.equal(x['protein_name'], ['BRD4', 'sEH', 'HSA'])\n    oneHot = tf.reshape(oneHot,(3,))\n    fp = get_fp(x['molecule_smiles'])\n    fp.set_shape((N_BITS_FINGERPRINT))\n    return {'fp': fp, 'oneHot': oneHot}\n\ndef parse_fp_oneHot_binds(x,y):\n    #tf.print(\"tf print \", y, type(y))\n    #print(\"Normal  print \", y, type(y))\n    y = tf.reshape(y, shape=(1,))\n    y = tf.cast(y, tf.int32)\n    #tf.print(\"2 tf print \", y, type(y))\n    #print(\"2 Normal  print \", y, type(y))\n    return parse_fp_oneHot(x), y\n\n","metadata":{"_uuid":"6db0f3e6-5c32-4078-aeba-4462c96e904f","_cell_guid":"fd6499f4-6b53-4abc-b30a-8e9988960b3a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:16.039912Z","iopub.execute_input":"2024-06-19T11:10:16.040792Z","iopub.status.idle":"2024-06-19T11:10:16.048694Z","shell.execute_reply.started":"2024-06-19T11:10:16.040752Z","shell.execute_reply":"2024-06-19T11:10:16.047445Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"## Get Dataset:","metadata":{"_uuid":"88e01c2d-0b9b-4654-84f7-e86c08d3e127","_cell_guid":"4c6e70dd-38cc-4e40-80c5-ec4cc0378492","trusted":true}},{"cell_type":"code","source":"def get_ds_csv(csv_path, batch_size, n_samples, labeled=True, repeat=False):\n    \"\"\" n_samples=-1 means \"take all\"\n    \"\"\"\n    if labeled:\n        ds = tf.data.experimental.make_csv_dataset(\n            csv_path,\n            batch_size=4, # arbitrary .. ´will be overridden later on\n            shuffle=False,\n            num_epochs=1, # to prevent repeat()\n            label_name='binds')\n    else:\n        ds = tf.data.experimental.make_csv_dataset(\n            csv_path,\n            batch_size=4,   # arbitrary .. ´will be overridden later on\n            num_epochs=1, # to prevent repeat()\n            shuffle=False)\n    ds = ds.unbatch()\n    if n_samples!=-1:\n        ds = ds.take(n_samples)\n    if labeled:\n        ds = ds.map(parse_fp_oneHot_binds)\n    else:\n        ds = ds.map(parse_fp_oneHot)\n    if repeat:\n        ds = ds.repeat()\n    ds = ds.batch(batch_size)\n    return ds\n\nds = get_ds_csv(train_path, batch_size=BATCH_SIZE, n_samples=N_TRAIN, repeat=True)\n\n#for elem in ds.take(1):\n#    print(elem)\n#    print()","metadata":{"_uuid":"1fcef628-9771-45e1-a207-bd19cb3fb8ac","_cell_guid":"97e2592d-4e61-4631-8a2a-6ae631b98f0e","execution":{"iopub.status.busy":"2024-06-19T11:10:16.073185Z","iopub.execute_input":"2024-06-19T11:10:16.073602Z","iopub.status.idle":"2024-06-19T11:10:16.215624Z","shell.execute_reply.started":"2024-06-19T11:10:16.073565Z","shell.execute_reply":"2024-06-19T11:10:16.214465Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks","metadata":{"_uuid":"ec59d1f8-7ae7-4da5-9631-f56600fdf0a0","_cell_guid":"d79b9beb-abee-49c9-a9a5-cb9e7f4e1022","trusted":true}},{"cell_type":"code","source":"class TerminateAndBackup(tf.keras.callbacks.Callback):\n    def __init__(self, \n                 directory=\"/kaggle/working/temp\"):\n        super().__init__()\n        self.backup_file = directory+\".weights.h5\"\n        try:\n            os.stat(directory)\n        except:\n            os.mkdir(directory) \n\n    def on_epoch_begin(self, epoch, logs=None):\n        #Save weights in the beginning of epoch\n        self.model.save_weights(self.backup_file, overwrite=True)\n\n    def on_train_batch_end(self, batch, logs=None):\n        logs = logs or {}\n        loss = logs.get('loss')\n        if loss is not None:\n            # Check if we have NaN or Inf\n            if np.isnan(loss) or np.isinf(loss):\n                print('Stopping learning --- ')\n                model.load_weights(self.backup_file)\n                self.model.stop_training  = True\nterminate_and_backup = TerminateAndBackup()\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.2,\n                              patience=5, min_lr=0.001)","metadata":{"_uuid":"ac5f8837-c8d7-4200-be57-58a543b92a29","_cell_guid":"0fbd6fdc-1b2a-4fd1-a825-434baa052557","execution":{"iopub.status.busy":"2024-06-19T11:10:16.218395Z","iopub.execute_input":"2024-06-19T11:10:16.219286Z","iopub.status.idle":"2024-06-19T11:10:16.228062Z","shell.execute_reply.started":"2024-06-19T11:10:16.219214Z","shell.execute_reply":"2024-06-19T11:10:16.226736Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"## Prepare training weights","metadata":{"_uuid":"0569f69f-9302-4b04-8766-7d91e259e2a3","_cell_guid":"7a291dc3-44a4-4138-8c1f-c750f0c2e906","trusted":true}},{"cell_type":"code","source":"# Calculate proportion of positive binds\n# (Important for training weights)\nif submit:\n    n_consider = min(N_TRAIN, 500000)\nelse:\n    n_consider = min(N_TRAIN, 30000)\n\ninitial_state = (0,0)\ndef combined_reduce(state, data):\n    count, sum_binds = state\n    count += 1\n    sum_binds += int(data[1])\n    return count, sum_binds\nn_samples, n_binds = ds.unbatch().take(n_consider).reduce(initial_state, combined_reduce)\nn_binds = n_binds.numpy()[0]\nn_samples = n_samples.numpy()\nprint(f' {n_binds} of {n_samples} are positive')\nbinds_rate = n_binds / n_samples\nprint(f'bind rate = {binds_rate}')","metadata":{"_uuid":"6c38094a-70df-4a94-8c8b-3c4d44f23cfa","_cell_guid":"865a49f1-5ab1-43dc-86e4-4bed3d8f5b3a","execution":{"iopub.status.busy":"2024-06-19T11:10:16.230024Z","iopub.execute_input":"2024-06-19T11:10:16.230355Z","iopub.status.idle":"2024-06-19T11:10:21.602525Z","shell.execute_reply.started":"2024-06-19T11:10:16.230328Z","shell.execute_reply":"2024-06-19T11:10:21.601445Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":" 7 of 5000 are positive\nbind rate = 0.0014\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Split-Model Topology","metadata":{}},{"cell_type":"code","source":"def splitted_model():\n    ### creates single models for each target protein and concatenates them together\n    \n    def model_for_one_protein():\n        fp_input = tf.keras.Input((N_BITS_FINGERPRINT,), name='fp')\n        x = fp_input\n        for N in HIDDEN_NEURONS:\n            if WITH_DROPOUT:\n                x = tf.keras.layers.Dropout(DROPOUT_RATE)(x)\n            x = tf.keras.layers.Dense(N, activation=ACTIVATION)(x)\n        output = tf.keras.layers.Dense(1)(x)\n        return tf.keras.Model(fp_input, output)\n            \n    fp_input = tf.keras.Input((N_BITS_FINGERPRINT,), name='fp')\n    protein_input = tf.keras.Input((3,), name='oneHot')\n    model_BRD4 = model_for_one_protein()(fp_input)\n    model_HSA  = model_for_one_protein()(fp_input)\n    model_sEH  = model_for_one_protein()(fp_input)\n    single_models = tf.keras.layers.Concatenate(axis=1)([model_BRD4, model_HSA, model_sEH])\n\n    output = tf.keras.layers.Dot(axes=[1,1])([protein_input, single_models])\n    model = tf.keras.Model(inputs=[fp_input, protein_input], outputs=output)\n    \n    # gamma=0 is just the normal BinaryCrossentropy. (But that one does not support training weights alpha.)\n    loss_fn = tf.keras.losses.BinaryFocalCrossentropy(\n        gamma=0, from_logits=True, apply_class_balancing=True, alpha=1-binds_rate)\n    optimizer = tf.keras.optimizers.Adam(epsilon=1e-10)\n    model.compile(optimizer=\"adam\",\n                  loss=loss_fn,\n                  metrics=['accuracy'])\n    return model","metadata":{"_uuid":"6845873f-b411-4e61-90f9-7a095f23495a","_cell_guid":"e4a4e250-19e4-4437-ba28-e7fa8fde392b","execution":{"iopub.status.busy":"2024-06-19T11:10:21.605000Z","iopub.execute_input":"2024-06-19T11:10:21.605530Z","iopub.status.idle":"2024-06-19T11:10:21.616176Z","shell.execute_reply.started":"2024-06-19T11:10:21.605491Z","shell.execute_reply":"2024-06-19T11:10:21.615063Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"# if TPU is available:\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#tf.tpu.experimental.initialize_tpu_system(tpu)\n#tpu_strategy = tf.distribute.TPUStrategy(tpu)\n#with tpu_strategy.scope():\n\n#tf.keras.config.set_floatx('float64') # should use a \"DType_Policy\" instead\n\nmirrored_strategy = tf.distribute.MirroredStrategy()\nwith mirrored_strategy.scope():\n    #model = straight_model()\n    model = splitted_model()\n    #print(model.summary())\n    model.fit(ds,\n              epochs=N_EPOCHS,\n              steps_per_epoch=N_TRAIN//BATCH_SIZE\n              #,callbacks=[backup, terminate_on_nan]\n              #,callbacks=[reduce_lr_on_nan]\n              ,callbacks=[terminate_and_backup]\n             )","metadata":{"_uuid":"560efdfc-1031-4065-a500-4cbe1249ba18","_cell_guid":"ed64ab21-d97c-4221-8607-3031a182ab86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:14:16.525305Z","iopub.execute_input":"2024-06-19T11:14:16.525725Z","iopub.status.idle":"2024-06-19T11:14:32.691643Z","shell.execute_reply.started":"2024-06-19T11:14:16.525690Z","shell.execute_reply":"2024-06-19T11:14:32.690508Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.9981 - loss: 0.0106\nEpoch 2/15\n\u001b[1m131/200\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9961 - loss: 0.0032Stopping learning --- \n\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9946 - loss: nan \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Predict on Test Set","metadata":{"_uuid":"d9061a79-ddda-4c29-b1b9-2c2c3051dccb","_cell_guid":"5a6aebf5-3994-4341-bbe4-8fe6038b98ce","trusted":true}},{"cell_type":"code","source":"print(\"Start predicting....\")\ntest_ds = get_ds_csv(test_path, batch_size=215, n_samples=N_TEST, labeled=False)\ny = model.predict(test_ds, verbose=0)\nprint('Done predicting')","metadata":{"_uuid":"2c3636cf-5327-41e5-881e-c6d3f49fd61c","_cell_guid":"dad47fdd-52c5-473d-8625-8b96d0154bee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:41.182864Z","iopub.execute_input":"2024-06-19T11:10:41.183209Z","iopub.status.idle":"2024-06-19T11:10:42.713974Z","shell.execute_reply.started":"2024-06-19T11:10:41.183180Z","shell.execute_reply":"2024-06-19T11:10:42.712678Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Start predicting....\nDone predicting\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Write Submission File","metadata":{"_uuid":"9aad7c31-83d2-4a5f-bd70-a09926be517e","_cell_guid":"3ea9a72d-f805-433f-b23f-07283f4d6fa2","trusted":true}},{"cell_type":"code","source":"import pandas as pd\nfrom scipy.special import expit, logit\n\nyy = y[:,0]\nd = pd.DataFrame({'id': range(len(yy)), 'binds': yy})\nd['id'] = d['id'] + 295246830\nd['binds'] = expit(d['binds'])\nprint(\"Start writing...\")\nd.to_csv('submission.csv', index=False, header=True)\n\nprint(d['binds'].describe())","metadata":{"_uuid":"d7ed4222-6b84-43b2-bd3e-317ab6f02d0b","_cell_guid":"142b4c4e-9860-4927-a19d-9bcaae945cf2","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:42.715615Z","iopub.execute_input":"2024-06-19T11:10:42.715958Z","iopub.status.idle":"2024-06-19T11:10:42.731442Z","shell.execute_reply.started":"2024-06-19T11:10:42.715929Z","shell.execute_reply":"2024-06-19T11:10:42.730069Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Start writing...\ncount    1.000000e+03\nmean     8.858638e-04\nstd      1.703754e-03\nmin      5.677725e-09\n25%      3.669215e-06\n50%      3.252820e-04\n75%      1.128776e-03\nmax      2.256317e-02\nName: binds, dtype: float64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Parquet does not seem to be faster:","metadata":{"_uuid":"1a613f0f-5d4f-42a5-8479-ce53f2e70c3d","_cell_guid":"5ef3dc1a-cd91-4d69-90c4-a4ada8603155","trusted":true}},{"cell_type":"code","source":"#@tf.function # bringt es anscheinend nicht\n#def _parse_parquet(ex):\n#    oneHot = tf.math.equal(ex[b'protein_name'], ['BRD4', 'sEH', 'HSA'])\n#    oneHot   = tf.reshape(oneHot,(3,))\n#    fp = get_fp(ex[b'molecule_smiles'])\n#    return {'fp': fp, 'oneHot': oneHot}\n\n#import timeit\n#import tensorflow_io as tfio\n#ds_csv = test_ds\n#ds_parquet = tfio.IODataset.from_parquet('/kaggle/input/leash-BELKA/test.parquet',columns=[b'molecule_smiles',b'protein_name'])\n#ds_parquet = ds_parquet.map(_parse_parquet)\n#print('CSV: ', timeit.timeit(lambda: model.predict(test_ds.unbatch().take(10000).batch(100)), number=1))\n#print('Par: ', timeit.timeit(lambda: model.predict(ds_parquet.take(10000).batch(100)), number=1))","metadata":{"_uuid":"6aa65f5b-63b3-4a02-88df-4728e1f12c74","_cell_guid":"b4bbf2e2-fb58-4472-97d9-ce3f30d6cbdf","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:42.734810Z","iopub.execute_input":"2024-06-19T11:10:42.735294Z","iopub.status.idle":"2024-06-19T11:10:42.740116Z","shell.execute_reply.started":"2024-06-19T11:10:42.735225Z","shell.execute_reply":"2024-06-19T11:10:42.739041Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"Warum ist es bei 10 nicht wirklich schneller, aber bei 10000 schon und warum bringt es bei 10 nichts, wenn der graph vorher erstellt wird?:","metadata":{"_uuid":"e171f54c-71fc-4da8-b09c-48375e2dc6bc","_cell_guid":"4309c41b-25a7-49fe-aa8b-8e1d5c990a7c","trusted":true}},{"cell_type":"code","source":"#import timeit\n# TensorFlow imports\n#from tensorflow.keras import Input, Model\n#from tensorflow.keras.layers import Flatten, Dense\n## Define the model (Inspired by mnist inputs)\n#model = tf.keras.Sequential()\n#model.add(tf.keras.Input(shape=(28,28,)))\n#model.add(Flatten())\n#model.add(Dense(256,\"relu\"))\n#model.add(Dense(128,\"relu\"))\n#model.add(Dense(256,\"relu\"))\n#model.add(Dense(10,\"softmax\"))\n## Dummy data with MNIST image sizes\n#X = tf.random.uniform([1000, 28, 28])\n## Eager Execution to do inference (Model untrained as we are evaluating speed of inference)\n#eager_modell = model\n#print(\"Eager time:\", timeit.timeit(lambda: eager_modell(X,training=False), number=10))\n#\n##Graph Execution to do inference (Model untrained as we are evaluating speed of inference)\n#graph_modell = tf.function(eager_modell) # Wrap the model with tf.function\n#y = graph_model(X,training=False)\n#print(\"Graph time:\", timeit.timeit(lambda: graph_modell(X,training=False), number=10))","metadata":{"_uuid":"149eb040-83bb-4957-8fff-11a50c649a47","_cell_guid":"50fd5b22-f3a9-485f-8b31-c616058c5248","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-19T11:10:42.741283Z","iopub.execute_input":"2024-06-19T11:10:42.741580Z","iopub.status.idle":"2024-06-19T11:10:42.751051Z","shell.execute_reply.started":"2024-06-19T11:10:42.741554Z","shell.execute_reply":"2024-06-19T11:10:42.749949Z"},"trusted":true},"execution_count":82,"outputs":[]}]}