{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"markdown","source":"**Using the \"Hash-Trick\": Calculate Fingerprints for Molecules and build a neural network for prediction of the binding affinity.**\n\n**Finding a good topology for the net still poses a big challenge.**\n\n**Since the dataset is too big, we need to provide a data stream.\nI thought it might be better to prepare TFRecord-Files to speed up the data supply.\nBut the data is even too much for my 20GB disc memory on Kaggle. So using a datastream from the provided files may be the only option to train on all of the data.**\n\n**One can try to use TPUs instead of CPU/GPU. But one may end up waiting in line. (The TPU-code may be commented.)**\n\n**IDEAS TO IMPROVE:**\n- Search for pretrained nets online. (There are many publications in this subject.)\n- Use Graph Neural Networks\n- Use other finger prints (e.g. 3D-finger prints)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\n\n# rdkit helps generating characteristics of molecules:\n!pip install rdkit\nimport rdkit\nimport rdkit.Chem as Chem\nfrom rdkit.Chem import AllChem\n\ngpu_name = tf.test.gpu_device_name()\nif \"GPU\" not in gpu_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(gpu_name))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:08.383780Z","iopub.execute_input":"2024-06-04T19:56:08.384185Z","iopub.status.idle":"2024-06-04T19:56:22.935545Z","shell.execute_reply.started":"2024-06-04T19:56:08.384154Z","shell.execute_reply":"2024-06-04T19:56:22.934513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Switches:","metadata":{}},{"cell_type":"code","source":"# Original data gets preprocessed and saved into TFRecord files.\n# Otherwise use only csv\nuse_tfRecords = False","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:22.937282Z","iopub.execute_input":"2024-06-04T19:56:22.937561Z","iopub.status.idle":"2024-06-04T19:56:22.941846Z","shell.execute_reply.started":"2024-06-04T19:56:22.937535Z","shell.execute_reply":"2024-06-04T19:56:22.940936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Select Hyperparameters","metadata":{}},{"cell_type":"code","source":"N_BITS_FINGERPRINT = 512\nBATCH_SIZE = 64\nN_TRAIN = BATCH_SIZE * 2000 # set to -1 for \"all\"\nN_TEST = -1 # set to -1 for \"all\"\nN_EPOCHS = 7\n\n#Numbers of neurons per internal layer:\nN_Layer_1 = 100\nN_Layer_2 = 50\nN_Layer_3 = 10\nN_Layer_4 = 5","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:22.942996Z","iopub.execute_input":"2024-06-04T19:56:22.943246Z","iopub.status.idle":"2024-06-04T19:56:22.954556Z","shell.execute_reply.started":"2024-06-04T19:56:22.943225Z","shell.execute_reply":"2024-06-04T19:56:22.953797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions for creating TFRecords File","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/leash-BELKA/train.csv'\ntest_path = '/kaggle/input/leash-BELKA/test.csv'\npreproc_train_path = \"/kaggle/working/train_prepro.tfrecord\"\npreproc_test_path = \"/kaggle/working/test_prepro.tfrecord\"","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:22.956551Z","iopub.execute_input":"2024-06-04T19:56:22.956822Z","iopub.status.idle":"2024-06-04T19:56:22.964810Z","shell.execute_reply.started":"2024-06-04T19:56:22.956783Z","shell.execute_reply":"2024-06-04T19:56:22.964090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_ecfp(molecule, radius=2, bits=N_BITS_FINGERPRINT):\n    return list(AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:22.965766Z","iopub.execute_input":"2024-06-04T19:56:22.966048Z","iopub.status.idle":"2024-06-04T19:56:22.974693Z","shell.execute_reply.started":"2024-06-04T19:56:22.966027Z","shell.execute_reply":"2024-06-04T19:56:22.974020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_preproc_file(path_in, path_out, n_entries = -1):\n    ### Calculates the fingerprint of each molecule\n    ### and saves this into the TFRecords file.\n\n    # The following functions can be used to convert a value to a type compatible\n    # with tf.train.Example.\n    def _bytes_feature(value):\n      \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n      if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n      return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n    def _float_feature(value):\n        \"\"\"Returns a float_list from a float / double.\"\"\"\n        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n    def _int64_feature(value):\n        \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n    \n    def serialize_example(id_,hash_,protein_name,binds=None):\n        features = {\n            'id': _int64_feature(id_),\n            'hash': _bytes_feature(tf.io.serialize_tensor(tf.constant(hash_))),\n            'protein_name': _bytes_feature(str.encode(protein_name)),\n          }\n        if binds!=None:\n            features['binds'] = _int64_feature(binds)\n        example = tf.train.Example(features=tf.train.Features(feature=features))\n        return example.SerializeToString()\n\n    # The actual creation of the file:\n    try:\n        os.remove(path_out)\n    except FileNotFoundError:\n        pass\n    with open(path_in) as f_in, tf.io.TFRecordWriter(path_out) as writer:\n        first_line = f_in.readline() # skip headers\n        labeled = (len(first_line.split(\",\")))==7\n        for i, line in enumerate(f_in):\n            if i==n_entries:\n                break\n            if i % 10000 == 0:\n                print(i, \"examples processed\")\n            features = line.split(\",\")\n            molecule = Chem.MolFromSmiles(features[4])\n            ecfp = generate_ecfp(molecule)\n            if labeled:\n                example = serialize_example(int(features[0]),\n                                        ecfp,\n                                        features[5],\n                                        int(features[6]))\n                writer.write(example)\n            else:\n                example = serialize_example(int(features[0]),\n                                        ecfp,\n                                        features[5])\n                writer.write(example)\n        print('done processing examples')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:22.975781Z","iopub.execute_input":"2024-06-04T19:56:22.976066Z","iopub.status.idle":"2024-06-04T19:56:22.990109Z","shell.execute_reply.started":"2024-06-04T19:56:22.976045Z","shell.execute_reply":"2024-06-04T19:56:22.989318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions for reading the TFRecords","metadata":{}},{"cell_type":"code","source":"def _parse_function(example, label=True):\n    # Set label=False if processing test data.\n    # Parse the input `tf.train.Example` proto using the dictionary:\n    feature_description = {\n      'id':           tf.io.FixedLenFeature([], tf.int64),\n      'hash':         tf.io.FixedLenFeature([], tf.string),\n      'protein_name': tf.io.FixedLenFeature([], tf.string),\n    }\n    if label:\n        feature_description['binds'] = tf.io.FixedLenFeature([1], tf.int64)\n    \n    features = tf.io.parse_single_example(example, feature_description)\n    id_     = features['id']\n    hash_   = tf.io.parse_tensor(features['hash'], out_type=tf.int32)\n    hash_   = tf.reshape(hash_, shape=(N_BITS_FINGERPRINT,))  # needed to bring back the shape to former string-byte\n    protein_name = features['protein_name']\n    if label:\n        return id_, hash_, protein_name, features['binds']\n    else:\n        return id_, hash_, protein_name\n\ndef _parse_hash_oneHot_binds(example_proto):\n    ### Returns only the Fingerprint(hash), the one-Hot-encoding of the protein and the binds-value\n    id_, hash_, protein_name, binds = _parse_function(example_proto)\n    oneHot = tf.math.equal(protein_name, ['BRD4', 'sEH', 'HSA'])\n    oneHot   = tf.reshape(oneHot, (3,))\n    return {'hash': hash_, 'oneHot': oneHot}, binds\n\ndef _parse_hash_oneHot(example_proto):\n    ### Returns only the Fingerprint(hash) and the one-Hot-encoding of the protein\n    id_, hash_, protein_name, = _parse_function(example_proto, label=False)\n    oneHot = tf.math.equal(protein_name, ['BRD4', 'sEH', 'HSA'])\n    oneHot   = tf.reshape(oneHot, (3,))\n    return {'hash': hash_, 'oneHot': oneHot}\n\ndef _parse_hash_binds(example_proto):\n    ### Returns only the Fingerprint(hash) and the binds-value\n    id_, hash_, protein_name, binds = _parse_function(example_proto)\n    return hash_, binds","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:22.991069Z","iopub.execute_input":"2024-06-04T19:56:22.991339Z","iopub.status.idle":"2024-06-04T19:56:23.003498Z","shell.execute_reply.started":"2024-06-04T19:56:22.991317Z","shell.execute_reply":"2024-06-04T19:56:23.002613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions for reading csv","metadata":{}},{"cell_type":"code","source":"@tf.py_function(Tout=tf.int32)\ndef get_fp(smile):\n    mol = Chem.MolFromSmiles(smile.numpy())\n    fp = generate_ecfp(mol)\n    fp = tf.constant(fp, dtype=tf.int32, shape=(N_BITS_FINGERPRINT,))\n    return fp\n\ndef _parse_csv_hash_oneHot_binds(x,y):\n    oneHot = tf.math.equal(x['protein_name'], ['BRD4', 'sEH', 'HSA'])\n    oneHot   = tf.reshape(oneHot,(3,))\n    hash_ = get_fp(x['molecule_smiles'])\n    hash_   = tf.reshape(hash_, shape=(N_BITS_FINGERPRINT,))\n    y = tf.reshape(y, shape=(1,))\n    y = tf.cast(y, tf.int64)\n    return {'hash': hash_, 'oneHot': oneHot}, y\n\ndef _parse_csv_hash_oneHot(x):\n    oneHot = tf.math.equal(x['protein_name'], ['BRD4', 'sEH', 'HSA'])\n    oneHot   = tf.reshape(oneHot,(3,))\n    hash_ = get_fp(x['molecule_smiles'])\n    return {'hash': hash_, 'oneHot': oneHot}","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:23.004654Z","iopub.execute_input":"2024-06-04T19:56:23.005113Z","iopub.status.idle":"2024-06-04T19:56:23.017253Z","shell.execute_reply.started":"2024-06-04T19:56:23.005084Z","shell.execute_reply":"2024-06-04T19:56:23.016503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get Dataset from either csv or TFrecords:","metadata":{}},{"cell_type":"code","source":"def get_ds_tfRecord(csv_path, tfRecords_path, batch_size, n_entries=-1, labeled=True):\n    # creates the tfRecords-File from the csv-File\n    # n_entries=-1 means that all samples are to be taken from the csv\n    \n    # determines automatically if labeled==True: (could be changed!)\n    create_preproc_file(csv_path,\n                        tfRecords_path,\n                        n_entries = n_entries)\n    ds = tf.data.TFRecordDataset(tfRecords_path)\n    if labeled:\n        ds = ds.map(_parse_hash_oneHot_binds)\n    else:\n        ds = ds.map(_parse_hash_oneHot)\n    ds = ds.batch(batch_size)\n    ds = ds.shuffle(2*batch_size)\n    return ds\n\ndef get_ds_csv(csv_path, batch_size, n_samples, labeled=True):\n    ### n_samples=-1 means \"take all\"\n    if labeled:\n        ds = tf.data.experimental.make_csv_dataset(\n            csv_path,\n            batch_size=4, # arbitrary\n            shuffle=False,\n            num_epochs=1, # to prevent repeat()\n            label_name='binds')\n    else:\n        ds = tf.data.experimental.make_csv_dataset(\n            csv_path,\n            batch_size=4,   # arbitrary\n            num_epochs=1, # to prevent repeat()\n            shuffle=False)\n    ds = ds.unbatch()\n    if n_samples!=-1:\n        ds = ds.take(n_samples)\n    if labeled:\n        ds = ds.map(_parse_csv_hash_oneHot_binds)\n    else:\n        ds = ds.map(_parse_csv_hash_oneHot)\n    ds = ds.batch(batch_size)\n    return ds\n\nif use_tfRecords:\n    print('Creating TFRecords file...')\n    ds = get_ds_tfRecord(train_path, preproc_train_path, batch_size=BATCH_SIZE, n_entries=N_TRAIN)\nelse:\n    print('Use CSV')\n    with tf.device('/device:GPU:0'):\n        ds = get_ds_csv(train_path, batch_size=BATCH_SIZE, n_samples=N_TRAIN)\n\n#for elem in ds.take(1):\n#    print(elem)\n#    print(\" \")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:23.018166Z","iopub.execute_input":"2024-06-04T19:56:23.018462Z","iopub.status.idle":"2024-06-04T19:56:23.581394Z","shell.execute_reply.started":"2024-06-04T19:56:23.018392Z","shell.execute_reply":"2024-06-04T19:56:23.580404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## First naive model","metadata":{}},{"cell_type":"code","source":"# Calculate proportion of positive binds\n# (Important for training weights)\nn_samples = ds.unbatch().reduce(0, lambda i,_: i+1).numpy()\nn_binds = ds.unbatch().reduce(0, lambda i, data: i+int(data[1])).numpy()[0]\nprint(f' {n_binds} of {n_samples} are positive')\nbinds_rate = n_binds / n_samples","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:23.584031Z","iopub.execute_input":"2024-06-04T19:56:23.584341Z","iopub.status.idle":"2024-06-04T19:56:23.827857Z","shell.execute_reply.started":"2024-06-04T19:56:23.584315Z","shell.execute_reply":"2024-06-04T19:56:23.826996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Prepare Dataset for training:","metadata":{}},{"cell_type":"code","source":"# if TPU is available:\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#tf.tpu.experimental.initialize_tpu_system(tpu)\n#tpu_strategy = tf.distribute.TPUStrategy(tpu)\n#with tpu_strategy.scope():\n\nmirrored_strategy = tf.distribute.MirroredStrategy()\n\nwith mirrored_strategy.scope():\n    hash_inputs = tf.keras.Input((N_BITS_FINGERPRINT,), name='hash')\n    protein_inputs = tf.keras.Input((3,), name='oneHot')\n    inputs = tf.keras.layers.concatenate([hash_inputs, protein_inputs])\n    x = inputs\n    x = tf.keras.layers.Dense(N_Layer_1, activation=\"sigmoid\")(x)\n    x = tf.keras.layers.Dropout(0.7)(x)\n    x = tf.keras.layers.Dense(N_Layer_2, activation=\"sigmoid\")(x)\n    x = tf.keras.layers.Dropout(0.7)(x)\n    x = tf.keras.layers.Dense(N_Layer_3, activation=\"sigmoid\")(x)\n    x = tf.keras.layers.Dropout(0.7)(x)\n    x = tf.keras.layers.Dense(N_Layer_4, activation=\"sigmoid\")(x)\n    outputs = tf.keras.layers.Dense(1)(x)\n\n    model = tf.keras.Model(inputs=[hash_inputs, protein_inputs], outputs=outputs)\n    #print(model.summary())\n    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n    model.compile(optimizer='adam',\n                  loss=loss_fn,\n                  metrics=['accuracy'])\n    \nmodel.fit(ds, epochs=N_EPOCHS, class_weight={0: 1, 1: 1/binds_rate})","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:23.829150Z","iopub.execute_input":"2024-06-04T19:56:23.829523Z","iopub.status.idle":"2024-06-04T19:56:29.641855Z","shell.execute_reply.started":"2024-06-04T19:56:23.829487Z","shell.execute_reply":"2024-06-04T19:56:29.640977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If you want to continue/retake training:","metadata":{}},{"cell_type":"code","source":"#model2 = tf.keras.models.clone_model(model)\n#model2.fit(hash_ds, epochs=10, class_weight={0: 1, 1: 1/binds_rate})","metadata":{"execution":{"iopub.status.busy":"2024-06-04T19:56:29.643086Z","iopub.execute_input":"2024-06-04T19:56:29.644170Z","iopub.status.idle":"2024-06-04T19:56:29.648004Z","shell.execute_reply.started":"2024-06-04T19:56:29.644130Z","shell.execute_reply":"2024-06-04T19:56:29.647086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Predict on Test Set","metadata":{}},{"cell_type":"code","source":"test_ds = get_ds_csv(test_path, batch_size=512, n_samples=N_TEST, labeled=False)\ny = model.predict(test_ds)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T20:00:15.892308Z","iopub.execute_input":"2024-06-04T20:00:15.892975Z","iopub.status.idle":"2024-06-04T20:00:16.099096Z","shell.execute_reply.started":"2024-06-04T20:00:15.892938Z","shell.execute_reply":"2024-06-04T20:00:16.097984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Write Submission File","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nyy = y[:,0]\nd = pd.DataFrame({'id': range(len(yy)), 'binds': yy})\nd['id'] = d['id'] + 295246830\nfrom scipy.special import expit, logit\nd['binds'] = expit(d['binds'])\nd.to_csv('submission.csv', index=False, header=True)\nprint(d['binds'].describe())","metadata":{"execution":{"iopub.status.busy":"2024-06-04T20:00:23.501775Z","iopub.execute_input":"2024-06-04T20:00:23.502504Z","iopub.status.idle":"2024-06-04T20:00:23.514261Z","shell.execute_reply.started":"2024-06-04T20:00:23.502472Z","shell.execute_reply":"2024-06-04T20:00:23.513312Z"},"trusted":true},"execution_count":null,"outputs":[]}]}