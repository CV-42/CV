{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nAfter first attempts, the score was very low. (about 0.5)\n\nThen, we lokked up other Kaggler's submissions, in particular Beatriz Justino's https://www.kaggle.com/code/beatrizjustino/lstm-disaster-tweets. (Version 12)\n\nAnd we wondered, why it was so much better (about 0.8). Here are the findngs:","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\n# Imports that Justino's code needs:\nfrom keras import preprocessing\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.layers import Embedding, LSTM, Dense, Dropout,BatchNormalization\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:26.268269Z","iopub.execute_input":"2024-08-13T13:01:26.269512Z","iopub.status.idle":"2024-08-13T13:01:33.200450Z","shell.execute_reply.started":"2024-08-13T13:01:26.269429Z","shell.execute_reply":"2024-08-13T13:01:33.198566Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-13 13:01:28.014829: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-13 13:01:28.014921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-13 13:01:28.020307: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Choices","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nMAX_TOKENS = 10000\nEPOCHS = 20\nMAX_SENTENCE_LENGTH = 60","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:33.208360Z","iopub.execute_input":"2024-08-13T13:01:33.208983Z","iopub.status.idle":"2024-08-13T13:01:33.218063Z","shell.execute_reply.started":"2024-08-13T13:01:33.208911Z","shell.execute_reply":"2024-08-13T13:01:33.216512Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Raw Datasets","metadata":{}},{"cell_type":"code","source":"all_known_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\ntrain_df, val_df = train_test_split(all_known_df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:33.219834Z","iopub.execute_input":"2024-08-13T13:01:33.220277Z","iopub.status.idle":"2024-08-13T13:01:33.298841Z","shell.execute_reply.started":"2024-08-13T13:01:33.220242Z","shell.execute_reply":"2024-08-13T13:01:33.297151Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Note that the data seems to be badly classified:\nTwo examples classified as disaster, which I stumbled about:","metadata":{}},{"cell_type":"code","source":"badly_classified_example = all_known_df[all_known_df[\"text\"].str.contains(\"whirlwind of time\")]\nprint(badly_classified_example)\nprint(badly_classified_example['text'].to_numpy())\nprint(badly_classified_example['target'].to_numpy())\n\nbadly_classified_example = all_known_df[all_known_df[\"text\"].str.contains(\"Attack II Volleyball\")]\nprint()\nprint(print(badly_classified_example))\nprint(badly_classified_example['text'].to_numpy())\nprint(badly_classified_example['target'].to_numpy())","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:33.303409Z","iopub.execute_input":"2024-08-13T13:01:33.303892Z","iopub.status.idle":"2024-08-13T13:01:33.343510Z","shell.execute_reply.started":"2024-08-13T13:01:33.303855Z","shell.execute_reply":"2024-08-13T13:01:33.341408Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"         id    keyword                        location  \\\n7270  10409  whirlwind  Stamford & Cork (& Shropshire)   \n\n                                                   text  target  \n7270  I moved to England five years ago today. What ...       1  \n['I moved to England five years ago today. What a whirlwind of time it has been! http://t.co/eaSlGeA1B7']\n[1]\n\n      id keyword location                                               text  \\\n466  674  attack      NaN  #volleyball Attack II Volleyball Training Mach...   \n\n     target  \n466       1  \nNone\n['#volleyball Attack II Volleyball Training Machine - Sets Simulation - http://t.co/dCDeCFv934 http://t.co/dWBC1dUvdk']\n[1]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Justino's Raw Dataset\n\nJustino encodes the target differently, and balances the uneven classes. (It does not seem to help a lot.)","metadata":{}},{"cell_type":"code","source":"def get_Justino_raw_data(df, df_val=None):\n    def extract_text_and_target(df):\n        return df[\"text\"].to_numpy(), df[\"target\"].to_numpy()\n    class_0 = df[df['target'] == 0]\n    class_1 = df[df['target'] == 1]\n    class_0_under = class_0.sample(len(class_1), random_state=42)\n    df_equalized = pd.concat([class_0_under, class_1])\n    text, label = extract_text_and_target(df_equalized)\n    if df_val is not None:\n        text_val, label_val = extract_text_and_target(df_val)\n        return text, label, text_val, label_val\n    else:\n        return text, label","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:33.346414Z","iopub.execute_input":"2024-08-13T13:01:33.347218Z","iopub.status.idle":"2024-08-13T13:01:33.362525Z","shell.execute_reply.started":"2024-08-13T13:01:33.347175Z","shell.execute_reply":"2024-08-13T13:01:33.360375Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Our preprocessing functions","metadata":{}},{"cell_type":"markdown","source":"One function for cleaning text snippets:","metadata":{}},{"cell_type":"code","source":"import re, string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nstemmer = SnowballStemmer('english')\nstop_words = set(stopwords.words('english'))\n\ndef clean_stem_text(text):    \n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n    # Remove @mentions and hashtags\n    text = re.sub(r'\\@\\w+|\\#', '', text)\n    # Remove digits\n    text = re.sub(r'\\d+', '', text)\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    # Remove extra spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    # Convert to lowercase\n    text = text.lower()\n    # Remove stopwords and stem\n    text = ' '.join([stemmer.stem(word) \n                     for word in text.split() \n                     if word not in stop_words])\n    return text\n\ndef clean_stem_byte_tensor(tensor):\n    texts = tensor.numpy()\n    texts = np.reshape(texts, (-1,))\n    texts = [text.decode(\"utf-8\") for text in texts]\n    texts = [clean_stem_text(text) for text in texts]\n    return tf.constant(texts, dtype=tf.string, shape=(len(texts),))","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:33.365074Z","iopub.execute_input":"2024-08-13T13:01:33.365860Z","iopub.status.idle":"2024-08-13T13:01:34.019159Z","shell.execute_reply.started":"2024-08-13T13:01:33.365795Z","shell.execute_reply":"2024-08-13T13:01:34.016379Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Lots of functions for applying the cleaning function and for encoding the text numerically:\n\n(One can later chose from these different methods.)","metadata":{}},{"cell_type":"code","source":"int_text_vectorization = keras.layers.TextVectorization(\n    output_mode=\"int\",\n    max_tokens=MAX_TOKENS,\n    output_sequence_length=MAX_SENTENCE_LENGTH\n)\nint_text_vectorization_custom_clean_text = keras.layers.TextVectorization(\n    output_mode=\"int\",\n    max_tokens=MAX_TOKENS,\n    output_sequence_length=MAX_SENTENCE_LENGTH,\n    standardize=clean_stem_byte_tensor\n)\ntf_idf_text_vectorization_custom_clean_text = keras.layers.TextVectorization(\n    output_mode=\"tf_idf\",\n    max_tokens=MAX_TOKENS,\n    standardize=clean_stem_byte_tensor\n)\ntf_idf_text_vectorization = keras.layers.TextVectorization(\n    output_mode=\"tf_idf\",\n    max_tokens=MAX_TOKENS\n)\ntf_idf_text_vectorization_custom_clean_text_ngram_2 = keras.layers.TextVectorization(\n    output_mode=\"tf_idf\",\n    max_tokens=MAX_TOKENS,\n    standardize=clean_stem_byte_tensor,\n    ngrams=(1,2)\n)\nint_text_vectorization_custom_clean_text_ngram_2 = keras.layers.TextVectorization(\n    output_mode=\"int\",\n    max_tokens=MAX_TOKENS,\n    standardize=clean_stem_byte_tensor,\n    ngrams=(1,2)\n)\n\ndef preprocess_df(df, df_val=None, mode=\"int\", clean=\"standard\", ngrams=(1,), df_test=None, max_tokens=MAX_TOKENS,\n                 output_sequence_length=MAX_SENTENCE_LENGTH):\n    assert mode in (\"int\", \"tf_idf\")\n    assert clean in (\"standard\", \"custom\")\n    assert ngrams in [(1,), (1,2)]\n    \n    if clean==\"standard\":\n        clean_method = \"lower_and_strip_punctuation\"\n    elif clean==\"custom\":\n        clean_method = clean_stem_byte_tensor\n    \n    # Need to silence output_sequence_length for the TextVectorization-layer if not in \"int\"-mode:\n    if mode!=\"int\": output_sequence_length=None\n    \n    vectorizer = keras.layers.TextVectorization(\n        output_mode=mode,\n        max_tokens=max_tokens,\n        output_sequence_length=output_sequence_length,\n        standardize=clean_method\n    )\n        \n    def df_to_X_y(df):\n        X = df[\"text\"].to_numpy()\n        y = np.reshape(np.array(df[\"target\"]), (-1,1))\n        return X, y\n    \n    X, y = df_to_X_y(df)\n    vectorizer.adapt(X)\n    if df_test is not None:\n        X_test = vectorizer(df_test[\"text\"].to_numpy())\n        if df_val is not None:\n            X_val, y_val = df_to_X_y(df_val)\n            return vectorizer(X), y, vectorizer(X_val), y_val, X_test\n        else:\n            return vectorizer(X), y, X_test\n    else:\n        if X_val is not None:\n            X_val, y_val = df_to_X_y(df_val)\n            return vectorizer(X), y, vectorizer(X_val), y_val\n        else:\n            return vectorizer(X), y","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.021677Z","iopub.execute_input":"2024-08-13T13:01:34.022271Z","iopub.status.idle":"2024-08-13T13:01:34.169788Z","shell.execute_reply.started":"2024-08-13T13:01:34.022221Z","shell.execute_reply":"2024-08-13T13:01:34.167987Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"(The proprocessing is safely run on the dataset (not in the model) to save the GPU from being blocked.)","metadata":{}},{"cell_type":"markdown","source":"# Justino's preprocessing functions\nATTENTION: There seemed to be a bug in applying the stemming! It does not work with lists, but should be applied on single words.","metadata":{}},{"cell_type":"code","source":"def clean_Justino(text_array):\n    def process_sentence(sentence):\n        sentence = re.sub(r'http\\S+|www\\S+|https\\S+', '', sentence, flags=re.MULTILINE)\n        sentence = re.sub(r'#\\S+', '', sentence)\n        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n        words = sentence.split()\n        filtered_words = [word for word in words if word.lower() not in ENGLISH_STOP_WORDS]\n        return ' '.join(filtered_words)\n    return [process_sentence(sentence) for sentence in text_array]\n\ndef get_Justino_preprocessed_data(df, df_val=None, label_to_cat=True, vocab_length=None, length_long_sentence=MAX_SENTENCE_LENGTH):\n    if df_val is not None:\n        texts, labels, texts_val, labels_val = get_Justino_raw_data(df, df_val)\n        texts_val = clean_Justino(texts_val)\n        texts_val = [stemmer.stem(word) for word in texts_val]\n    else:\n        texts, labels = get_Justino_raw_data(df)\n    texts = clean_Justino(texts)\n    #print(texts[:5])\n    texts = [stemmer.stem(word) for word in texts]\n    #print(\"-----------\")\n    #print(texts[:5])\n    \n    word_tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_length)\n    word_tokenizer.fit_on_texts(texts)\n    \n    #from nltk.tokenize import word_tokenize\n    #longest_train = max(text, key=lambda sentence: len(word_tokenize(sentence)))\n    #length_long_sentence = len(word_tokenize(longest_train))\n    \n    def process_data(texts, labels):\n        sequences = word_tokenizer.texts_to_sequences(texts)\n        padded_sequences = pad_sequences(sequences, maxlen=length_long_sentence)\n        if label_to_cat:\n            labels = keras.utils.to_categorical(labels)\n        return padded_sequences, labels\n    \n    padded_sequences, labels = process_data(texts, labels)\n    if df_val is not None:\n        padded_sequences_val, labels_val = process_data(texts_val, labels_val)\n        return padded_sequences, labels, padded_sequences_val, labels_val\n    else:\n        return padded_sequences, labels\n#get_Justino_preprocessed_data(train_df, val_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.173714Z","iopub.execute_input":"2024-08-13T13:01:34.174173Z","iopub.status.idle":"2024-08-13T13:01:34.193477Z","shell.execute_reply.started":"2024-08-13T13:01:34.174142Z","shell.execute_reply":"2024-08-13T13:01:34.191292Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# F1-Metric\n\nUsing metrics=[\"f1_score\"] is not working properly in tensorflow up until now!! The problem is discussed on some GitHub-site...\n\nWe specify an f1-metric more manually here:","metadata":{}},{"cell_type":"code","source":"f1 = tf.keras.metrics.F1Score(\n    average=None, threshold=0.5, name='f1', dtype=None\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.196085Z","iopub.execute_input":"2024-08-13T13:01:34.196543Z","iopub.status.idle":"2024-08-13T13:01:34.218508Z","shell.execute_reply.started":"2024-08-13T13:01:34.196469Z","shell.execute_reply":"2024-08-13T13:01:34.215444Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"For training, one could also try to use an adapted \"f1-loss\":","metadata":{}},{"cell_type":"code","source":"def f1_loss(y_true, y_pred):\n    \n    tp = tf.sum(tf.cast(y_true*y_pred, 'float'), axis=0)\n    tn = tf.sum(tf.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = tf.sum(tf.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = tf.sum(tf.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + tf.epsilon())\n    r = tp / (tp + fn + tf.epsilon())\n\n    f1 = 2*p*r / (p+r+tf.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1 - tf.mean(f1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.221030Z","iopub.execute_input":"2024-08-13T13:01:34.221499Z","iopub.status.idle":"2024-08-13T13:01:34.241764Z","shell.execute_reply.started":"2024-08-13T13:01:34.221464Z","shell.execute_reply":"2024-08-13T13:01:34.238106Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Our Models","metadata":{}},{"cell_type":"code","source":"\ndef get_model(max_tokens=MAX_TOKENS, max_sentence_length=MAX_SENTENCE_LENGTH,\n              hidden_dim=16, embedding_dim=33, mode=\"int\"):\n    if mode==\"int\":\n        inputs = keras.Input(shape=(max_sentence_length,), dtype=\"int64\")\n        x = keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim)(inputs)\n        x = keras.layers.GlobalAveragePooling1D()(x)\n        #x = keras.layers.Flatten()(x)\n    elif mode==\"tf_idf\":\n        inputs = keras.Input(shape=(max_tokens,), dtype=\"int64\")\n        x = inputs\n    \n    x = keras.layers.Dense(hidden_dim, activation=\"relu\")(x)\n    x = keras.layers.Dense(hidden_dim, activation=\"relu\")(x)+x\n    #x = keras.layers.Dense(hidden_dim, activation=\"relu\")(x)\n    \n    x = keras.layers.Dropout(0.5)(x)\n    x = keras.layers.Dense(1)(x)\n    \n    model = keras.Model(inputs=inputs, outputs=x)\n    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n                 #loss=f1_loss,\n                 optimizer=\"rmsprop\",\n                 metrics=[\"accuracy\", f1],\n                 #run_eagerly=True\n                 )\n    return model\n\n# We should also try to do simple logistic regression, when we find the time for it:\n\n#def get_LR_model(max_tokens):\n#    inputs = keras.Input(shape=(MAX_SENTENCE_LENGTH,), dtype=\"int64\")\n#    x = tf.keras.layers.CategoryEncoding(\n#        num_tokens=max_tokens, output_mode='multi_hot', sparse=False\n#    )(inputs)\n#    x = keras.layers.Dense(1)(x)\n#    model = keras.Model(inputs=inputs, outputs=x)\n#    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n#                 #loss=f1_loss,\n#                 optimizer=\"adam\",\n#                 metrics=[\"f1_score\", \"accuracy\", \"precision\", \"recall\"],\n#                 #run_eagerly=True\n#                 )\n#    return model\n\n#def get_tf_idf_LR_model(max_tokens):\n#    inputs = keras.Input(shape=(max_tokens,), dtype=\"int64\")\n#    x = keras.layers.Dense(1)(inputs)\n#    model = keras.Model(inputs=inputs, outputs=x)\n#    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n#                 #loss=f1_loss,\n#                 optimizer=\"adam\",\n#                 metrics=[\"f1_score\", \"accuracy\", \"precision\", \"recall\"],\n#                 #run_eagerly=True\n#                 )\n#    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.245164Z","iopub.execute_input":"2024-08-13T13:01:34.246861Z","iopub.status.idle":"2024-08-13T13:01:34.263075Z","shell.execute_reply.started":"2024-08-13T13:01:34.246814Z","shell.execute_reply":"2024-08-13T13:01:34.261068Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# That's basically Justino's model for our own data-formatting.. Maybe we'll use it one day.\n\n#def get_LSTM_model():\n#    inputs = keras.Input((MAX_SENTENCE_LENGTH,), dtype=tf.int64)\n#    x = keras.layers.Embedding(input_dim=MAX_TOKENS, output_dim=128)(inputs)\n#    x = keras.layers.Dropout(0.5)(x)\n#    x = keras.layers.LSTM(65)(x)\n#    x = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n#    model=keras.Model(inputs, x)\n#    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n#                  optimizer=\"Adamax\",\n#                  metrics=[\"accuracy\", \"f1_score\"],\n#                 #run_eagerly=True\n#                 )\n#    model.summary()\n#    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.265337Z","iopub.execute_input":"2024-08-13T13:01:34.267859Z","iopub.status.idle":"2024-08-13T13:01:34.288032Z","shell.execute_reply.started":"2024-08-13T13:01:34.267805Z","shell.execute_reply":"2024-08-13T13:01:34.286022Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Jutino's Model","metadata":{}},{"cell_type":"code","source":"def get_Justino_model(max_words=MAX_TOKENS, max_len=MAX_SENTENCE_LENGTH):\n    model = Sequential()\n    model.add(Embedding(max_words, 128))\n    model.add(Dropout(0.5))\n    model.add(LSTM(64))\n    model.add(Dense(2, activation='sigmoid'))\n\n    model.compile(loss='BinaryCrossentropy', optimizer='Adamax', metrics=['accuracy', f1])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.294998Z","iopub.execute_input":"2024-08-13T13:01:34.295482Z","iopub.status.idle":"2024-08-13T13:01:34.312241Z","shell.execute_reply.started":"2024-08-13T13:01:34.295447Z","shell.execute_reply":"2024-08-13T13:01:34.309584Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Function for saving predictions","metadata":{}},{"cell_type":"code","source":"def predict_and_save(model, X_test, filename):\n    predictions_logits = model.predict(X_test)\n    predictions = tf.math.sigmoid(predictions_logits).numpy()\n    predictions = (predictions>0.5).astype(int)\n    df = test_df[[\"id\"]].copy()\n    df[\"target\"] = predictions\n    df.to_csv(filename, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.314538Z","iopub.execute_input":"2024-08-13T13:01:34.315907Z","iopub.status.idle":"2024-08-13T13:01:34.329587Z","shell.execute_reply.started":"2024-08-13T13:01:34.315832Z","shell.execute_reply":"2024-08-13T13:01:34.327478Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Runs","metadata":{}},{"cell_type":"markdown","source":"Justino orginal:","metadata":{}},{"cell_type":"code","source":"X_Justino, y_Justino = get_Justino_preprocessed_data(all_known_df)\nmod_Justino = get_Justino_model(max_words=np.max(np.max(X_Justino))+1)\nmod_Justino.fit(X_Justino, y_Justino, epochs=EPOCHS, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:01:34.332191Z","iopub.execute_input":"2024-08-13T13:01:34.332714Z","iopub.status.idle":"2024-08-13T13:04:37.341252Z","shell.execute_reply.started":"2024-08-13T13:01:34.332679Z","shell.execute_reply":"2024-08-13T13:04:37.339193Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.5710 - f1: 0.5607 - loss: 0.6883\nEpoch 2/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - accuracy: 0.6810 - f1: 0.6826 - loss: 0.6138\nEpoch 3/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7812 - f1: 0.7794 - loss: 0.4753\nEpoch 4/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8213 - f1: 0.8198 - loss: 0.3947\nEpoch 5/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8495 - f1: 0.8494 - loss: 0.3569\nEpoch 6/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8534 - f1: 0.8530 - loss: 0.3400\nEpoch 7/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.8777 - f1: 0.8775 - loss: 0.2968\nEpoch 8/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.8820 - f1: 0.8809 - loss: 0.2808\nEpoch 9/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.9075 - f1: 0.9063 - loss: 0.2371\nEpoch 10/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.9098 - f1: 0.9096 - loss: 0.2328\nEpoch 11/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9100 - f1: 0.9100 - loss: 0.2227\nEpoch 12/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.9300 - f1: 0.9299 - loss: 0.1891\nEpoch 13/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.9278 - f1: 0.9285 - loss: 0.1858\nEpoch 14/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - accuracy: 0.9322 - f1: 0.9323 - loss: 0.1722\nEpoch 15/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 78ms/step - accuracy: 0.9410 - f1: 0.9405 - loss: 0.1531\nEpoch 16/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.9448 - f1: 0.9449 - loss: 0.1431\nEpoch 17/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.9463 - f1: 0.9456 - loss: 0.1422\nEpoch 18/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - accuracy: 0.9513 - f1: 0.9517 - loss: 0.1246\nEpoch 19/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.9514 - f1: 0.9513 - loss: 0.1215\nEpoch 20/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.9586 - f1: 0.9581 - loss: 0.1144\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x790df46dada0>"},"metadata":{}}]},{"cell_type":"markdown","source":"Justino with splitting data into train and val:","metadata":{}},{"cell_type":"code","source":"X_Justino, y_Justino, X_Justino_val, y_Justino_val = get_Justino_preprocessed_data(train_df, val_df)\nmod_Justino = get_Justino_model(max_words=np.max(np.max(X_Justino))+1)\nmod_Justino.fit(X_Justino, y_Justino, validation_data=(X_Justino_val, y_Justino_val), epochs=EPOCHS, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:04:37.343599Z","iopub.execute_input":"2024-08-13T13:04:37.344192Z","iopub.status.idle":"2024-08-13T13:06:49.779882Z","shell.execute_reply.started":"2024-08-13T13:04:37.344141Z","shell.execute_reply":"2024-08-13T13:06:49.778250Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.5416 - f1: 0.8482 - loss: 0.6908 - val_accuracy: 0.6848 - val_f1: 0.6239 - val_loss: 0.6583\nEpoch 2/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.6470 - f1: 0.6351 - loss: 0.6498 - val_accuracy: 0.7301 - val_f1: 0.7209 - val_loss: 0.5768\nEpoch 3/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 84ms/step - accuracy: 0.7402 - f1: 0.7396 - loss: 0.5419 - val_accuracy: 0.7682 - val_f1: 0.7517 - val_loss: 0.4922\nEpoch 4/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - accuracy: 0.8145 - f1: 0.8160 - loss: 0.4157 - val_accuracy: 0.7781 - val_f1: 0.7647 - val_loss: 0.4741\nEpoch 5/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8465 - f1: 0.8476 - loss: 0.3566 - val_accuracy: 0.7781 - val_f1: 0.7683 - val_loss: 0.4791\nEpoch 6/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - accuracy: 0.8667 - f1: 0.8664 - loss: 0.3176 - val_accuracy: 0.7748 - val_f1: 0.7689 - val_loss: 0.4897\nEpoch 7/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.8775 - f1: 0.8769 - loss: 0.2901 - val_accuracy: 0.7846 - val_f1: 0.7736 - val_loss: 0.4829\nEpoch 8/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.8929 - f1: 0.8952 - loss: 0.2716 - val_accuracy: 0.7768 - val_f1: 0.7694 - val_loss: 0.5202\nEpoch 9/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.9074 - f1: 0.9071 - loss: 0.2369 - val_accuracy: 0.7741 - val_f1: 0.7689 - val_loss: 0.5307\nEpoch 10/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9184 - f1: 0.9180 - loss: 0.2087 - val_accuracy: 0.7492 - val_f1: 0.7508 - val_loss: 0.5950\nEpoch 11/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9212 - f1: 0.9208 - loss: 0.2098 - val_accuracy: 0.7695 - val_f1: 0.7639 - val_loss: 0.5724\nEpoch 12/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9307 - f1: 0.9302 - loss: 0.1821 - val_accuracy: 0.7663 - val_f1: 0.7612 - val_loss: 0.5953\nEpoch 13/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9327 - f1: 0.9322 - loss: 0.1731 - val_accuracy: 0.7695 - val_f1: 0.7643 - val_loss: 0.5983\nEpoch 14/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9421 - f1: 0.9416 - loss: 0.1552 - val_accuracy: 0.7695 - val_f1: 0.7587 - val_loss: 0.5984\nEpoch 15/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9392 - f1: 0.9382 - loss: 0.1516 - val_accuracy: 0.7584 - val_f1: 0.7544 - val_loss: 0.6600\nEpoch 16/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.9593 - f1: 0.9593 - loss: 0.1167 - val_accuracy: 0.7571 - val_f1: 0.7555 - val_loss: 0.6854\nEpoch 17/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.9540 - f1: 0.9537 - loss: 0.1242 - val_accuracy: 0.7623 - val_f1: 0.7579 - val_loss: 0.7001\nEpoch 18/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - accuracy: 0.9552 - f1: 0.9543 - loss: 0.1215 - val_accuracy: 0.7617 - val_f1: 0.7568 - val_loss: 0.6945\nEpoch 19/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.9659 - f1: 0.9659 - loss: 0.1005 - val_accuracy: 0.7439 - val_f1: 0.7428 - val_loss: 0.7511\nEpoch 20/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.9545 - f1: 0.9548 - loss: 0.1073 - val_accuracy: 0.7367 - val_f1: 0.7398 - val_loss: 0.7376\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x790dc85b19c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Own models:","metadata":{}},{"cell_type":"markdown","source":"Using standard cleaning and multi-hot-encodig:","metadata":{}},{"cell_type":"code","source":"X_train, y_train, X_val, y_val, X_test = preprocess_df(train_df, val_df, df_test=test_df, mode=\"int\", clean=\"standard\")\nmodel = get_model(MAX_TOKENS)\nmodel.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=64,\n         callbacks=[keras.callbacks.ModelCheckpoint(\"own_model_int_standard.keras\",save_best_only=True)])","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:06:49.782006Z","iopub.execute_input":"2024-08-13T13:06:49.782500Z","iopub.status.idle":"2024-08-13T13:07:08.843219Z","shell.execute_reply.started":"2024-08-13T13:06:49.782454Z","shell.execute_reply":"2024-08-13T13:07:08.841920Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5774 - f1: 0.4279 - loss: 0.6858 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6859\nEpoch 2/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5687 - f1: 0.0000e+00 - loss: 0.6842 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6801\nEpoch 3/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5600 - f1: 0.0000e+00 - loss: 0.6859 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6781\nEpoch 4/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5704 - f1: 0.0000e+00 - loss: 0.6801 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6763\nEpoch 5/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5719 - f1: 0.0000e+00 - loss: 0.6763 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6711\nEpoch 6/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5571 - f1: 0.0000e+00 - loss: 0.6721 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6540\nEpoch 7/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5765 - f1: 0.0000e+00 - loss: 0.6458 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6283\nEpoch 8/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5722 - f1: 0.0044 - loss: 0.6291 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6572\nEpoch 9/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5858 - f1: 0.0975 - loss: 0.6101 - val_accuracy: 0.6054 - val_f1: 0.1451 - val_loss: 0.6955\nEpoch 10/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6201 - f1: 0.2714 - loss: 0.5951 - val_accuracy: 0.5778 - val_f1: 0.0243 - val_loss: 0.6640\nEpoch 11/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6384 - f1: 0.3442 - loss: 0.5744 - val_accuracy: 0.7177 - val_f1: 0.7055 - val_loss: 0.6505\nEpoch 12/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6869 - f1: 0.4968 - loss: 0.5600 - val_accuracy: 0.5299 - val_f1: 0.6328 - val_loss: 0.7757\nEpoch 13/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6865 - f1: 0.5311 - loss: 0.5579 - val_accuracy: 0.6980 - val_f1: 0.4713 - val_loss: 0.5343\nEpoch 14/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7189 - f1: 0.5708 - loss: 0.5340 - val_accuracy: 0.7492 - val_f1: 0.7306 - val_loss: 0.6069\nEpoch 15/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7381 - f1: 0.6164 - loss: 0.5160 - val_accuracy: 0.7446 - val_f1: 0.5935 - val_loss: 0.5130\nEpoch 16/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7626 - f1: 0.6598 - loss: 0.4833 - val_accuracy: 0.7157 - val_f1: 0.5162 - val_loss: 0.5290\nEpoch 17/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7592 - f1: 0.6529 - loss: 0.5052 - val_accuracy: 0.7873 - val_f1: 0.6989 - val_loss: 0.4894\nEpoch 18/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7600 - f1: 0.6629 - loss: 0.4939 - val_accuracy: 0.7840 - val_f1: 0.7424 - val_loss: 0.5357\nEpoch 19/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7717 - f1: 0.6831 - loss: 0.4727 - val_accuracy: 0.8024 - val_f1: 0.7324 - val_loss: 0.4769\nEpoch 20/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7823 - f1: 0.7095 - loss: 0.4600 - val_accuracy: 0.7649 - val_f1: 0.6391 - val_loss: 0.4862\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x790dc22f56c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"Run all possible encodings with the get_model():","metadata":{}},{"cell_type":"code","source":"histories = {}\nfor mode in (\"int\", \"tf_idf\"):\n    for clean in (\"standard\", \"custom\"):\n        for ngrams in [(1,), (1,2)]:\n            name = \"__\".join([mode, clean, str(ngrams)])\n            print()\n            print(\"------------- Starting \" + name + \" ---------------------\")\n            X_train, y_train, X_val, y_val, X_test = preprocess_df(train_df, val_df, df_test=test_df,\n                                                                   mode=mode, clean=clean, ngrams=ngrams)\n            model = get_model(MAX_TOKENS, mode=mode)\n            #model.summary()\n            histories[name] = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=42, batch_size=64,\n                 callbacks=[keras.callbacks.ModelCheckpoint(name+\".keras\", save_best_only=True)])\n            \n            # Save predictions with best model:\n            model = keras.models.load_model(name+\".keras\")\n            predict_and_save(model, X_test, \"predictions__\" + name)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:07:08.844681Z","iopub.execute_input":"2024-08-13T13:07:08.845140Z","iopub.status.idle":"2024-08-13T13:13:26.927691Z","shell.execute_reply.started":"2024-08-13T13:07:08.845107Z","shell.execute_reply":"2024-08-13T13:13:26.926405Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\n------------- Starting int__standard__(1,) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5775 - f1: 0.3099 - loss: 0.6921 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6856\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5665 - f1: 0.0000e+00 - loss: 0.6880 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6830\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5727 - f1: 0.0000e+00 - loss: 0.6841 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6823\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5576 - f1: 0.0000e+00 - loss: 0.6871 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6822\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5688 - f1: 0.0000e+00 - loss: 0.6855 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6818\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5788 - f1: 0.0000e+00 - loss: 0.6820 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6824\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5666 - f1: 0.0000e+00 - loss: 0.6843 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6816\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5701 - f1: 0.0000e+00 - loss: 0.6832 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6815\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5673 - f1: 0.0000e+00 - loss: 0.6854 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6813\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5798 - f1: 0.0000e+00 - loss: 0.6805 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6817\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5778 - f1: 0.0000e+00 - loss: 0.6809 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6816\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5738 - f1: 0.0000e+00 - loss: 0.6818 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6811\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5681 - f1: 0.0000e+00 - loss: 0.6827 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6802\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5713 - f1: 0.0000e+00 - loss: 0.6807 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6812\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5727 - f1: 0.0000e+00 - loss: 0.6783 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6788\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5750 - f1: 0.0000e+00 - loss: 0.6739 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6698\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5670 - f1: 0.0000e+00 - loss: 0.6717 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6652\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5778 - f1: 3.5301e-04 - loss: 0.6643 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6725\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5642 - f1: 0.0318 - loss: 0.6535 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6510\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5897 - f1: 0.0851 - loss: 0.6393 - val_accuracy: 0.6093 - val_f1: 0.1632 - val_loss: 0.6393\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6044 - f1: 0.1866 - loss: 0.6320 - val_accuracy: 0.5811 - val_f1: 0.0392 - val_loss: 0.6212\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6283 - f1: 0.3066 - loss: 0.6132 - val_accuracy: 0.6625 - val_f1: 0.3670 - val_loss: 0.5880\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6550 - f1: 0.3711 - loss: 0.5978 - val_accuracy: 0.6533 - val_f1: 0.3316 - val_loss: 0.5699\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6718 - f1: 0.4537 - loss: 0.5811 - val_accuracy: 0.6356 - val_f1: 0.6675 - val_loss: 0.7014\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6966 - f1: 0.5272 - loss: 0.5711 - val_accuracy: 0.7242 - val_f1: 0.5484 - val_loss: 0.5368\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6988 - f1: 0.5332 - loss: 0.5576 - val_accuracy: 0.6717 - val_f1: 0.3842 - val_loss: 0.5531\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7225 - f1: 0.5716 - loss: 0.5407 - val_accuracy: 0.6829 - val_f1: 0.4216 - val_loss: 0.5407\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7323 - f1: 0.5787 - loss: 0.5351 - val_accuracy: 0.7098 - val_f1: 0.5023 - val_loss: 0.5197\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7375 - f1: 0.6136 - loss: 0.5212 - val_accuracy: 0.7676 - val_f1: 0.6556 - val_loss: 0.4922\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7563 - f1: 0.6482 - loss: 0.5094 - val_accuracy: 0.7387 - val_f1: 0.5766 - val_loss: 0.4987\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7736 - f1: 0.6746 - loss: 0.4815 - val_accuracy: 0.6750 - val_f1: 0.6889 - val_loss: 0.6679\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7707 - f1: 0.6817 - loss: 0.4881 - val_accuracy: 0.7912 - val_f1: 0.7104 - val_loss: 0.4700\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7744 - f1: 0.6914 - loss: 0.4793 - val_accuracy: 0.7150 - val_f1: 0.5090 - val_loss: 0.5333\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7758 - f1: 0.6856 - loss: 0.4685 - val_accuracy: 0.6789 - val_f1: 0.4073 - val_loss: 0.5834\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7791 - f1: 0.6851 - loss: 0.4648 - val_accuracy: 0.7787 - val_f1: 0.6750 - val_loss: 0.4610\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7972 - f1: 0.7195 - loss: 0.4472 - val_accuracy: 0.7807 - val_f1: 0.7519 - val_loss: 0.5403\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7999 - f1: 0.7209 - loss: 0.4511 - val_accuracy: 0.8030 - val_f1: 0.7317 - val_loss: 0.4535\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8119 - f1: 0.7423 - loss: 0.4262 - val_accuracy: 0.6185 - val_f1: 0.6716 - val_loss: 0.8768\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8128 - f1: 0.7520 - loss: 0.4347 - val_accuracy: 0.7433 - val_f1: 0.5854 - val_loss: 0.4974\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8143 - f1: 0.7500 - loss: 0.4119 - val_accuracy: 0.7032 - val_f1: 0.7095 - val_loss: 0.6714\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8152 - f1: 0.7530 - loss: 0.4193 - val_accuracy: 0.7525 - val_f1: 0.6069 - val_loss: 0.4920\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8305 - f1: 0.7628 - loss: 0.3951 - val_accuracy: 0.7564 - val_f1: 0.7367 - val_loss: 0.5776\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\n------------- Starting int__standard__(1, 2) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.5734 - f1: 0.4117 - loss: 0.6880 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6820\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5641 - f1: 0.0000e+00 - loss: 0.6862 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6802\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5670 - f1: 0.0000e+00 - loss: 0.6832 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6787\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5564 - f1: 0.0000e+00 - loss: 0.6854 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6808\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5700 - f1: 0.0000e+00 - loss: 0.6782 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6781\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5699 - f1: 0.0000e+00 - loss: 0.6687 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6617\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5666 - f1: 0.0000e+00 - loss: 0.6541 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6385\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5738 - f1: 0.0111 - loss: 0.6388 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6374\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5930 - f1: 0.1161 - loss: 0.6261 - val_accuracy: 0.5955 - val_f1: 0.1020 - val_loss: 0.5936\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6186 - f1: 0.2414 - loss: 0.6062 - val_accuracy: 0.7242 - val_f1: 0.5541 - val_loss: 0.6132\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6433 - f1: 0.3655 - loss: 0.5894 - val_accuracy: 0.6980 - val_f1: 0.6950 - val_loss: 0.6619\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6811 - f1: 0.4679 - loss: 0.5687 - val_accuracy: 0.5962 - val_f1: 0.1048 - val_loss: 0.6485\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6958 - f1: 0.4997 - loss: 0.5673 - val_accuracy: 0.6422 - val_f1: 0.6723 - val_loss: 0.6861\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7113 - f1: 0.5734 - loss: 0.5583 - val_accuracy: 0.6901 - val_f1: 0.4434 - val_loss: 0.5350\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7379 - f1: 0.6123 - loss: 0.5133 - val_accuracy: 0.7820 - val_f1: 0.7004 - val_loss: 0.5181\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7530 - f1: 0.6302 - loss: 0.5158 - val_accuracy: 0.7873 - val_f1: 0.7318 - val_loss: 0.5163\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7611 - f1: 0.6535 - loss: 0.5000 - val_accuracy: 0.7846 - val_f1: 0.7346 - val_loss: 0.5125\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7594 - f1: 0.6630 - loss: 0.5000 - val_accuracy: 0.6487 - val_f1: 0.3043 - val_loss: 0.6609\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7643 - f1: 0.6683 - loss: 0.5027 - val_accuracy: 0.7124 - val_f1: 0.5034 - val_loss: 0.5358\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7811 - f1: 0.6823 - loss: 0.4737 - val_accuracy: 0.7735 - val_f1: 0.6608 - val_loss: 0.4682\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7898 - f1: 0.7097 - loss: 0.4655 - val_accuracy: 0.8024 - val_f1: 0.7286 - val_loss: 0.4687\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7935 - f1: 0.7111 - loss: 0.4673 - val_accuracy: 0.7525 - val_f1: 0.6077 - val_loss: 0.4826\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8044 - f1: 0.7278 - loss: 0.4479 - val_accuracy: 0.7479 - val_f1: 0.5966 - val_loss: 0.4902\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7972 - f1: 0.7265 - loss: 0.4364 - val_accuracy: 0.7203 - val_f1: 0.5235 - val_loss: 0.5308\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7972 - f1: 0.7225 - loss: 0.4474 - val_accuracy: 0.7367 - val_f1: 0.5702 - val_loss: 0.5189\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8022 - f1: 0.7460 - loss: 0.4355 - val_accuracy: 0.7045 - val_f1: 0.4816 - val_loss: 0.5611\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8145 - f1: 0.7443 - loss: 0.4182 - val_accuracy: 0.7899 - val_f1: 0.7568 - val_loss: 0.5036\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8261 - f1: 0.7684 - loss: 0.4169 - val_accuracy: 0.7347 - val_f1: 0.5665 - val_loss: 0.5153\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8126 - f1: 0.7483 - loss: 0.4101 - val_accuracy: 0.7708 - val_f1: 0.7487 - val_loss: 0.5390\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8375 - f1: 0.7768 - loss: 0.3829 - val_accuracy: 0.7708 - val_f1: 0.6492 - val_loss: 0.4761\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8258 - f1: 0.7747 - loss: 0.4076 - val_accuracy: 0.7255 - val_f1: 0.5386 - val_loss: 0.5787\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8225 - f1: 0.7553 - loss: 0.4065 - val_accuracy: 0.7492 - val_f1: 0.6004 - val_loss: 0.5287\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8465 - f1: 0.7980 - loss: 0.3593 - val_accuracy: 0.7511 - val_f1: 0.7392 - val_loss: 0.5831\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8435 - f1: 0.8002 - loss: 0.3727 - val_accuracy: 0.7781 - val_f1: 0.6653 - val_loss: 0.4636\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8416 - f1: 0.7907 - loss: 0.3781 - val_accuracy: 0.7787 - val_f1: 0.7560 - val_loss: 0.5464\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8297 - f1: 0.7641 - loss: 0.3883 - val_accuracy: 0.5699 - val_f1: 0.6507 - val_loss: 1.0883\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8469 - f1: 0.7992 - loss: 0.3787 - val_accuracy: 0.8135 - val_f1: 0.7418 - val_loss: 0.4449\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8593 - f1: 0.8124 - loss: 0.3426 - val_accuracy: 0.7971 - val_f1: 0.7625 - val_loss: 0.5129\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8433 - f1: 0.7988 - loss: 0.3678 - val_accuracy: 0.8168 - val_f1: 0.7593 - val_loss: 0.4484\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8430 - f1: 0.7896 - loss: 0.3733 - val_accuracy: 0.6553 - val_f1: 0.6892 - val_loss: 0.8208\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8609 - f1: 0.8259 - loss: 0.3465 - val_accuracy: 0.7905 - val_f1: 0.6906 - val_loss: 0.4748\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8447 - f1: 0.7977 - loss: 0.3684 - val_accuracy: 0.6362 - val_f1: 0.6790 - val_loss: 0.9202\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\n------------- Starting int__custom__(1,) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5654 - f1: 0.4074 - loss: 0.6870 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6806\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5681 - f1: 0.0000e+00 - loss: 0.6865 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6811\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5759 - f1: 0.0000e+00 - loss: 0.6829 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6806\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5687 - f1: 0.0000e+00 - loss: 0.6829 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6841\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5721 - f1: 0.0000e+00 - loss: 0.6831 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6807\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5617 - f1: 0.0000e+00 - loss: 0.6852 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6808\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5748 - f1: 0.0000e+00 - loss: 0.6813 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6819\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5695 - f1: 0.0000e+00 - loss: 0.6826 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6813\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5723 - f1: 0.0000e+00 - loss: 0.6820 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6797\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5665 - f1: 0.0000e+00 - loss: 0.6836 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6815\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5736 - f1: 0.0000e+00 - loss: 0.6812 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6787\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5761 - f1: 0.0000e+00 - loss: 0.6787 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6779\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5660 - f1: 0.0000e+00 - loss: 0.6823 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6772\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5754 - f1: 0.0000e+00 - loss: 0.6779 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6833\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5682 - f1: 0.0000e+00 - loss: 0.6779 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6769\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5722 - f1: 0.0000e+00 - loss: 0.6734 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6692\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5762 - f1: 0.0000e+00 - loss: 0.6644 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6592\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5706 - f1: 0.0000e+00 - loss: 0.6569 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6406\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5735 - f1: 0.0040 - loss: 0.6430 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6193\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5752 - f1: 0.0804 - loss: 0.6299 - val_accuracy: 0.6894 - val_f1: 0.4335 - val_loss: 0.6774\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6232 - f1: 0.2395 - loss: 0.6100 - val_accuracy: 0.6047 - val_f1: 0.1375 - val_loss: 0.5761\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6499 - f1: 0.3471 - loss: 0.5906 - val_accuracy: 0.6369 - val_f1: 0.2597 - val_loss: 0.5642\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6848 - f1: 0.4420 - loss: 0.5630 - val_accuracy: 0.6855 - val_f1: 0.4166 - val_loss: 0.5330\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6936 - f1: 0.4919 - loss: 0.5664 - val_accuracy: 0.7085 - val_f1: 0.4837 - val_loss: 0.5188\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7016 - f1: 0.5331 - loss: 0.5668 - val_accuracy: 0.7433 - val_f1: 0.5809 - val_loss: 0.5107\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7308 - f1: 0.5837 - loss: 0.5260 - val_accuracy: 0.5890 - val_f1: 0.6587 - val_loss: 0.7353\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7260 - f1: 0.5859 - loss: 0.5443 - val_accuracy: 0.6146 - val_f1: 0.1767 - val_loss: 0.6801\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7310 - f1: 0.5935 - loss: 0.5293 - val_accuracy: 0.6205 - val_f1: 0.1994 - val_loss: 0.6817\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7438 - f1: 0.6120 - loss: 0.5114 - val_accuracy: 0.7400 - val_f1: 0.5705 - val_loss: 0.4929\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7690 - f1: 0.6630 - loss: 0.4821 - val_accuracy: 0.7597 - val_f1: 0.6288 - val_loss: 0.4664\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7726 - f1: 0.6780 - loss: 0.4832 - val_accuracy: 0.7951 - val_f1: 0.7100 - val_loss: 0.4506\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7928 - f1: 0.7121 - loss: 0.4494 - val_accuracy: 0.7406 - val_f1: 0.5711 - val_loss: 0.5029\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7832 - f1: 0.7015 - loss: 0.4589 - val_accuracy: 0.7531 - val_f1: 0.6034 - val_loss: 0.4825\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8100 - f1: 0.7396 - loss: 0.4352 - val_accuracy: 0.6448 - val_f1: 0.2872 - val_loss: 0.7425\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8048 - f1: 0.7253 - loss: 0.4418 - val_accuracy: 0.7800 - val_f1: 0.6751 - val_loss: 0.4484\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8000 - f1: 0.7301 - loss: 0.4523 - val_accuracy: 0.8076 - val_f1: 0.7459 - val_loss: 0.4460\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8102 - f1: 0.7489 - loss: 0.4326 - val_accuracy: 0.8017 - val_f1: 0.7250 - val_loss: 0.4398\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8092 - f1: 0.7468 - loss: 0.4286 - val_accuracy: 0.8102 - val_f1: 0.7515 - val_loss: 0.4438\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8106 - f1: 0.7425 - loss: 0.4305 - val_accuracy: 0.7321 - val_f1: 0.7305 - val_loss: 0.6368\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8021 - f1: 0.7237 - loss: 0.4504 - val_accuracy: 0.8102 - val_f1: 0.7493 - val_loss: 0.4415\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8223 - f1: 0.7548 - loss: 0.4104 - val_accuracy: 0.7492 - val_f1: 0.5928 - val_loss: 0.5095\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8345 - f1: 0.7847 - loss: 0.4015 - val_accuracy: 0.7157 - val_f1: 0.5040 - val_loss: 0.5878\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\n------------- Starting int__custom__(1, 2) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5613 - f1: 0.2269 - loss: 0.6866 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6806\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5751 - f1: 0.0000e+00 - loss: 0.6825 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6806\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5708 - f1: 0.0000e+00 - loss: 0.6844 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6847\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5701 - f1: 0.0000e+00 - loss: 0.6843 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6798\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5676 - f1: 0.0000e+00 - loss: 0.6839 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6794\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5682 - f1: 0.0000e+00 - loss: 0.6844 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6794\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5635 - f1: 0.0000e+00 - loss: 0.6836 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6783\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5742 - f1: 0.0000e+00 - loss: 0.6822 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6833\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5698 - f1: 0.0000e+00 - loss: 0.6828 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6782\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5702 - f1: 0.0000e+00 - loss: 0.6785 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6751\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5749 - f1: 0.0000e+00 - loss: 0.6767 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6777\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5589 - f1: 0.0000e+00 - loss: 0.6824 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6671\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5675 - f1: 0.0000e+00 - loss: 0.6700 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6592\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5693 - f1: 0.0000e+00 - loss: 0.6604 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6564\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5692 - f1: 0.0000e+00 - loss: 0.6495 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6348\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5688 - f1: 0.0000e+00 - loss: 0.6378 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.7130\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5780 - f1: 0.0239 - loss: 0.6435 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6279\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6052 - f1: 0.1769 - loss: 0.6151 - val_accuracy: 0.4957 - val_f1: 0.6194 - val_loss: 0.7715\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6242 - f1: 0.3410 - loss: 0.6159 - val_accuracy: 0.6461 - val_f1: 0.2917 - val_loss: 0.5578\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6596 - f1: 0.3866 - loss: 0.5792 - val_accuracy: 0.6625 - val_f1: 0.3461 - val_loss: 0.5436\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6781 - f1: 0.4935 - loss: 0.5742 - val_accuracy: 0.7708 - val_f1: 0.7527 - val_loss: 0.6452\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6990 - f1: 0.5489 - loss: 0.5616 - val_accuracy: 0.5811 - val_f1: 0.0333 - val_loss: 0.8124\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7156 - f1: 0.5476 - loss: 0.5566 - val_accuracy: 0.6211 - val_f1: 0.6727 - val_loss: 0.7219\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7308 - f1: 0.5906 - loss: 0.5482 - val_accuracy: 0.7012 - val_f1: 0.4615 - val_loss: 0.5210\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7300 - f1: 0.5891 - loss: 0.5316 - val_accuracy: 0.7446 - val_f1: 0.5822 - val_loss: 0.4904\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7675 - f1: 0.6663 - loss: 0.4901 - val_accuracy: 0.7472 - val_f1: 0.5909 - val_loss: 0.4864\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7516 - f1: 0.6515 - loss: 0.5034 - val_accuracy: 0.6809 - val_f1: 0.7040 - val_loss: 0.6740\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7505 - f1: 0.6498 - loss: 0.5133 - val_accuracy: 0.7242 - val_f1: 0.5249 - val_loss: 0.5114\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7696 - f1: 0.6796 - loss: 0.4920 - val_accuracy: 0.7492 - val_f1: 0.5953 - val_loss: 0.4839\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7812 - f1: 0.7008 - loss: 0.4668 - val_accuracy: 0.7938 - val_f1: 0.7551 - val_loss: 0.4984\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7879 - f1: 0.7104 - loss: 0.4566 - val_accuracy: 0.6901 - val_f1: 0.4300 - val_loss: 0.6056\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7961 - f1: 0.7282 - loss: 0.4673 - val_accuracy: 0.7938 - val_f1: 0.7535 - val_loss: 0.4852\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8101 - f1: 0.7503 - loss: 0.4350 - val_accuracy: 0.7741 - val_f1: 0.6614 - val_loss: 0.4542\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8202 - f1: 0.7581 - loss: 0.4317 - val_accuracy: 0.7695 - val_f1: 0.7502 - val_loss: 0.5541\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8253 - f1: 0.7708 - loss: 0.4101 - val_accuracy: 0.7426 - val_f1: 0.5748 - val_loss: 0.5270\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8011 - f1: 0.7319 - loss: 0.4536 - val_accuracy: 0.7873 - val_f1: 0.6914 - val_loss: 0.4466\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8226 - f1: 0.7550 - loss: 0.4141 - val_accuracy: 0.8083 - val_f1: 0.7538 - val_loss: 0.4468\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8297 - f1: 0.7730 - loss: 0.3993 - val_accuracy: 0.8102 - val_f1: 0.7528 - val_loss: 0.4434\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8349 - f1: 0.7826 - loss: 0.3852 - val_accuracy: 0.7393 - val_f1: 0.5652 - val_loss: 0.5441\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8267 - f1: 0.7660 - loss: 0.4025 - val_accuracy: 0.6625 - val_f1: 0.3461 - val_loss: 0.7833\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8356 - f1: 0.7755 - loss: 0.3836 - val_accuracy: 0.4760 - val_f1: 0.6141 - val_loss: 1.2415\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8222 - f1: 0.7748 - loss: 0.4347 - val_accuracy: 0.8024 - val_f1: 0.7567 - val_loss: 0.4605\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\n------------- Starting tf_idf__standard__(1,) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6008 - f1: 0.4854 - loss: 0.6537 - val_accuracy: 0.7800 - val_f1: 0.6843 - val_loss: 0.5162\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7698 - f1: 0.6738 - loss: 0.4554 - val_accuracy: 0.8037 - val_f1: 0.7342 - val_loss: 0.4726\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8487 - f1: 0.8020 - loss: 0.3351 - val_accuracy: 0.7991 - val_f1: 0.7316 - val_loss: 0.4877\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8851 - f1: 0.8554 - loss: 0.2671 - val_accuracy: 0.7991 - val_f1: 0.7424 - val_loss: 0.5273\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9069 - f1: 0.8837 - loss: 0.2318 - val_accuracy: 0.7965 - val_f1: 0.7438 - val_loss: 0.5712\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9294 - f1: 0.9143 - loss: 0.1835 - val_accuracy: 0.7866 - val_f1: 0.7390 - val_loss: 0.6344\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9383 - f1: 0.9254 - loss: 0.1724 - val_accuracy: 0.7873 - val_f1: 0.7424 - val_loss: 0.6778\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9485 - f1: 0.9381 - loss: 0.1454 - val_accuracy: 0.7899 - val_f1: 0.7324 - val_loss: 0.6960\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9552 - f1: 0.9449 - loss: 0.1228 - val_accuracy: 0.7814 - val_f1: 0.7433 - val_loss: 0.7768\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9576 - f1: 0.9499 - loss: 0.1241 - val_accuracy: 0.7814 - val_f1: 0.7396 - val_loss: 0.8188\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9591 - f1: 0.9497 - loss: 0.1072 - val_accuracy: 0.7768 - val_f1: 0.7381 - val_loss: 0.8800\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9642 - f1: 0.9571 - loss: 0.0973 - val_accuracy: 0.7722 - val_f1: 0.7393 - val_loss: 0.9224\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9644 - f1: 0.9578 - loss: 0.0919 - val_accuracy: 0.7702 - val_f1: 0.7287 - val_loss: 0.9286\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9702 - f1: 0.9643 - loss: 0.0852 - val_accuracy: 0.7669 - val_f1: 0.7237 - val_loss: 0.9750\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9726 - f1: 0.9681 - loss: 0.0783 - val_accuracy: 0.7617 - val_f1: 0.7265 - val_loss: 1.0479\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9687 - f1: 0.9633 - loss: 0.0882 - val_accuracy: 0.7577 - val_f1: 0.7202 - val_loss: 1.1165\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9681 - f1: 0.9635 - loss: 0.0849 - val_accuracy: 0.7676 - val_f1: 0.7168 - val_loss: 1.0835\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9703 - f1: 0.9643 - loss: 0.0872 - val_accuracy: 0.7649 - val_f1: 0.7216 - val_loss: 1.1121\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9728 - f1: 0.9674 - loss: 0.0689 - val_accuracy: 0.7584 - val_f1: 0.7165 - val_loss: 1.1166\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9744 - f1: 0.9693 - loss: 0.0675 - val_accuracy: 0.7590 - val_f1: 0.7140 - val_loss: 1.1580\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9710 - f1: 0.9658 - loss: 0.0737 - val_accuracy: 0.7649 - val_f1: 0.7259 - val_loss: 1.2091\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9787 - f1: 0.9744 - loss: 0.0588 - val_accuracy: 0.7649 - val_f1: 0.7271 - val_loss: 1.2445\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9780 - f1: 0.9738 - loss: 0.0599 - val_accuracy: 0.7571 - val_f1: 0.7188 - val_loss: 1.3063\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9768 - f1: 0.9727 - loss: 0.0610 - val_accuracy: 0.7590 - val_f1: 0.7179 - val_loss: 1.3412\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9753 - f1: 0.9703 - loss: 0.0706 - val_accuracy: 0.7531 - val_f1: 0.7134 - val_loss: 1.3335\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9759 - f1: 0.9711 - loss: 0.0587 - val_accuracy: 0.7452 - val_f1: 0.7139 - val_loss: 1.3891\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9791 - f1: 0.9756 - loss: 0.0534 - val_accuracy: 0.7505 - val_f1: 0.7143 - val_loss: 1.3796\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9769 - f1: 0.9725 - loss: 0.0548 - val_accuracy: 0.7603 - val_f1: 0.7241 - val_loss: 1.4089\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9741 - f1: 0.9692 - loss: 0.0671 - val_accuracy: 0.7518 - val_f1: 0.7179 - val_loss: 1.4275\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9795 - f1: 0.9757 - loss: 0.0570 - val_accuracy: 0.7492 - val_f1: 0.7212 - val_loss: 1.5569\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9756 - f1: 0.9713 - loss: 0.0561 - val_accuracy: 0.7426 - val_f1: 0.7143 - val_loss: 1.5218\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9750 - f1: 0.9702 - loss: 0.0590 - val_accuracy: 0.7590 - val_f1: 0.7205 - val_loss: 1.4928\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9757 - f1: 0.9712 - loss: 0.0554 - val_accuracy: 0.7511 - val_f1: 0.7215 - val_loss: 1.6041\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9763 - f1: 0.9719 - loss: 0.0620 - val_accuracy: 0.7689 - val_f1: 0.7237 - val_loss: 1.4899\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9800 - f1: 0.9761 - loss: 0.0474 - val_accuracy: 0.7571 - val_f1: 0.7255 - val_loss: 1.6120\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9780 - f1: 0.9739 - loss: 0.0527 - val_accuracy: 0.7584 - val_f1: 0.7032 - val_loss: 1.4475\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9785 - f1: 0.9749 - loss: 0.0568 - val_accuracy: 0.7511 - val_f1: 0.7215 - val_loss: 1.6551\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9778 - f1: 0.9732 - loss: 0.0577 - val_accuracy: 0.7492 - val_f1: 0.7244 - val_loss: 1.7707\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9777 - f1: 0.9735 - loss: 0.0511 - val_accuracy: 0.7439 - val_f1: 0.7145 - val_loss: 1.6666\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9777 - f1: 0.9732 - loss: 0.0501 - val_accuracy: 0.7452 - val_f1: 0.7160 - val_loss: 1.6818\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9800 - f1: 0.9764 - loss: 0.0515 - val_accuracy: 0.7439 - val_f1: 0.7153 - val_loss: 1.7391\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9780 - f1: 0.9740 - loss: 0.0501 - val_accuracy: 0.7531 - val_f1: 0.7194 - val_loss: 1.6337\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\n------------- Starting tf_idf__standard__(1, 2) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6024 - f1: 0.4648 - loss: 0.6574 - val_accuracy: 0.7249 - val_f1: 0.5318 - val_loss: 0.5289\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7385 - f1: 0.5900 - loss: 0.4686 - val_accuracy: 0.7925 - val_f1: 0.6996 - val_loss: 0.4796\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8285 - f1: 0.7691 - loss: 0.3531 - val_accuracy: 0.7938 - val_f1: 0.7435 - val_loss: 0.4969\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8842 - f1: 0.8525 - loss: 0.2909 - val_accuracy: 0.7919 - val_f1: 0.7187 - val_loss: 0.5319\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9005 - f1: 0.8720 - loss: 0.2379 - val_accuracy: 0.7800 - val_f1: 0.7287 - val_loss: 0.5583\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9278 - f1: 0.9130 - loss: 0.1922 - val_accuracy: 0.7833 - val_f1: 0.7227 - val_loss: 0.6062\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9249 - f1: 0.9071 - loss: 0.1772 - val_accuracy: 0.7800 - val_f1: 0.7373 - val_loss: 0.6708\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9417 - f1: 0.9280 - loss: 0.1400 - val_accuracy: 0.7774 - val_f1: 0.7312 - val_loss: 0.7146\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9472 - f1: 0.9348 - loss: 0.1295 - val_accuracy: 0.7748 - val_f1: 0.7343 - val_loss: 0.7617\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9479 - f1: 0.9384 - loss: 0.1212 - val_accuracy: 0.7827 - val_f1: 0.7289 - val_loss: 0.8136\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9619 - f1: 0.9534 - loss: 0.1005 - val_accuracy: 0.7715 - val_f1: 0.7294 - val_loss: 0.8285\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9647 - f1: 0.9587 - loss: 0.0998 - val_accuracy: 0.7708 - val_f1: 0.7254 - val_loss: 0.8507\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9589 - f1: 0.9510 - loss: 0.0968 - val_accuracy: 0.7781 - val_f1: 0.7287 - val_loss: 0.8978\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9648 - f1: 0.9591 - loss: 0.0889 - val_accuracy: 0.7761 - val_f1: 0.7334 - val_loss: 0.9500\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9660 - f1: 0.9592 - loss: 0.0872 - val_accuracy: 0.7715 - val_f1: 0.7302 - val_loss: 0.9874\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9680 - f1: 0.9625 - loss: 0.0771 - val_accuracy: 0.7669 - val_f1: 0.7280 - val_loss: 1.0074\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9682 - f1: 0.9622 - loss: 0.0786 - val_accuracy: 0.7643 - val_f1: 0.7303 - val_loss: 1.0906\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9698 - f1: 0.9632 - loss: 0.0774 - val_accuracy: 0.7669 - val_f1: 0.7216 - val_loss: 1.0481\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9668 - f1: 0.9598 - loss: 0.0716 - val_accuracy: 0.7630 - val_f1: 0.7267 - val_loss: 1.1308\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9698 - f1: 0.9640 - loss: 0.0669 - val_accuracy: 0.7597 - val_f1: 0.7227 - val_loss: 1.1609\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9770 - f1: 0.9729 - loss: 0.0607 - val_accuracy: 0.7649 - val_f1: 0.7172 - val_loss: 1.1274\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9679 - f1: 0.9618 - loss: 0.0649 - val_accuracy: 0.7590 - val_f1: 0.7192 - val_loss: 1.1866\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9711 - f1: 0.9660 - loss: 0.0658 - val_accuracy: 0.7643 - val_f1: 0.7253 - val_loss: 1.2402\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9686 - f1: 0.9627 - loss: 0.0744 - val_accuracy: 0.7663 - val_f1: 0.7232 - val_loss: 1.2464\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9782 - f1: 0.9746 - loss: 0.0509 - val_accuracy: 0.7649 - val_f1: 0.7271 - val_loss: 1.2147\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9768 - f1: 0.9722 - loss: 0.0551 - val_accuracy: 0.7708 - val_f1: 0.7305 - val_loss: 1.2326\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9730 - f1: 0.9682 - loss: 0.0571 - val_accuracy: 0.7702 - val_f1: 0.7257 - val_loss: 1.2424\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9760 - f1: 0.9716 - loss: 0.0577 - val_accuracy: 0.7669 - val_f1: 0.7233 - val_loss: 1.2747\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9779 - f1: 0.9738 - loss: 0.0519 - val_accuracy: 0.7676 - val_f1: 0.7277 - val_loss: 1.3073\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9786 - f1: 0.9750 - loss: 0.0549 - val_accuracy: 0.7676 - val_f1: 0.7213 - val_loss: 1.2903\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9762 - f1: 0.9720 - loss: 0.0534 - val_accuracy: 0.7636 - val_f1: 0.7269 - val_loss: 1.3456\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9755 - f1: 0.9711 - loss: 0.0528 - val_accuracy: 0.7689 - val_f1: 0.7254 - val_loss: 1.3248\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9764 - f1: 0.9722 - loss: 0.0555 - val_accuracy: 0.7636 - val_f1: 0.7078 - val_loss: 1.3732\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9722 - f1: 0.9662 - loss: 0.0608 - val_accuracy: 0.7689 - val_f1: 0.7263 - val_loss: 1.4058\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9723 - f1: 0.9675 - loss: 0.0551 - val_accuracy: 0.7649 - val_f1: 0.7159 - val_loss: 1.3715\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9748 - f1: 0.9706 - loss: 0.0556 - val_accuracy: 0.7708 - val_f1: 0.7297 - val_loss: 1.4267\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9797 - f1: 0.9751 - loss: 0.0471 - val_accuracy: 0.7715 - val_f1: 0.7323 - val_loss: 1.4184\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9762 - f1: 0.9717 - loss: 0.0492 - val_accuracy: 0.7682 - val_f1: 0.7223 - val_loss: 1.3706\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9751 - f1: 0.9707 - loss: 0.0501 - val_accuracy: 0.7656 - val_f1: 0.7182 - val_loss: 1.3825\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9729 - f1: 0.9677 - loss: 0.0576 - val_accuracy: 0.7702 - val_f1: 0.7257 - val_loss: 1.4152\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9779 - f1: 0.9736 - loss: 0.0523 - val_accuracy: 0.7689 - val_f1: 0.7224 - val_loss: 1.3944\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9782 - f1: 0.9737 - loss: 0.0582 - val_accuracy: 0.7636 - val_f1: 0.7143 - val_loss: 1.3960\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n\n------------- Starting tf_idf__custom__(1,) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6223 - f1: 0.5091 - loss: 0.6575 - val_accuracy: 0.7571 - val_f1: 0.6209 - val_loss: 0.5055\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8117 - f1: 0.7318 - loss: 0.4357 - val_accuracy: 0.7945 - val_f1: 0.7266 - val_loss: 0.4609\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8747 - f1: 0.8374 - loss: 0.3291 - val_accuracy: 0.8011 - val_f1: 0.7494 - val_loss: 0.4884\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9061 - f1: 0.8811 - loss: 0.2612 - val_accuracy: 0.7919 - val_f1: 0.7454 - val_loss: 0.5331\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9168 - f1: 0.8990 - loss: 0.2223 - val_accuracy: 0.7866 - val_f1: 0.7312 - val_loss: 0.5636\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9248 - f1: 0.9095 - loss: 0.2022 - val_accuracy: 0.7866 - val_f1: 0.7334 - val_loss: 0.6314\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9354 - f1: 0.9212 - loss: 0.1710 - val_accuracy: 0.7807 - val_f1: 0.7293 - val_loss: 0.6836\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9571 - f1: 0.9476 - loss: 0.1389 - val_accuracy: 0.7794 - val_f1: 0.7346 - val_loss: 0.7409\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9585 - f1: 0.9500 - loss: 0.1278 - val_accuracy: 0.7722 - val_f1: 0.7274 - val_loss: 0.7859\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9627 - f1: 0.9539 - loss: 0.1238 - val_accuracy: 0.7708 - val_f1: 0.7280 - val_loss: 0.8398\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9669 - f1: 0.9604 - loss: 0.1037 - val_accuracy: 0.7669 - val_f1: 0.7207 - val_loss: 0.8813\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9674 - f1: 0.9604 - loss: 0.0969 - val_accuracy: 0.7590 - val_f1: 0.7196 - val_loss: 0.9768\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9675 - f1: 0.9611 - loss: 0.0948 - val_accuracy: 0.7610 - val_f1: 0.7183 - val_loss: 1.0006\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9732 - f1: 0.9676 - loss: 0.0841 - val_accuracy: 0.7603 - val_f1: 0.7212 - val_loss: 1.0883\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9739 - f1: 0.9692 - loss: 0.0828 - val_accuracy: 0.7643 - val_f1: 0.7236 - val_loss: 1.1075\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9775 - f1: 0.9734 - loss: 0.0677 - val_accuracy: 0.7610 - val_f1: 0.7191 - val_loss: 1.1644\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9746 - f1: 0.9699 - loss: 0.0786 - val_accuracy: 0.7472 - val_f1: 0.7138 - val_loss: 1.2820\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9771 - f1: 0.9728 - loss: 0.0699 - val_accuracy: 0.7518 - val_f1: 0.7145 - val_loss: 1.2946\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9757 - f1: 0.9714 - loss: 0.0752 - val_accuracy: 0.7603 - val_f1: 0.7245 - val_loss: 1.3384\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9781 - f1: 0.9741 - loss: 0.0669 - val_accuracy: 0.7577 - val_f1: 0.7215 - val_loss: 1.3938\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9808 - f1: 0.9774 - loss: 0.0713 - val_accuracy: 0.7479 - val_f1: 0.7168 - val_loss: 1.4783\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9797 - f1: 0.9751 - loss: 0.0688 - val_accuracy: 0.7466 - val_f1: 0.7141 - val_loss: 1.5115\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9744 - f1: 0.9700 - loss: 0.0828 - val_accuracy: 0.7538 - val_f1: 0.7161 - val_loss: 1.4829\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9761 - f1: 0.9713 - loss: 0.0675 - val_accuracy: 0.7538 - val_f1: 0.7161 - val_loss: 1.4732\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9828 - f1: 0.9795 - loss: 0.0574 - val_accuracy: 0.7413 - val_f1: 0.7128 - val_loss: 1.6496\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9802 - f1: 0.9766 - loss: 0.0609 - val_accuracy: 0.7498 - val_f1: 0.7116 - val_loss: 1.5767\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9814 - f1: 0.9783 - loss: 0.0577 - val_accuracy: 0.7479 - val_f1: 0.7147 - val_loss: 1.6259\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9813 - f1: 0.9780 - loss: 0.0606 - val_accuracy: 0.7433 - val_f1: 0.7131 - val_loss: 1.7147\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9802 - f1: 0.9762 - loss: 0.0622 - val_accuracy: 0.7525 - val_f1: 0.7159 - val_loss: 1.6394\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9846 - f1: 0.9820 - loss: 0.0519 - val_accuracy: 0.7498 - val_f1: 0.7159 - val_loss: 1.7319\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9821 - f1: 0.9791 - loss: 0.0555 - val_accuracy: 0.7406 - val_f1: 0.7123 - val_loss: 1.8354\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9842 - f1: 0.9814 - loss: 0.0583 - val_accuracy: 0.7328 - val_f1: 0.7099 - val_loss: 1.9718\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9826 - f1: 0.9795 - loss: 0.0558 - val_accuracy: 0.7400 - val_f1: 0.7126 - val_loss: 1.9029\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9827 - f1: 0.9797 - loss: 0.0516 - val_accuracy: 0.7420 - val_f1: 0.7142 - val_loss: 1.9049\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9835 - f1: 0.9809 - loss: 0.0493 - val_accuracy: 0.7466 - val_f1: 0.7191 - val_loss: 1.9286\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9857 - f1: 0.9833 - loss: 0.0514 - val_accuracy: 0.7525 - val_f1: 0.7209 - val_loss: 1.8681\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9822 - f1: 0.9794 - loss: 0.0604 - val_accuracy: 0.7571 - val_f1: 0.7259 - val_loss: 1.8722\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9815 - f1: 0.9783 - loss: 0.0602 - val_accuracy: 0.7610 - val_f1: 0.7221 - val_loss: 1.8239\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9837 - f1: 0.9810 - loss: 0.0547 - val_accuracy: 0.7518 - val_f1: 0.7179 - val_loss: 1.9160\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9850 - f1: 0.9821 - loss: 0.0481 - val_accuracy: 0.7577 - val_f1: 0.7194 - val_loss: 1.8682\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9854 - f1: 0.9828 - loss: 0.0473 - val_accuracy: 0.7564 - val_f1: 0.7258 - val_loss: 1.9982\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9855 - f1: 0.9828 - loss: 0.0481 - val_accuracy: 0.7426 - val_f1: 0.7155 - val_loss: 2.0805\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\n------------- Starting tf_idf__custom__(1, 2) ---------------------\nEpoch 1/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6037 - f1: 0.5398 - loss: 0.6874 - val_accuracy: 0.7216 - val_f1: 0.5268 - val_loss: 0.5339\nEpoch 2/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7938 - f1: 0.7057 - loss: 0.4630 - val_accuracy: 0.7905 - val_f1: 0.7016 - val_loss: 0.4619\nEpoch 3/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8563 - f1: 0.8097 - loss: 0.3464 - val_accuracy: 0.7997 - val_f1: 0.7303 - val_loss: 0.4728\nEpoch 4/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8902 - f1: 0.8597 - loss: 0.2735 - val_accuracy: 0.7971 - val_f1: 0.7392 - val_loss: 0.5064\nEpoch 5/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9186 - f1: 0.8986 - loss: 0.2199 - val_accuracy: 0.7925 - val_f1: 0.7327 - val_loss: 0.5524\nEpoch 6/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9275 - f1: 0.9101 - loss: 0.1884 - val_accuracy: 0.7919 - val_f1: 0.7361 - val_loss: 0.5992\nEpoch 7/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9442 - f1: 0.9322 - loss: 0.1667 - val_accuracy: 0.7840 - val_f1: 0.7416 - val_loss: 0.6850\nEpoch 8/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9503 - f1: 0.9410 - loss: 0.1489 - val_accuracy: 0.7833 - val_f1: 0.7381 - val_loss: 0.7313\nEpoch 9/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9531 - f1: 0.9440 - loss: 0.1351 - val_accuracy: 0.7794 - val_f1: 0.7316 - val_loss: 0.7768\nEpoch 10/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9575 - f1: 0.9495 - loss: 0.1189 - val_accuracy: 0.7814 - val_f1: 0.7334 - val_loss: 0.8410\nEpoch 11/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9669 - f1: 0.9603 - loss: 0.1103 - val_accuracy: 0.7787 - val_f1: 0.7298 - val_loss: 0.8828\nEpoch 12/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9654 - f1: 0.9591 - loss: 0.1032 - val_accuracy: 0.7728 - val_f1: 0.7267 - val_loss: 0.9495\nEpoch 13/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9697 - f1: 0.9649 - loss: 0.0956 - val_accuracy: 0.7695 - val_f1: 0.7251 - val_loss: 1.0086\nEpoch 14/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9755 - f1: 0.9708 - loss: 0.0877 - val_accuracy: 0.7754 - val_f1: 0.7341 - val_loss: 1.0484\nEpoch 15/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9732 - f1: 0.9690 - loss: 0.0881 - val_accuracy: 0.7643 - val_f1: 0.7206 - val_loss: 1.0926\nEpoch 16/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9778 - f1: 0.9738 - loss: 0.0760 - val_accuracy: 0.7617 - val_f1: 0.7218 - val_loss: 1.1751\nEpoch 17/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9774 - f1: 0.9733 - loss: 0.0761 - val_accuracy: 0.7748 - val_f1: 0.7335 - val_loss: 1.1735\nEpoch 18/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9771 - f1: 0.9728 - loss: 0.0808 - val_accuracy: 0.7590 - val_f1: 0.7205 - val_loss: 1.2770\nEpoch 19/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9790 - f1: 0.9752 - loss: 0.0654 - val_accuracy: 0.7525 - val_f1: 0.7218 - val_loss: 1.3975\nEpoch 20/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9788 - f1: 0.9744 - loss: 0.0696 - val_accuracy: 0.7617 - val_f1: 0.7206 - val_loss: 1.3288\nEpoch 21/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9783 - f1: 0.9749 - loss: 0.0696 - val_accuracy: 0.7564 - val_f1: 0.7258 - val_loss: 1.4228\nEpoch 22/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9769 - f1: 0.9730 - loss: 0.0696 - val_accuracy: 0.7577 - val_f1: 0.7252 - val_loss: 1.4009\nEpoch 23/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9818 - f1: 0.9777 - loss: 0.0610 - val_accuracy: 0.7538 - val_f1: 0.7257 - val_loss: 1.4959\nEpoch 24/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9811 - f1: 0.9779 - loss: 0.0660 - val_accuracy: 0.7511 - val_f1: 0.7260 - val_loss: 1.5884\nEpoch 25/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9800 - f1: 0.9758 - loss: 0.0600 - val_accuracy: 0.7531 - val_f1: 0.7287 - val_loss: 1.6172\nEpoch 26/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9813 - f1: 0.9782 - loss: 0.0617 - val_accuracy: 0.7590 - val_f1: 0.7239 - val_loss: 1.4819\nEpoch 27/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9836 - f1: 0.9808 - loss: 0.0547 - val_accuracy: 0.7538 - val_f1: 0.7296 - val_loss: 1.6409\nEpoch 28/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9848 - f1: 0.9820 - loss: 0.0485 - val_accuracy: 0.7597 - val_f1: 0.7248 - val_loss: 1.5790\nEpoch 29/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9824 - f1: 0.9789 - loss: 0.0542 - val_accuracy: 0.7584 - val_f1: 0.7241 - val_loss: 1.6261\nEpoch 30/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9846 - f1: 0.9817 - loss: 0.0571 - val_accuracy: 0.7571 - val_f1: 0.7319 - val_loss: 1.7663\nEpoch 31/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9836 - f1: 0.9805 - loss: 0.0497 - val_accuracy: 0.7498 - val_f1: 0.7217 - val_loss: 1.7495\nEpoch 32/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9780 - f1: 0.9740 - loss: 0.0647 - val_accuracy: 0.7498 - val_f1: 0.7237 - val_loss: 1.7364\nEpoch 33/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9840 - f1: 0.9811 - loss: 0.0510 - val_accuracy: 0.7472 - val_f1: 0.7256 - val_loss: 1.8843\nEpoch 34/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9806 - f1: 0.9771 - loss: 0.0583 - val_accuracy: 0.7426 - val_f1: 0.7200 - val_loss: 1.8765\nEpoch 35/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9858 - f1: 0.9834 - loss: 0.0509 - val_accuracy: 0.7466 - val_f1: 0.7219 - val_loss: 1.8837\nEpoch 36/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9821 - f1: 0.9793 - loss: 0.0519 - val_accuracy: 0.7518 - val_f1: 0.7257 - val_loss: 1.8507\nEpoch 37/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9826 - f1: 0.9795 - loss: 0.0523 - val_accuracy: 0.7406 - val_f1: 0.7201 - val_loss: 2.0308\nEpoch 38/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9816 - f1: 0.9781 - loss: 0.0599 - val_accuracy: 0.7387 - val_f1: 0.7213 - val_loss: 2.0960\nEpoch 39/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9847 - f1: 0.9819 - loss: 0.0498 - val_accuracy: 0.7400 - val_f1: 0.7242 - val_loss: 2.1431\nEpoch 40/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9838 - f1: 0.9811 - loss: 0.0520 - val_accuracy: 0.7374 - val_f1: 0.7226 - val_loss: 2.1674\nEpoch 41/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9839 - f1: 0.9806 - loss: 0.0523 - val_accuracy: 0.7400 - val_f1: 0.7231 - val_loss: 2.1056\nEpoch 42/42\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9812 - f1: 0.9779 - loss: 0.0536 - val_accuracy: 0.7275 - val_f1: 0.7152 - val_loss: 2.3494\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model_name = \"\"\nglobal_best_val_score = 0\n\nfor name, history in histories.items():\n    print(name)\n    mode, cleaning, ngrams = name.split(\"__\")\n    print(f\"Validation-f1-scores for {mode}-encoding, {cleaning}-cleaning, {ngrams}-ngrams:\")\n    vals_f1 = tf.stack(history.history[\"val_f1\"])[:,0].numpy() # Don't know why it is saved so intricated\n    print(vals_f1)\n    max_val = np.max(vals_f1)\n    if max_val > global_best_val_score:\n        global_best_val_score = max_val\n        best_model_name = name\n    print(\"The maximal f1-score: \", np.max(vals_f1))\n    print()\nprint(\"The best model in total is \", best_model_name)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:13:26.930536Z","iopub.execute_input":"2024-08-13T13:13:26.931080Z","iopub.status.idle":"2024-08-13T13:13:26.963265Z","shell.execute_reply.started":"2024-08-13T13:13:26.931032Z","shell.execute_reply":"2024-08-13T13:13:26.962015Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"int__standard__(1,)\nValidation-f1-scores for int-encoding, standard-cleaning, (1,)-ngrams:\n[0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.16315047 0.03915662 0.36699504 0.33164552 0.6674655\n 0.54838705 0.38423643 0.42155686 0.50225216 0.6556419  0.57659566\n 0.6888749  0.71038246 0.5090497  0.40727267 0.67502403 0.7518573\n 0.7316636  0.6715658  0.5853658  0.7095115  0.6068821  0.73669267]\nThe maximal f1-score:  0.7518573\n\nint__standard__(1, 2)\nValidation-f1-scores for int-encoding, standard-cleaning, (1, 2)-ngrams:\n[0.         0.         0.         0.         0.         0.\n 0.         0.         0.1020408  0.5541401  0.6949602  0.10480348\n 0.672279   0.44339615 0.7003609  0.731788   0.7346278  0.30429125\n 0.50340134 0.6607669  0.7285843  0.6077002  0.5966386  0.5234899\n 0.57020354 0.4815668  0.7568388  0.56652355 0.74874    0.64924616\n 0.5386313  0.6004184  0.7391603  0.6653465  0.7559738  0.65066665\n 0.74181813 0.76249033 0.7592752  0.6891652  0.69059163 0.6790266 ]\nThe maximal f1-score:  0.76249033\n\nint__custom__(1,)\nValidation-f1-scores for int-encoding, custom-cleaning, (1,)-ngrams:\n[0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.43353292 0.13753581 0.25970545 0.41656515 0.4837209\n 0.5809217  0.65866953 0.17671809 0.19944596 0.5704989  0.6288032\n 0.71003705 0.5711183  0.60337543 0.28722    0.67507267 0.7458803\n 0.72495437 0.75150466 0.7305152  0.7493495  0.5927505  0.5040091 ]\nThe maximal f1-score:  0.75150466\n\nint__custom__(1, 2)\nValidation-f1-scores for int-encoding, custom-cleaning, (1, 2)-ngrams:\n[0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.6194251\n 0.29172137 0.34605592 0.7526576  0.03333333 0.67271686 0.4615384\n 0.58216965 0.5908607  0.70401937 0.52488685 0.5953389  0.7550701\n 0.4299516  0.7535322  0.66141725 0.75017786 0.57483727 0.69142854\n 0.75379425 0.75278014 0.56516975 0.34605592 0.6141199  0.7566693 ]\nThe maximal f1-score:  0.7566693\n\ntf_idf__standard__(1,)\nValidation-f1-scores for tf_idf-encoding, standard-cleaning, (1,)-ngrams:\n[0.68426013 0.7342222  0.73157895 0.7424242  0.7438016  0.73895574\n 0.7424483  0.73244137 0.74325365 0.73964024 0.73805845 0.7392937\n 0.7286821  0.7237354  0.72645056 0.72024256 0.7167999  0.72161734\n 0.7164869  0.7139516  0.7258805  0.72713405 0.71884495 0.7179093\n 0.7134146  0.71386427 0.7142857  0.72411186 0.7179104  0.72116786\n 0.7142857  0.72048736 0.7215282  0.72370476 0.7255192  0.70322573\n 0.7215282  0.7243867  0.7144949  0.71595895 0.7153284  0.71940297]\nThe maximal f1-score:  0.7438016\n\ntf_idf__standard__(1, 2)\nValidation-f1-scores for tf_idf-encoding, standard-cleaning, (1, 2)-ngrams:\n[0.53184354 0.6996197  0.743464   0.7187222  0.72874486 0.72268903\n 0.73725486 0.7311657  0.7343144  0.7289107  0.72939336 0.72541296\n 0.72873193 0.7333854  0.73023254 0.7279693  0.7302779  0.7215685\n 0.7267222  0.72272724 0.7172196  0.7192042  0.7253251  0.7231726\n 0.72713405 0.7305019  0.7257052  0.7233047  0.7276923  0.72125983\n 0.7268588  0.725429   0.70779216 0.726283   0.71587294 0.7296668\n 0.73230755 0.72226584 0.718232   0.7257052  0.72239745 0.7142856 ]\nThe maximal f1-score:  0.743464\n\ntf_idf__custom__(1,)\nValidation-f1-scores for tf_idf-encoding, custom-cleaning, (1,)-ngrams:\n[0.6209015  0.72663754 0.7493796  0.74538153 0.73118275 0.733388\n 0.7293354  0.7345971  0.7274155  0.7279812  0.7206922  0.7196333\n 0.7182662  0.7211611  0.7236335  0.7191357  0.7137546  0.7145015\n 0.72452825 0.7215094  0.7168141  0.7140741  0.7161241  0.7161241\n 0.712828   0.71158206 0.7147102  0.7131328  0.7159005  0.7158836\n 0.7123088  0.70990723 0.7126269  0.7141818  0.7190683  0.7209474\n 0.72592586 0.7221374  0.7179104  0.71939164 0.72579455 0.71552974]\nThe maximal f1-score:  0.7493796\n\ntf_idf__custom__(1, 2)\nValidation-f1-scores for tf_idf-encoding, custom-cleaning, (1, 2)-ngrams:\n[0.5267857  0.70159024 0.73032707 0.7392404  0.73265654 0.7360532\n 0.7415553  0.7380952  0.7316294  0.73338664 0.72975135 0.72669816\n 0.725137   0.7340591  0.72062254 0.7218391  0.7334887  0.72048736\n 0.7217711  0.72055423 0.72579455 0.72524196 0.72567666 0.72595805\n 0.7287156  0.72385246 0.7296322  0.7248119  0.72413784 0.731884\n 0.72169465 0.72371274 0.72558796 0.71999997 0.721902   0.72568935\n 0.72005665 0.72128844 0.7242339  0.72260743 0.7230769  0.71516806]\nThe maximal f1-score:  0.7415553\n\nThe best model in total is  int__standard__(1, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"predictions__\" + best_model_name)\ndf.to_csv(\"submission.csv\", index=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:13:26.964519Z","iopub.execute_input":"2024-08-13T13:13:26.965040Z","iopub.status.idle":"2024-08-13T13:13:26.990534Z","shell.execute_reply.started":"2024-08-13T13:13:26.964994Z","shell.execute_reply":"2024-08-13T13:13:26.989014Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       1\n1   2       0\n2   3       1\n3   9       0\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Helper function for recunstructing Sentences","metadata":{}},{"cell_type":"code","source":"def reconstruct_sentence(int_vec, vectorizer):\n    voc = np.array(vectorizer.get_vocabulary())\n    #print(int_vecs)\n    #print(type(int_vecs))\n    sentence = (\" \".join(voc[int_vec]))\n    return sentence\n#for i in range(...):\n#    print(reconstruct_sentence(...), \"  \", y_train[i])","metadata":{"execution":{"iopub.status.busy":"2024-08-13T13:13:26.993019Z","iopub.execute_input":"2024-08-13T13:13:26.993561Z","iopub.status.idle":"2024-08-13T13:13:27.001702Z","shell.execute_reply.started":"2024-08-13T13:13:26.993515Z","shell.execute_reply":"2024-08-13T13:13:26.999919Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"It seems, that our own original submission where heavily overfitted.\n\nUsing the ModelCheckpoint-Callback helps a lot! (What else do we have the validation data for?!)\n\nAlso, Justino's training starts to improve MUCH earlier, probably because of the ordering in the data, leading to some kind of \"Curriculum learning\". \n(See the code line with\ndf_equalized = pd.concat([class_0_under, class_1]))","metadata":{}}]}