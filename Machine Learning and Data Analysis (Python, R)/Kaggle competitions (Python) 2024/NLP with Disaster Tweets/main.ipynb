{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nAfter first attempts, the score was very low. (about 0.5)\n\nThen, we lokked up other Kaggler's submissions, in particular Beatriz Justino's https://www.kaggle.com/code/beatrizjustino/lstm-disaster-tweets. (Version 12)\n\nAnd we wondered, why it was so much better (about 0.8). Here are the findngs:","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow import keras\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\n# Imports that Justino's code needs:\nfrom keras import preprocessing\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.layers import Embedding, LSTM, Dense, Dropout,BatchNormalization\nfrom keras.models import Sequential\nimport tensorflow as tf\nfrom sklearn.feature_extraction.text import ENGLISH_STOP_WORDS","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:23:31.712881Z","iopub.execute_input":"2024-08-12T08:23:31.714193Z","iopub.status.idle":"2024-08-12T08:23:31.722724Z","shell.execute_reply.started":"2024-08-12T08:23:31.714135Z","shell.execute_reply":"2024-08-12T08:23:31.721178Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Choices","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nMAX_TOKENS = 10000\nEPOCHS = 20\nMAX_SENTENCE_LENGTH = 60","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:29:41.516215Z","iopub.execute_input":"2024-08-12T08:29:41.516676Z","iopub.status.idle":"2024-08-12T08:29:41.521964Z","shell.execute_reply.started":"2024-08-12T08:29:41.516639Z","shell.execute_reply":"2024-08-12T08:29:41.520662Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Raw Datasets","metadata":{}},{"cell_type":"code","source":"all_known_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\n\ntrain_df, val_df = train_test_split(all_known_df, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:23:36.003656Z","iopub.execute_input":"2024-08-12T08:23:36.004108Z","iopub.status.idle":"2024-08-12T08:23:36.052293Z","shell.execute_reply.started":"2024-08-12T08:23:36.004075Z","shell.execute_reply":"2024-08-12T08:23:36.050978Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Note that the data seems to be badly classified:\nTwo examples classified as disaster, which I stumbled about:","metadata":{}},{"cell_type":"code","source":"badly_classified_example = all_known_df[all_known_df[\"text\"].str.contains(\"whirlwind of time\")]\nprint(badly_classified_example)\nprint(badly_classified_example['text'].to_numpy())\nprint(badly_classified_example['target'].to_numpy())\n\nbadly_classified_example = all_known_df[all_known_df[\"text\"].str.contains(\"Attack II Volleyball\")]\nprint()\nprint(print(badly_classified_example))\nprint(badly_classified_example['text'].to_numpy())\nprint(badly_classified_example['target'].to_numpy())","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:23:38.056072Z","iopub.execute_input":"2024-08-12T08:23:38.056525Z","iopub.status.idle":"2024-08-12T08:23:38.079495Z","shell.execute_reply.started":"2024-08-12T08:23:38.056490Z","shell.execute_reply":"2024-08-12T08:23:38.078210Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"         id    keyword                        location  \\\n7270  10409  whirlwind  Stamford & Cork (& Shropshire)   \n\n                                                   text  target  \n7270  I moved to England five years ago today. What ...       1  \n['I moved to England five years ago today. What a whirlwind of time it has been! http://t.co/eaSlGeA1B7']\n[1]\n\n      id keyword location                                               text  \\\n466  674  attack      NaN  #volleyball Attack II Volleyball Training Mach...   \n\n     target  \n466       1  \nNone\n['#volleyball Attack II Volleyball Training Machine - Sets Simulation - http://t.co/dCDeCFv934 http://t.co/dWBC1dUvdk']\n[1]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Justino's Raw Dataset\n\nJustino encodes the target differently, and balances the uneven classes. (It does not seem to help a lot.)","metadata":{}},{"cell_type":"code","source":"def get_Justino_raw_data(df, df_val=None):\n    def extract_text_and_target(df):\n        return df[\"text\"].to_numpy(), df[\"target\"].to_numpy()\n    class_0 = df[df['target'] == 0]\n    class_1 = df[df['target'] == 1]\n    class_0_under = class_0.sample(len(class_1), random_state=42)\n    df_equalized = pd.concat([class_0_under, class_1])\n    text, label = extract_text_and_target(df_equalized)\n    if df_val is not None:\n        text_val, label_val = extract_text_and_target(df_val)\n        return text, label, text_val, label_val\n    else:\n        return text, label","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:23:40.781519Z","iopub.execute_input":"2024-08-12T08:23:40.782263Z","iopub.status.idle":"2024-08-12T08:23:40.789251Z","shell.execute_reply.started":"2024-08-12T08:23:40.782230Z","shell.execute_reply":"2024-08-12T08:23:40.788005Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Our preprocessing functions","metadata":{}},{"cell_type":"markdown","source":"One function for cleaning text snippets:","metadata":{}},{"cell_type":"code","source":"import re, string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nstemmer = SnowballStemmer('english')\nstop_words = set(stopwords.words('english'))\n\ndef clean_stem_text(text):    \n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n    # Remove @mentions and hashtags\n    text = re.sub(r'\\@\\w+|\\#', '', text)\n    # Remove digits\n    text = re.sub(r'\\d+', '', text)\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    # Remove extra spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    # Convert to lowercase\n    text = text.lower()\n    # Remove stopwords and stem\n    text = ' '.join([stemmer.stem(word) \n                     for word in text.split() \n                     if word not in stop_words])\n    return text\n\ndef clean_stem_byte_tensor(tensor):\n    texts = tensor.numpy()\n    texts = np.reshape(texts, (-1,))\n    texts = [text.decode(\"utf-8\") for text in texts]\n    texts = [clean_stem_text(text) for text in texts]\n    return tf.constant(texts, dtype=tf.string, shape=(len(texts),))","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:25:19.773498Z","iopub.execute_input":"2024-08-12T08:25:19.774630Z","iopub.status.idle":"2024-08-12T08:25:19.787371Z","shell.execute_reply.started":"2024-08-12T08:25:19.774556Z","shell.execute_reply":"2024-08-12T08:25:19.785709Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Lots of functions for applying the cleaning function and for encoding the text numerically:\n\n(One can later chose from these different methods.)","metadata":{}},{"cell_type":"code","source":"int_text_vectorization_custom_clean_text = keras.layers.TextVectorization(\n    output_mode=\"int\",\n    max_tokens=MAX_TOKENS,\n    output_sequence_length=MAX_SENTENCE_LENGTH,\n    standardize=clean_stem_byte_tensor\n)\ntf_idf_text_vectorization_custom_clean_text = keras.layers.TextVectorization(\n    output_mode=\"tf_idf\",\n    max_tokens=MAX_TOKENS,\n    standardize=clean_stem_byte_tensor\n)\nint_text_vectorization = keras.layers.TextVectorization(\n    output_mode=\"int\",\n    max_tokens=MAX_TOKENS,\n    output_sequence_length=MAX_SENTENCE_LENGTH\n)\ntf_idf_text_vectorization = keras.layers.TextVectorization(\n    output_mode=\"tf_idf\",\n    max_tokens=MAX_TOKENS\n)\nvectorizers = [int_text_vectorization_custom_clean_text,\n              tf_idf_text_vectorization_custom_clean_text,\n              int_text_vectorization,\n              tf_idf_text_vectorization]\n\ndef preprocess_df(df, df_val=None, mode=\"int\", clean=\"standard\", df_test=None):\n    if mode==\"int\" and clean==\"standard\":\n        vectorizer = int_text_vectorization\n    elif mode==\"tf_idf\" and clean==\"standard\":\n        vectorizer = tf_idf_text_vectorization\n    elif mode==\"int\" and clean==\"custom\":\n        vectorizer = int_text_vectorization_custom_clean_text\n    elif mode==\"tf_idf\" and clean==\"custom\":\n        vectorizer = tf_idf_text_vectorization_custom_clean_text\n    else:\n        raise ValueError(\"Value not allowed\")\n        \n    def df_to_X_y(df):\n        X = df[\"text\"].to_numpy()\n        y = np.reshape(np.array(df[\"target\"]), (-1,1))\n        return X, y\n    \n    X, y = df_to_X_y(df)\n    vectorizer.adapt(X)\n    if df_test is not None:\n        X_test = vectorizer(df_test[\"text\"].to_numpy())\n        if df_val is not None:\n            X_val, y_val = df_to_X_y(df_val)\n            return vectorizer(X), y, vectorizer(X_val), y_val, X_test\n        else:\n            return vectorizer(X), y, X_test\n    else:\n        if X_val is not None:\n            X_val, y_val = df_to_X_y(df_val)\n            return vectorizer(X), y, vectorizer(X_val), y_val\n        else:\n            return vectorizer(X), y","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:25:28.691565Z","iopub.execute_input":"2024-08-12T08:25:28.692026Z","iopub.status.idle":"2024-08-12T08:25:28.774234Z","shell.execute_reply.started":"2024-08-12T08:25:28.691992Z","shell.execute_reply":"2024-08-12T08:25:28.772978Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"(The proprocessing is safely run on the dataset (not in the model) to save the GPU from being blocked.)","metadata":{}},{"cell_type":"markdown","source":"# Justino's preprocessing functions\nATTENTION: There seemed to be a bug in applying the stemming! It does not work with lists, but should be applied on single words.","metadata":{}},{"cell_type":"code","source":"def clean_Justino(text_array):\n    def process_sentence(sentence):\n        sentence = re.sub(r'http\\S+|www\\S+|https\\S+', '', sentence, flags=re.MULTILINE)\n        sentence = re.sub(r'#\\S+', '', sentence)\n        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n        words = sentence.split()\n        filtered_words = [word for word in words if word.lower() not in ENGLISH_STOP_WORDS]\n        return ' '.join(filtered_words)\n    return [process_sentence(sentence) for sentence in text_array]\n\ndef get_Justino_preprocessed_data(df, df_val=None, label_to_cat=True, vocab_length=None, length_long_sentence=MAX_SENTENCE_LENGTH):\n    if df_val is not None:\n        texts, labels, texts_val, labels_val = get_Justino_raw_data(df, df_val)\n        texts_val = clean_Justino(texts_val)\n        texts_val = [stemmer.stem(word) for word in texts_val]\n    else:\n        texts, labels = get_Justino_raw_data(df)\n    texts = clean_Justino(texts)\n    #print(texts[:5])\n    texts = [stemmer.stem(word) for word in texts]\n    #print(\"-----------\")\n    #print(texts[:5])\n    \n    word_tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_length)\n    word_tokenizer.fit_on_texts(texts)\n    \n    #from nltk.tokenize import word_tokenize\n    #longest_train = max(text, key=lambda sentence: len(word_tokenize(sentence)))\n    #length_long_sentence = len(word_tokenize(longest_train))\n    \n    def process_data(texts, labels):\n        sequences = word_tokenizer.texts_to_sequences(texts)\n        padded_sequences = pad_sequences(sequences, maxlen=length_long_sentence)\n        if label_to_cat:\n            labels = keras.utils.to_categorical(labels)\n        return padded_sequences, labels\n    \n    padded_sequences, labels = process_data(texts, labels)\n    if df_val is not None:\n        padded_sequences_val, labels_val = process_data(texts_val, labels_val)\n        return padded_sequences, labels, padded_sequences_val, labels_val\n    else:\n        return padded_sequences, labels\n#get_Justino_preprocessed_data(train_df, val_df)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:26:33.599753Z","iopub.execute_input":"2024-08-12T08:26:33.600930Z","iopub.status.idle":"2024-08-12T08:26:33.612605Z","shell.execute_reply.started":"2024-08-12T08:26:33.600885Z","shell.execute_reply":"2024-08-12T08:26:33.611321Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# F1-Metric\n\nUsing metrics=[\"f1_score\"] is not working properly in tensorflow up until now!! The problem is discussed on some GitHub-site...\n\nWe specify an f1-metric more manually here:","metadata":{}},{"cell_type":"code","source":"f1 = tf.keras.metrics.F1Score(\n    average=None, threshold=0.5, name='f1', dtype=None\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:26:37.494506Z","iopub.execute_input":"2024-08-12T08:26:37.495665Z","iopub.status.idle":"2024-08-12T08:26:37.501231Z","shell.execute_reply.started":"2024-08-12T08:26:37.495616Z","shell.execute_reply":"2024-08-12T08:26:37.499675Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"For training, one could also try to use an adapted \"f1-loss\":","metadata":{}},{"cell_type":"code","source":"def f1_loss(y_true, y_pred):\n    \n    tp = tf.sum(tf.cast(y_true*y_pred, 'float'), axis=0)\n    tn = tf.sum(tf.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = tf.sum(tf.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = tf.sum(tf.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + tf.epsilon())\n    r = tp / (tp + fn + tf.epsilon())\n\n    f1 = 2*p*r / (p+r+tf.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1 - tf.mean(f1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:26:39.451466Z","iopub.execute_input":"2024-08-12T08:26:39.452688Z","iopub.status.idle":"2024-08-12T08:26:39.460236Z","shell.execute_reply.started":"2024-08-12T08:26:39.452646Z","shell.execute_reply":"2024-08-12T08:26:39.458944Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Our Models","metadata":{}},{"cell_type":"code","source":"\ndef get_model(max_tokens, hidden_dim=16, embedding_dim=33):\n    inputs = keras.Input(shape=(MAX_SENTENCE_LENGTH,), dtype=\"int64\")\n    x = keras.layers.Embedding(input_dim=max_tokens, output_dim=embedding_dim)(inputs)\n    #x = keras.layers.Flatten()(x)\n    #x = keras.layers.Conv1D(1,embedding_dim)(x)[:,0]\n    x = keras.layers.GlobalAveragePooling1D()(x)\n    x = keras.layers.Dense(hidden_dim, activation=\"relu\")(x)\n    x = keras.layers.Dense(hidden_dim, activation=\"relu\")(x)+x\n    #x = keras.layers.Dense(hidden_dim, activation=\"relu\")(x)\n    x = keras.layers.Dropout(0.5)(x)\n    x = keras.layers.Dense(1)(x)\n    model = keras.Model(inputs=inputs, outputs=x)\n    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n                 #loss=f1_loss,\n                 optimizer=\"rmsprop\",\n                 metrics=[\"accuracy\", f1],\n                 #run_eagerly=True\n                 )\n    return model\n\n# We should also try to do simple logistic regression, when we find the time for it:\n\n#def get_LR_model(max_tokens):\n#    inputs = keras.Input(shape=(MAX_SENTENCE_LENGTH,), dtype=\"int64\")\n#    x = tf.keras.layers.CategoryEncoding(\n#        num_tokens=max_tokens, output_mode='multi_hot', sparse=False\n#    )(inputs)\n#    x = keras.layers.Dense(1)(x)\n#    model = keras.Model(inputs=inputs, outputs=x)\n#    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n#                 #loss=f1_loss,\n#                 optimizer=\"adam\",\n#                 metrics=[\"f1_score\", \"accuracy\", \"precision\", \"recall\"],\n#                 #run_eagerly=True\n#                 )\n#    return model\n\n#def get_tf_idf_LR_model(max_tokens):\n#    inputs = keras.Input(shape=(max_tokens,), dtype=\"int64\")\n#    x = keras.layers.Dense(1)(inputs)\n#    model = keras.Model(inputs=inputs, outputs=x)\n#    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n#                 #loss=f1_loss,\n#                 optimizer=\"adam\",\n#                 metrics=[\"f1_score\", \"accuracy\", \"precision\", \"recall\"],\n#                 #run_eagerly=True\n#                 )\n#    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:26:42.561080Z","iopub.execute_input":"2024-08-12T08:26:42.561551Z","iopub.status.idle":"2024-08-12T08:26:42.578766Z","shell.execute_reply.started":"2024-08-12T08:26:42.561513Z","shell.execute_reply":"2024-08-12T08:26:42.577612Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# That's basically Justino's model for our own data-formatting.. Maybe we'll use it one day.\n\n#def get_LSTM_model():\n#    inputs = keras.Input((MAX_SENTENCE_LENGTH,), dtype=tf.int64)\n#    x = keras.layers.Embedding(input_dim=MAX_TOKENS, output_dim=128)(inputs)\n#    x = keras.layers.Dropout(0.5)(x)\n#    x = keras.layers.LSTM(65)(x)\n#    x = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n#    model=keras.Model(inputs, x)\n#    model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=False),\n#                  optimizer=\"Adamax\",\n#                  metrics=[\"accuracy\", \"f1_score\"],\n#                 #run_eagerly=True\n#                 )\n#    model.summary()\n#    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-10T10:22:35.163512Z","iopub.execute_input":"2024-08-10T10:22:35.163992Z","iopub.status.idle":"2024-08-10T10:22:35.177304Z","shell.execute_reply.started":"2024-08-10T10:22:35.163952Z","shell.execute_reply":"2024-08-10T10:22:35.176306Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"# Jutino's Model","metadata":{}},{"cell_type":"code","source":"def get_Justino_model(max_words=MAX_TOKENS, max_len=MAX_SENTENCE_LENGTH):\n    model = Sequential()\n    model.add(Embedding(max_words, 128))\n    model.add(Dropout(0.5))\n    model.add(LSTM(64))\n    model.add(Dense(2, activation='sigmoid'))\n\n    model.compile(loss='BinaryCrossentropy', optimizer='Adamax', metrics=['accuracy', f1])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:29:03.591396Z","iopub.execute_input":"2024-08-12T08:29:03.591815Z","iopub.status.idle":"2024-08-12T08:29:03.598905Z","shell.execute_reply.started":"2024-08-12T08:29:03.591783Z","shell.execute_reply":"2024-08-12T08:29:03.597486Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Runs","metadata":{}},{"cell_type":"markdown","source":"Justino orginal:","metadata":{}},{"cell_type":"code","source":"X_Justino, y_Justino = get_Justino_preprocessed_data(all_known_df)\nmod_Justino = get_Justino_model(max_words=np.max(np.max(X_Justino))+1)\nmod_Justino.fit(X_Justino, y_Justino, epochs=EPOCHS, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:29:55.229246Z","iopub.execute_input":"2024-08-12T08:29:55.229696Z","iopub.status.idle":"2024-08-12T08:32:10.155103Z","shell.execute_reply.started":"2024-08-12T08:29:55.229652Z","shell.execute_reply":"2024-08-12T08:32:10.153632Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.5415 - f1: 0.5381 - loss: 0.6898\nEpoch 2/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.6776 - f1: 0.6748 - loss: 0.6206\nEpoch 3/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.7737 - f1: 0.7752 - loss: 0.4896\nEpoch 4/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - accuracy: 0.8080 - f1: 0.8070 - loss: 0.4240\nEpoch 5/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.8390 - f1: 0.8386 - loss: 0.3719\nEpoch 6/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.8577 - f1: 0.8584 - loss: 0.3334\nEpoch 7/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.8766 - f1: 0.8769 - loss: 0.2972\nEpoch 8/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.8912 - f1: 0.8917 - loss: 0.2769\nEpoch 9/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.8954 - f1: 0.8953 - loss: 0.2551\nEpoch 10/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9095 - f1: 0.9094 - loss: 0.2264\nEpoch 11/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.9258 - f1: 0.9254 - loss: 0.2049\nEpoch 12/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9232 - f1: 0.9227 - loss: 0.2032\nEpoch 13/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9301 - f1: 0.9299 - loss: 0.1805\nEpoch 14/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9330 - f1: 0.9327 - loss: 0.1697\nEpoch 15/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.9438 - f1: 0.9438 - loss: 0.1534\nEpoch 16/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9455 - f1: 0.9452 - loss: 0.1482\nEpoch 17/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9534 - f1: 0.9532 - loss: 0.1244\nEpoch 18/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.9541 - f1: 0.9540 - loss: 0.1209\nEpoch 19/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.9572 - f1: 0.9575 - loss: 0.1134\nEpoch 20/20\n\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.9570 - f1: 0.9568 - loss: 0.1103\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7df3a44d7460>"},"metadata":{}}]},{"cell_type":"markdown","source":"Justino with splitting data into train and val:","metadata":{}},{"cell_type":"code","source":"X_Justino, y_Justino, X_Justino_val, y_Justino_val = get_Justino_preprocessed_data(train_df, val_df)\nmod_Justino = get_Justino_model(max_words=np.max(np.max(X_Justino))+1)\nmod_Justino.fit(X_Justino, y_Justino, validation_data=(X_Justino_val, y_Justino_val), epochs=EPOCHS, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:32:10.157054Z","iopub.execute_input":"2024-08-12T08:32:10.157409Z","iopub.status.idle":"2024-08-12T08:33:56.791795Z","shell.execute_reply.started":"2024-08-12T08:32:10.157379Z","shell.execute_reply":"2024-08-12T08:33:56.790464Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.5634 - f1: 0.8516 - loss: 0.6891 - val_accuracy: 0.6842 - val_f1: 0.6604 - val_loss: 0.6523\nEpoch 2/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.6683 - f1: 0.6649 - loss: 0.6392 - val_accuracy: 0.7413 - val_f1: 0.7179 - val_loss: 0.5537\nEpoch 3/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.7497 - f1: 0.7487 - loss: 0.5168 - val_accuracy: 0.7735 - val_f1: 0.7515 - val_loss: 0.4887\nEpoch 4/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8094 - f1: 0.8076 - loss: 0.4222 - val_accuracy: 0.7761 - val_f1: 0.7673 - val_loss: 0.4755\nEpoch 5/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8560 - f1: 0.8548 - loss: 0.3462 - val_accuracy: 0.7794 - val_f1: 0.7726 - val_loss: 0.4845\nEpoch 6/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8703 - f1: 0.8699 - loss: 0.3239 - val_accuracy: 0.7814 - val_f1: 0.7719 - val_loss: 0.4900\nEpoch 7/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8777 - f1: 0.8787 - loss: 0.2917 - val_accuracy: 0.7689 - val_f1: 0.7664 - val_loss: 0.5263\nEpoch 8/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8932 - f1: 0.8916 - loss: 0.2709 - val_accuracy: 0.7741 - val_f1: 0.7701 - val_loss: 0.5187\nEpoch 9/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9119 - f1: 0.9112 - loss: 0.2224 - val_accuracy: 0.7584 - val_f1: 0.7573 - val_loss: 0.5624\nEpoch 10/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9090 - f1: 0.9090 - loss: 0.2218 - val_accuracy: 0.7702 - val_f1: 0.7683 - val_loss: 0.5606\nEpoch 11/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9253 - f1: 0.9259 - loss: 0.1962 - val_accuracy: 0.7741 - val_f1: 0.7664 - val_loss: 0.5414\nEpoch 12/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9282 - f1: 0.9280 - loss: 0.1835 - val_accuracy: 0.7649 - val_f1: 0.7626 - val_loss: 0.5864\nEpoch 13/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9345 - f1: 0.9343 - loss: 0.1660 - val_accuracy: 0.7485 - val_f1: 0.7469 - val_loss: 0.6487\nEpoch 14/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9406 - f1: 0.9398 - loss: 0.1548 - val_accuracy: 0.7406 - val_f1: 0.7395 - val_loss: 0.6821\nEpoch 15/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9429 - f1: 0.9417 - loss: 0.1451 - val_accuracy: 0.7505 - val_f1: 0.7491 - val_loss: 0.6715\nEpoch 16/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9490 - f1: 0.9492 - loss: 0.1318 - val_accuracy: 0.7722 - val_f1: 0.7645 - val_loss: 0.6499\nEpoch 17/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9492 - f1: 0.9498 - loss: 0.1264 - val_accuracy: 0.7636 - val_f1: 0.7605 - val_loss: 0.6812\nEpoch 18/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9578 - f1: 0.9580 - loss: 0.1144 - val_accuracy: 0.7774 - val_f1: 0.7703 - val_loss: 0.6750\nEpoch 19/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9573 - f1: 0.9572 - loss: 0.1165 - val_accuracy: 0.7538 - val_f1: 0.7533 - val_loss: 0.7086\nEpoch 20/20\n\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9646 - f1: 0.9641 - loss: 0.1046 - val_accuracy: 0.7597 - val_f1: 0.7567 - val_loss: 0.7180\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7df39f4f10c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Own models:","metadata":{}},{"cell_type":"code","source":"X_train, y_train, X_val, y_val, X_test = preprocess_df(train_df, val_df, df_test=test_df)\nmodel = get_model(MAX_TOKENS)\nmodel.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=64,\n         callbacks=[keras.callbacks.ModelCheckpoint(\"own_model.keras\",save_best_only=True)])","metadata":{"execution":{"iopub.status.busy":"2024-08-12T08:36:34.208409Z","iopub.execute_input":"2024-08-12T08:36:34.208939Z","iopub.status.idle":"2024-08-12T08:36:49.655781Z","shell.execute_reply.started":"2024-08-12T08:36:34.208904Z","shell.execute_reply":"2024-08-12T08:36:49.654643Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5759 - f1: 0.2025 - loss: 0.6889 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6813\nEpoch 2/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5725 - f1: 0.0000e+00 - loss: 0.6850 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6824\nEpoch 3/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5587 - f1: 0.0000e+00 - loss: 0.6862 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6802\nEpoch 4/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5714 - f1: 0.0000e+00 - loss: 0.6819 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6838\nEpoch 5/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5649 - f1: 0.0000e+00 - loss: 0.6841 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6788\nEpoch 6/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5649 - f1: 0.0000e+00 - loss: 0.6803 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6756\nEpoch 7/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5629 - f1: 0.0000e+00 - loss: 0.6804 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6685\nEpoch 8/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5589 - f1: 0.0000e+00 - loss: 0.6717 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6650\nEpoch 9/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5579 - f1: 0.0000e+00 - loss: 0.6607 - val_accuracy: 0.5739 - val_f1: 0.0000e+00 - val_loss: 0.6474\nEpoch 10/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5657 - f1: 0.0279 - loss: 0.6424 - val_accuracy: 0.6316 - val_f1: 0.2724 - val_loss: 0.7005\nEpoch 11/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5919 - f1: 0.1726 - loss: 0.6311 - val_accuracy: 0.5975 - val_f1: 0.1129 - val_loss: 0.6010\nEpoch 12/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6432 - f1: 0.2873 - loss: 0.5924 - val_accuracy: 0.6973 - val_f1: 0.4861 - val_loss: 0.5795\nEpoch 13/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6655 - f1: 0.4286 - loss: 0.5939 - val_accuracy: 0.7630 - val_f1: 0.7142 - val_loss: 0.6089\nEpoch 14/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6981 - f1: 0.5290 - loss: 0.5719 - val_accuracy: 0.5988 - val_f1: 0.1158 - val_loss: 0.6412\nEpoch 15/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7004 - f1: 0.5100 - loss: 0.5638 - val_accuracy: 0.7708 - val_f1: 0.7170 - val_loss: 0.5626\nEpoch 16/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7272 - f1: 0.5910 - loss: 0.5429 - val_accuracy: 0.6054 - val_f1: 0.6556 - val_loss: 0.7436\nEpoch 17/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7148 - f1: 0.5824 - loss: 0.5566 - val_accuracy: 0.7538 - val_f1: 0.6154 - val_loss: 0.5043\nEpoch 18/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7510 - f1: 0.6384 - loss: 0.5204 - val_accuracy: 0.7735 - val_f1: 0.6767 - val_loss: 0.4969\nEpoch 19/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7611 - f1: 0.6616 - loss: 0.5026 - val_accuracy: 0.7768 - val_f1: 0.6805 - val_loss: 0.4851\nEpoch 20/20\n\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7594 - f1: 0.6583 - loss: 0.5056 - val_accuracy: 0.6494 - val_f1: 0.6787 - val_loss: 0.7233\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7df39d2bace0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Helper function for recunstructing Reconstruct Sentences","metadata":{}},{"cell_type":"code","source":"def reconstruct_sentence(int_vec, vectorizer):\n    voc = np.array(vectorizer.get_vocabulary())\n    #print(int_vecs)\n    #print(type(int_vecs))\n    sentence = (\" \".join(voc[int_vec]))\n    return sentence\n#for i in range(...):\n#    print(reconstruct_sentence(...), \"  \", y_train[i])","metadata":{"execution":{"iopub.status.busy":"2024-08-10T10:22:53.949975Z","iopub.status.idle":"2024-08-10T10:22:53.950328Z","shell.execute_reply.started":"2024-08-10T10:22:53.950160Z","shell.execute_reply":"2024-08-10T10:22:53.950174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"model = keras.models.load_model(\"own_model.keras\")\npredictions_logits = model.predict(X_test)\npredictions = tf.math.sigmoid(predictions_logits).numpy()\nsubmit_df = test_df[[\"id\"]].copy()\nsubmit_df[\"target\"] = (predictions>0.5).astype(int)\nsubmit_df.to_csv(\"submission.csv\", index=False)\nsubmit_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"It seems, that our own original submission where heavily overfitted.\n\nUsing the ModelCheckpoint-Callback helps a lot! (What else do we have the validation data for?!)\n\nAlso, Justino's training starts to improve MUCH earlier, probably because of the ordering in the data, leading to some kind of \"Curriculum learning\". \n(See the code line with\ndf_equalized = pd.concat([class_0_under, class_1]))","metadata":{}}]}